{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "592e57a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ColabNotebook = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if ColabNotebook:\n",
    "    # monta G-drive en entorno COLAB\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    DATOS_DIR = '/content/drive/MyDrive/Colab Notebooks/DATOS/'  # carpeta donde se encuentran los datasets\n",
    "else:\n",
    "    FUENTES_DIR = '../Fuentes/' # carpeta LOCAL donde se encuentran los scripts\n",
    "    DATOS_DIR   = '../Datos/' # carpeta LOCAL donde se encuentran los datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "006e5b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import chardet\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def openFile(nomArch, sep=None):\n",
    "    file = DATOS_DIR + nomArch\n",
    "    #-- detectando la codificación de caracteres usada ----\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read()) \n",
    "    return pd.read_csv(file, encoding=result['encoding'], sep=sep, engine='python') # or readline if the file is large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32766a11",
   "metadata": {},
   "source": [
    "### Ejercicio 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6be231c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = openFile('hawks.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27fb1758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Año Especie   Ala   Peso  Cola  Hallux\n",
      "0  1994      RT  2770   9400   218     304\n",
      "1  1997      RT  3730   9140   221     304\n",
      "2  2000      RT  3790  10000   217     322\n",
      "3  2000      RT  3920  11850   229     330\n",
      "4  2002      RT  3650  11250   213     293\n",
      "============\n",
      "               Año          Ala          Peso        Cola       Hallux\n",
      "count   893.000000   893.000000    893.000000  893.000000   893.000000\n",
      "mean   1998.285554  3161.178052   7722.609183  198.954087   291.771557\n",
      "std       3.446286   952.791335   4626.197218   36.807936   321.324050\n",
      "min    1992.000000   372.000000    560.000000  119.000000    95.000000\n",
      "25%    1995.000000  2020.000000   1850.000000  160.000000   152.000000\n",
      "50%    1999.000000  3700.000000   9700.000000  214.000000   295.000000\n",
      "75%    2001.000000  3900.000000  11200.000000  225.000000   315.000000\n",
      "max    2003.000000  4800.000000  20300.000000  288.000000  3414.000000\n",
      "============\n",
      "Año        0\n",
      "Especie    0\n",
      "Ala        0\n",
      "Peso       0\n",
      "Cola       0\n",
      "Hallux     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(\"============\")\n",
    "print(df.describe())\n",
    "print(\"============\")\n",
    "print(df.isnull().sum())  # para ver si hay datos nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4cc8a5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerización one-hot de la columna \"Especie\"\n",
    "df = pd.get_dummies(df, columns=[\"Especie\"])*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9096fe1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8998883674343939\n",
      "Correlación: 0.8998883674343939, Intensidad: fuerte, Tipo: positiva\n"
     ]
    }
   ],
   "source": [
    "# Calcule la correlación lineal entre los atributos Ala y Cola. Indique la intensidad de la correlación (no hay\n",
    "# correlación/débil/fuerte) y el tipo (positiva/negativa)\n",
    "\n",
    "correlacion = df[\"Ala\"].corr(df[\"Cola\"])\n",
    "print(correlacion)\n",
    "\n",
    "abs_correlacion = abs(correlacion)\n",
    "\n",
    "if abs_correlacion == 0:\n",
    "    intensidad = \"no hay correlación\"\n",
    "elif abs_correlacion < 0.5:\n",
    "    intensidad = \"débil\"\n",
    "else:\n",
    "    intensidad = \"fuerte\"\n",
    "\n",
    "if correlacion > 0:\n",
    "    tipo = \"positiva\"\n",
    "else:\n",
    "    tipo = \"negativa\"\n",
    "\n",
    "print(f\"Correlación: {correlacion}, Intensidad: {intensidad}, Tipo: {tipo}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d5ad528a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media: -3.182722220649945e-17\n",
      "Desviación estándar: 1.0005603811031016\n",
      "Mínimo: -0.6127204722295961\n",
      "Máximo: 9.722204366378598\n",
      "Q1: -0.43523004866808146\n",
      "Q2 (mediana): 0.010052943775718458\n",
      "Q3: 0.07233028537624991\n",
      "Rango intercuartílico (IQR): 0.5075603340443313\n",
      "Bigote superior: 0.8336707864427468\n",
      "Bigote inferior: -1.1965705497345784\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "normalizador = preprocessing.StandardScaler()\n",
    "\n",
    "df_estandarizado = df.copy()\n",
    "df_estandarizado[\"Hallux\"] = normalizador.fit_transform(df[[\"Hallux\"]])\n",
    "\n",
    "describe = df_estandarizado[\"Hallux\"].describe()\n",
    "print(\"Media:\", describe[\"mean\"])\n",
    "print(\"Desviación estándar:\", describe[\"std\"])\n",
    "print(\"Mínimo:\", describe[\"min\"])\n",
    "print(\"Máximo:\", describe[\"max\"])\n",
    "print(\"Q1:\", describe[\"25%\"])\n",
    "print(\"Q2 (mediana):\", describe[\"50%\"])\n",
    "print(\"Q3:\", describe[\"75%\"])\n",
    "print(\"Rango intercuartílico (IQR):\", describe[\"75%\"] - describe[\"25%\"])\n",
    "print(\"Bigote superior:\", describe[\"75%\"] + 1.5 * (describe[\"75%\"] - describe[\"25%\"]))\n",
    "print(\"Bigote inferior:\", describe[\"25%\"] - 1.5 * (describe[\"75%\"] - describe[\"25%\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3374d5b1",
   "metadata": {},
   "source": [
    "Compare los valores obtenidos e indique el valor de verdad de las siguientes afirmaciones:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cc8678",
   "metadata": {},
   "source": [
    "### I. El valor de Q2 normalizado permite afirmar que la media y la mediana tienen valores cercanos. \n",
    "Falso, el valor de Q2(0.01005) no es similar al de la media(-3.182722)\n",
    "\n",
    "\n",
    "### II. El máximo valor de Hallux se encuentra a más de 9 desvíos por encima de la media. \n",
    "Sí, por que la media es -3 y el desvío 1, entonces -3+9*1= 6\n",
    "\n",
    "### III. Un hallux que mida más de 600 mm es considerado atípico extremo. \n",
    "No\n",
    "\n",
    "### IV. Un valor normalizado del atributo “hallux” de 2 se considerará un valor atípico extremo. \n",
    "\n",
    "\n",
    "V. En un gavilán es atípico que su hallux mida menos de 100 mm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0d88fd75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número estandarizado: 0.9592448604907569\n",
      "¿Es un valor extremo? False\n"
     ]
    }
   ],
   "source": [
    "media = df[\"Hallux\"].mean()\n",
    "desviacion_estandar = df[\"Hallux\"].std()\n",
    "\n",
    "num = 600\n",
    "num_estandarizado = (num - media) / desviacion_estandar\n",
    "\n",
    "# Cálculo de si es un valor extremo en base a 3 veces el IQR\n",
    "es_extremo = num_estandarizado < describe[\"25%\"] - 3 * (describe[\"75%\"] - describe[\"25%\"]) or num_estandarizado > describe[\"75%\"] + 3 * (describe[\"75%\"] - describe[\"25%\"])\n",
    "print(\"Número estandarizado:\", num_estandarizado) # Imprime 599.663.....\n",
    "print(\"¿Es un valor extremo?\", es_extremo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d201809d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número estandarizado: 2\n",
      "¿Es un valor extremo? True\n"
     ]
    }
   ],
   "source": [
    "media = df_estandarizado[\"Hallux\"].mean()\n",
    "desviacion_estandar = df_estandarizado[\"Hallux\"].std()\n",
    "num_estandarizado = 2\n",
    "\n",
    "es_extremo = num_estandarizado < describe[\"25%\"] - 3 * (describe[\"75%\"] - describe[\"25%\"]) or num_estandarizado > describe[\"75%\"] + 3 * (describe[\"75%\"] - describe[\"25%\"])\n",
    "print(\"Número estandarizado:\", num_estandarizado) # Imprime 2\n",
    "print(\"¿Es un valor extremo?\", es_extremo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e5d9fc",
   "metadata": {},
   "source": [
    "### Ejercicio 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dad94cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(df, dummie):\n",
    "    df_estandarizado = df.copy()\n",
    "    df_estandarizado= df_estandarizado[df_estandarizado[\"Drug\"] != 'drugY']\n",
    "\n",
    "    df_estandarizado[\"Age\"] = normalizador.fit_transform(df_estandarizado[[\"Age\"]])\n",
    "\n",
    "    # Convertimos Sex a numérico\n",
    "    df_estandarizado[\"Sex\"] = df_estandarizado[\"Sex\"].map({'F': 1, 'M': 0})\n",
    "\n",
    "    if dummie:\n",
    "        # Aplicamos get_dummies DESPUÉS de las otras transformaciones\n",
    "        # y sobre el dataframe ya transformado\n",
    "        df_estandarizado[[\"BP_HIGH\", \"BP_NORMAL\", \"BP_LOW\", \"Cholesterol_HIGH\", \"Cholesterol_NORMAL\"]] = pd.get_dummies(df_estandarizado[[\"BP\", \"Cholesterol\"]])\n",
    "        # Convertimos las columnas booleanas a enteros\n",
    "        for col in df_estandarizado.columns:\n",
    "            if df_estandarizado[col].dtype == bool:\n",
    "                df_estandarizado[col] = df_estandarizado[col].astype(int)\n",
    "        df_estandarizado = df_estandarizado.drop(columns=[\"BP\", \"Cholesterol\"])\n",
    "    else:\n",
    "        df_estandarizado[\"BP\"] = df_estandarizado[\"BP\"].map({'HIGH': 2, 'NORMAL': 1, 'LOW': 0})\n",
    "        df_estandarizado[\"Cholesterol\"] = df_estandarizado[\"Cholesterol\"].map({'HIGH': 1, 'NORMAL': 0})\n",
    "\n",
    "    # Normalizamos Na y K\n",
    "    df_estandarizado[\"Na\"] = normalizador.fit_transform(df_estandarizado[[\"Na\"]])\n",
    "    df_estandarizado[\"K\"] = normalizador.fit_transform(df_estandarizado[[\"K\"]])\n",
    "\n",
    "\n",
    "    # Extraemos X e Y\n",
    "    Y = (df_estandarizado[\"Drug\"] == 'drugY')*1  # 1 Si es drugY, 0 en caso contrario\n",
    "    X = df_estandarizado.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "    return df_estandarizado, X, Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "44d57e1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aciertos =  22\n",
      "% de aciertos = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(FUENTES_DIR)\n",
    "from ClassPerceptron import Perceptron\n",
    "import pandas as pd\n",
    "\n",
    "ppn = Perceptron(alpha=0.01, n_iter=40, draw=1, random_state=1)\n",
    "df = openFile('drugs_train.csv')\n",
    "df_test = openFile('drugs_test.csv')\n",
    "\n",
    "dummie = 1\n",
    "\n",
    "df_estandarizado, X, Y = process(df, dummie)\n",
    "\n",
    "ppn.fit(X, Y)\n",
    "\n",
    "df_estandarizado_test, X, T = process(df_test, dummie)\n",
    "\n",
    "Y = ppn.predict(X)\n",
    "\n",
    "aciertos = sum(Y == T)  \n",
    "print(\"aciertos = \", aciertos)\n",
    "\n",
    "nAciertos = sum(Y==T)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*nAciertos/X.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddde72ef",
   "metadata": {},
   "source": [
    "Sin el dummie (Mapeando con numéricos ordinales): aciertos =  17\n",
    "% de aciertos = 94.44 %.\n",
    "\n",
    "Con el dummie (Una columna para BP_HIG, BP_LOW, etc.): aciertos =  18\n",
    "% de aciertos = 100.00 %. \n",
    "\n",
    "¿Por qué es mejor el uso de OneHot Encoding (dummie)?\n",
    "\n",
    "#### Diferencia entre mapeo ordinal y dummies\n",
    "\n",
    "Mapeo ordinal (ej. HIGH=2, NORMAL=1, LOW=0):\n",
    "\n",
    "Estás imponiendo un orden numérico artificial.\n",
    "\n",
    "El modelo interpretará que HIGH está “más cerca” de NORMAL que de LOW, lo cual no necesariamente refleja la realidad médica.\n",
    "\n",
    "Ejemplo: la presión \"HIGH\" no es simplemente \"dos veces\" la de \"LOW\".\n",
    "\n",
    "Dummies (one-hot encoding):\n",
    "\n",
    "Cada categoría se convierte en una variable independiente binaria (ej. BP_HIGH=1 o 0).\n",
    "\n",
    "El perceptrón ya no necesita “adivinar” un orden, simplemente asigna un peso distinto a cada categoría.\n",
    "\n",
    "Esto elimina la falsa suposición de que hay un orden numérico entre los valores categóricos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "716692a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizador(df, normalizador=None):\n",
    "    df_normalizado = df.copy()\n",
    "\n",
    "    # Convertimos a numérico\n",
    "    df_normalizado[\"Sex\"] = df_normalizado[\"Sex\"].map({'F': 1, 'M': 0})\n",
    "    df_normalizado[\"BP\"] = df_normalizado[\"BP\"].map({'HIGH': 2, 'NORMAL': 1, 'LOW': 0})\n",
    "    df_normalizado[\"Cholesterol\"] = df_normalizado[\"Cholesterol\"].map({'HIGH': 1, 'NORMAL': 0})\n",
    "    df_normalizado[\"Drug\"] = (df_normalizado[\"Drug\"]==\"drugY\")*1\n",
    "    print(df_normalizado.head())\n",
    "\n",
    "    if normalizador:\n",
    "        df_normalizado[\"BP\"] = normalizador.fit_transform(df_normalizado[[\"BP\"]])\n",
    "        df_normalizado[\"Cholesterol\"] = normalizador.fit_transform(df_normalizado[[\"Cholesterol\"]])\n",
    "        df_normalizado[\"Age\"] = normalizador.fit_transform(df_normalizado[[\"Age\"]])\n",
    "        df_normalizado[\"Na\"] = normalizador.fit_transform(df_normalizado[[\"Na\"]])\n",
    "        df_normalizado[\"K\"] = normalizador.fit_transform(df_normalizado[[\"K\"]])\n",
    "\n",
    "    return df_normalizado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372049a0",
   "metadata": {},
   "source": [
    "#### DF Sin normalizar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "05d4dad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  BP  Cholesterol        Na         K  Drug\n",
      "0   16    0   0            1  0.743021  0.061886     0\n",
      "1   42    1   2            1  0.533228  0.025348     1\n",
      "2   33    1   0            1  0.858387  0.025634     1\n",
      "3   47    0   0            1  0.697269  0.068944     0\n",
      "4   56    1   2            1  0.750962  0.029571     1\n",
      "   Age  Sex  BP  Cholesterol        Na         K  Drug\n",
      "0   47    1   0            1  0.539774  0.053620     0\n",
      "1   49    0   0            0  0.625889  0.056828     0\n",
      "2   50    0   2            1  0.518285  0.069193     0\n",
      "3   32    1   1            1  0.549375  0.073474     0\n",
      "4   40    0   2            1  0.557133  0.020022     1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: Drug, dtype: int64\n",
      "aciertos =  18\n",
      "% de aciertos = 45.00 %\n"
     ]
    }
   ],
   "source": [
    "df = openFile('drugs_train.csv')\n",
    "df_test = openFile('drugs_test.csv')\n",
    "\n",
    "ppn = Perceptron(alpha=0.01, n_iter=40, draw=1, random_state=1)\n",
    "\n",
    "df_train_sin_estandarizar = normalizador(df)\n",
    "df_test_sin_estandarizar = normalizador(df_test)\n",
    "\n",
    "# Extraemos X e Y\n",
    "Y = df_train_sin_estandarizar[\"Drug\"]*1  # 1 Si es drugY, 0 en caso contrario\n",
    "X = df_train_sin_estandarizar.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "print(Y.head())\n",
    "\n",
    "ppn.fit(X, Y)\n",
    "\n",
    "Y_Test = df_test_sin_estandarizar[\"Drug\"].values  # 1 Si es drugY, 0 en caso contrario\n",
    "X_Test = df_test_sin_estandarizar.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "T = ppn.predict(X_Test)\n",
    "\n",
    "aciertos = sum(Y_Test == T)  \n",
    "print(\"aciertos = \", aciertos)\n",
    "\n",
    "nAciertos = sum(Y_Test==T)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*nAciertos/X_Test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b745d0c",
   "metadata": {},
   "source": [
    "#### DF Normalizado con normalización lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "549346ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  BP  Cholesterol        Na         K  Drug\n",
      "0   16    0   0            1  0.743021  0.061886     0\n",
      "1   42    1   2            1  0.533228  0.025348     1\n",
      "2   33    1   0            1  0.858387  0.025634     1\n",
      "3   47    0   0            1  0.697269  0.068944     0\n",
      "4   56    1   2            1  0.750962  0.029571     1\n",
      "   Age  Sex  BP  Cholesterol        Na         K  Drug\n",
      "0   47    1   0            1  0.539774  0.053620     0\n",
      "1   49    0   0            0  0.625889  0.056828     0\n",
      "2   50    0   2            1  0.518285  0.069193     0\n",
      "3   32    1   1            1  0.549375  0.073474     0\n",
      "4   40    0   2            1  0.557133  0.020022     1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: Drug, dtype: int64\n",
      "aciertos =  39\n",
      "% de aciertos = 97.50 %\n"
     ]
    }
   ],
   "source": [
    "norm = preprocessing.MinMaxScaler()\n",
    "\n",
    "df_train_sin_estandarizar = normalizador(df, norm)\n",
    "df_test_sin_estandarizar = normalizador(df_test, norm)\n",
    "\n",
    "# Extraemos X e Y\n",
    "Y = df_train_sin_estandarizar[\"Drug\"]*1  # 1 Si es drugY, 0 en caso contrario\n",
    "X = df_train_sin_estandarizar.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "print(Y.head())\n",
    "\n",
    "ppn.fit(X, Y)\n",
    "\n",
    "Y_Test = df_test_sin_estandarizar[\"Drug\"].values  # 1 Si es drugY, 0 en caso contrario\n",
    "X_Test = df_test_sin_estandarizar.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "T = ppn.predict(X_Test)\n",
    "\n",
    "aciertos = sum(Y_Test == T)  \n",
    "print(\"aciertos = \", aciertos)\n",
    "\n",
    "nAciertos = sum(Y_Test==T)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*nAciertos/X_Test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbc3d58",
   "metadata": {},
   "source": [
    "DF Normalizado con normalización de media y desvío"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d4ea5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  Sex  BP  Cholesterol        Na         K  Drug\n",
      "0   16    0   0            1  0.743021  0.061886     0\n",
      "1   42    1   2            1  0.533228  0.025348     1\n",
      "2   33    1   0            1  0.858387  0.025634     1\n",
      "3   47    0   0            1  0.697269  0.068944     0\n",
      "4   56    1   2            1  0.750962  0.029571     1\n",
      "   Age  Sex  BP  Cholesterol        Na         K  Drug\n",
      "0   47    1   0            1  0.539774  0.053620     0\n",
      "1   49    0   0            0  0.625889  0.056828     0\n",
      "2   50    0   2            1  0.518285  0.069193     0\n",
      "3   32    1   1            1  0.549375  0.073474     0\n",
      "4   40    0   2            1  0.557133  0.020022     1\n",
      "0    0\n",
      "1    1\n",
      "2    1\n",
      "3    0\n",
      "4    1\n",
      "Name: Drug, dtype: int64\n",
      "[0 0 0 0 1 1 1 1 1 1 0 0 0 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 1 1\n",
      " 0 1 1]\n",
      "aciertos =  37\n",
      "% de aciertos = 92.50 %\n"
     ]
    }
   ],
   "source": [
    "norm = preprocessing.StandardScaler()\n",
    "\n",
    "df_train_sin_estandarizar = normalizador(df, norm)\n",
    "df_test_sin_estandarizar = normalizador(df_test, norm)\n",
    "\n",
    "# Extraemos X e Y\n",
    "Y = df_train_sin_estandarizar[\"Drug\"]*1  # 1 Si es drugY, 0 en caso contrario\n",
    "X = df_train_sin_estandarizar.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "print(Y.head())\n",
    "\n",
    "ppn.fit(X, Y)\n",
    "\n",
    "Y_Test = df_test_sin_estandarizar[\"Drug\"].values  # 1 Si es drugY, 0 en caso contrario\n",
    "X_Test = df_test_sin_estandarizar.drop(columns=[\"Drug\"]).values\n",
    "\n",
    "T = ppn.predict(X_Test)\n",
    "\n",
    "print(T)\n",
    "\n",
    "aciertos = sum(Y_Test == T)  \n",
    "print(\"aciertos = \", aciertos)\n",
    "\n",
    "nAciertos = sum(Y_Test==T)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*nAciertos/X_Test.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5272e97e",
   "metadata": {},
   "source": [
    "### Ejercicio 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ac49b745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clases únicas: ['Tipo1' 'Tipo2' 'Tipo3']\n",
      "Distribución de clases:\n",
      "Clase\n",
      "Tipo1    70\n",
      "Tipo2    70\n",
      "Tipo3    70\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== Entrenando perceptrón para detectar 'Tipo1' ===\n",
      "Precisión para 'Tipo1': 91.90%\n",
      "Verdaderos positivos: 57\n",
      "Falsos positivos: 4\n",
      "Falsos negativos: 13\n",
      "Verdaderos negativos: 136\n",
      "Ejemplos de 'Tipo1' clasificados correctamente: 57\n",
      "Total de ejemplos de 'Tipo1': 70\n",
      "\n",
      "=== Entrenando perceptrón para detectar 'Tipo2' ===\n",
      "Precisión para 'Tipo2': 97.14%\n",
      "Verdaderos positivos: 65\n",
      "Falsos positivos: 1\n",
      "Falsos negativos: 5\n",
      "Verdaderos negativos: 139\n",
      "Ejemplos de 'Tipo2' clasificados correctamente: 65\n",
      "Total de ejemplos de 'Tipo2': 70\n",
      "\n",
      "=== Entrenando perceptrón para detectar 'Tipo3' ===\n",
      "Precisión para 'Tipo3': 93.81%\n",
      "Verdaderos positivos: 58\n",
      "Falsos positivos: 1\n",
      "Falsos negativos: 12\n",
      "Verdaderos negativos: 139\n",
      "Ejemplos de 'Tipo3' clasificados correctamente: 58\n",
      "Total de ejemplos de 'Tipo3': 70\n",
      "\n",
      "=== RESUMEN FINAL ===\n",
      "Tipo1: Precisión = 91.90%\n",
      "Tipo2: Precisión = 97.14%\n",
      "Tipo3: Precisión = 93.81%\n",
      "\n",
      "Ninguna clase puede ser reconocida con 100% de precisión usando un perceptrón simple\n",
      "Mejores resultados:\n",
      "  Tipo2: 97.14%\n",
      "  Tipo3: 93.81%\n",
      "  Tipo1: 91.90%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos\n",
    "df = openFile('semillas.csv')\n",
    "print(\"Clases únicas:\", df['Clase'].unique())\n",
    "print(\"Distribución de clases:\")\n",
    "print(df['Clase'].value_counts())\n",
    "\n",
    "# Preparar datos\n",
    "X = df.drop(columns=['Clase']).values\n",
    "y = df['Clase'].values\n",
    "\n",
    "# Normalizar datos\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Entrenar perceptrones para cada clase (One-vs-Rest)\n",
    "clases = df['Clase'].unique()\n",
    "resultados = {}\n",
    "\n",
    "for clase in clases:\n",
    "    print(f\"\\n=== Entrenando perceptrón para detectar '{clase}' ===\")\n",
    "    \n",
    "    # Crear etiquetas binarias: 1 para la clase actual, 0 para las demás\n",
    "    y_binary = (y == clase).astype(int)\n",
    "    \n",
    "    # Entrenar perceptrón\n",
    "    ppn = Perceptron(alpha=0.05, max_iter=200)\n",
    "    ppn.fit(X_scaled, y_binary)\n",
    "    \n",
    "    # Hacer predicciones\n",
    "    y_pred = ppn.predict(X_scaled)\n",
    "    \n",
    "    # Calcular precisión\n",
    "    accuracy = accuracy_score(y_binary, y_pred)\n",
    "    \n",
    "    print(f\"Precisión para '{clase}': {accuracy:.2%}\")\n",
    "    \n",
    "    # Análisis detallado\n",
    "    true_positives = np.sum((y_binary == 1) & (y_pred == 1))\n",
    "    false_positives = np.sum((y_binary == 0) & (y_pred == 1))\n",
    "    false_negatives = np.sum((y_binary == 1) & (y_pred == 0))\n",
    "    true_negatives = np.sum((y_binary == 0) & (y_pred == 0))\n",
    "    \n",
    "    print(f\"Verdaderos positivos: {true_positives}\")\n",
    "    print(f\"Falsos positivos: {false_positives}\")\n",
    "    print(f\"Falsos negativos: {false_negatives}\")\n",
    "    print(f\"Verdaderos negativos: {true_negatives}\")\n",
    "    \n",
    "    # Mostrar ejemplos clasificados correctamente\n",
    "    ejemplos_correctos = df[y_binary == y_pred]\n",
    "    ejemplos_clase_actual = ejemplos_correctos[ejemplos_correctos['Clase'] == clase]\n",
    "    \n",
    "    print(f\"Ejemplos de '{clase}' clasificados correctamente: {len(ejemplos_clase_actual)}\")\n",
    "    print(f\"Total de ejemplos de '{clase}': {np.sum(y == clase)}\")\n",
    "    \n",
    "    resultados[clase] = {\n",
    "        'accuracy': accuracy,\n",
    "        'ejemplos_correctos_clase': len(ejemplos_clase_actual),\n",
    "        'total_clase': np.sum(y == clase),\n",
    "        'perceptron': ppn\n",
    "    }\n",
    "\n",
    "print(\"\\n=== RESUMEN FINAL ===\")\n",
    "for clase, resultado in resultados.items():\n",
    "    print(f\"{clase}: Precisión = {resultado['accuracy']:.2%}\")\n",
    "    if resultado['accuracy'] == 1.0:\n",
    "        print(f\"*** {clase} puede ser reconocido con 100% de precisión ***\")\n",
    "\n",
    "# Encontrar la clase que se puede separar linealmente con 100% de precisión\n",
    "clase_perfecta = None\n",
    "for clase, resultado in resultados.items():\n",
    "    if resultado['accuracy'] == 1.0:\n",
    "        clase_perfecta = clase\n",
    "        break\n",
    "\n",
    "if clase_perfecta:\n",
    "    print(f\"\\nLa semilla que el perceptrón puede reconocer correctamente es: {clase_perfecta}\")\n",
    "else:\n",
    "    print(\"\\nNinguna clase puede ser reconocida con 100% de precisión usando un perceptrón simple\")\n",
    "    print(\"Mejores resultados:\")\n",
    "    for clase, resultado in sorted(resultados.items(), key=lambda x: x[1]['accuracy'], reverse=True):\n",
    "        print(f\"  {clase}: {resultado['accuracy']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdf3faa",
   "metadata": {},
   "source": [
    "En el ejercicio 6 de la práctica 2 se trabajó con los ejemplos del archivo Zoo.csv Indique el valor de verdad de la siguiente afirmación:\n",
    "\n",
    "\n",
    "- Si se normalizan linealmente los ejemplos del archivo Zoo.csv y se selecciona al azar una de las 7 especies, utilizando una velocidad de aprendizaje de 0.05 y un máximo de 200 iteraciones puede entrenarse un perceptrón para que separe correctamente los ejemplos de la clase seleccionada del resto.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58ba45bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aciertos =  101\n",
      "% de aciertos = 100.00 %\n"
     ]
    }
   ],
   "source": [
    "df = openFile('zoo.csv')\n",
    "df = df.drop(columns=[\"animal\"])\n",
    "\n",
    "# Normalizar todas las columnas usando MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "df_normalizado = pd.DataFrame(scaler.fit_transform(df.iloc[:, :-1]), columns=df.columns[:-1])\n",
    "\n",
    "# Mapeo manual y visual de las clases\n",
    "df[\"Clase\"] = df[\"Clase\"].map({\n",
    "    'Mamifero': 0,\n",
    "    'Pez': 1,\n",
    "    'Ave': 2,\n",
    "    'Invertebrado': 3,\n",
    "    'Insecto': 4,\n",
    "    'Anfibio': 5,\n",
    "    'Reptil': 6\n",
    "})\n",
    "\n",
    "X = df_normalizado.values\n",
    "Y = (df[\"Clase\"] == 0).astype(int).values  # 1 Si es Mamifero, 0 en caso contrario\n",
    "\n",
    "ppn = Perceptron(alpha=0.05, max_iter=200)\n",
    "ppn.fit(X, Y)\n",
    "\n",
    "Y_pred = ppn.predict(X)\n",
    "aciertos = sum(Y == Y_pred)  \n",
    "print(\"aciertos = \", aciertos)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*aciertos/X.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4beb81bd",
   "metadata": {},
   "source": [
    "En base a los ejemplos del archivo “automobile-simple.csv” utilizado en el ejercicio 7 de la práctica 2, se ha entrenado un perceptrón capaz de predecir si un auto es ecológico o no. Un auto es considerado ecológico si el valor de “eco-rating” supera la media de dicho atributo. Por simplicidad, se han eliminado los registros que presentan valores faltantes y se ha entrenado el perceptrón utilizando sólo los atributos numéricos de los 197 registros (no se dividió en entrenamiento y testeo). Los ejemplos fueron normalizados utilizando media y desvío.\n",
    "Indique el valor de verdad de la siguiente afirmación:\n",
    "\n",
    "- Es posible entrenar un perceptrón que prediga correctamente si un auto es ecológico o no utilizando únicamente los atributos: “curb-weight”, “engine-size”, “highway-mpg”, “volumen”, con una velocidad de aprendizaje de 0.05 y una cantidad máxima de 100 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "711b59ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aciertos =  203\n",
      "% de aciertos = 99.02 %\n"
     ]
    }
   ],
   "source": [
    "df = openFile('automobile-simple.csv')\n",
    "df = df.drop(columns=[\"fuel-type\", \"make\", \"num-of-doors\", \"body-style\", \"price\", \"horsepower\", \"city-mpg\"])\n",
    "\n",
    "ppn = Perceptron(alpha=0.05, max_iter=100)\n",
    "\n",
    "media_ecologica = df[\"eco-rating\"].mean()\n",
    "df[\"ecological\"] = (df[\"eco-rating\"] >= media_ecologica)*1  # 1 si es ecológica, 0 en caso contrario\n",
    "df = df.drop(columns=[\"eco-rating\"])\n",
    "\n",
    "# Normalizar todas las columnas usando StandardScaler\n",
    "scaler = StandardScaler()\n",
    "df_normalizado = pd.DataFrame(scaler.fit_transform(df.iloc[:, :-1]), columns=df.columns[:-1])\n",
    "\n",
    "X = df_normalizado.values\n",
    "Y = df[\"ecological\"]\n",
    "\n",
    "ppn.fit(X, Y)\n",
    "Y_pred = ppn.predict(X)\n",
    "aciertos = sum(Y == Y_pred)  \n",
    "print(\"aciertos = \", aciertos)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*aciertos/X.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f6a5f1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "aciertos =  23\n",
      "% de aciertos = 95.83 %\n",
      "[1 1 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "df = openFile('lentes.csv')\n",
    "ppn = Perceptron(alpha=0.0005, max_iter=20000)\n",
    "\n",
    "df = df.drop(columns=[\"Id\", \"Prescripcion\"])\n",
    "\n",
    "df[\"Edad\"] = df[\"Edad\"].map({'Joven': 1, 'pre_presb': 2, 'Presbicia': 3})\n",
    "df[\"Astigmatismo\"] = df[\"Astigmatismo\"].map({'SI': 2, 'NO': 1})\n",
    "df[\"Lagrimas\"] = df[\"Lagrimas\"].map({'Normal': 2, 'Reducida': 1})\n",
    "df[\"Diagnostico\"] = df[\"Diagnostico\"].map({'Lentes_Duros': 1, 'Lentes_Blandos': 2, 'No_usar_Lentes': 3})\n",
    "\n",
    "\n",
    "X = df.drop(columns=[\"Diagnostico\"]).values\n",
    "Y = (df[\"Diagnostico\"] == 2)*1  # 1 Si es Lentes_Blandos, 0 en caso contrario\n",
    "Y_diagnostico2 = (Y == 1).sum()\n",
    "print(Y_diagnostico2)\n",
    "\n",
    "ppn.fit(X, Y)\n",
    "Y_pred = ppn.predict(X)\n",
    "\n",
    "aciertos = sum(Y == Y_pred)\n",
    "print(\"aciertos = \", aciertos)\n",
    "print(\"%% de aciertos = %.2f %%\" %(100*aciertos/X.shape[0]))\n",
    "print(Y_pred)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
