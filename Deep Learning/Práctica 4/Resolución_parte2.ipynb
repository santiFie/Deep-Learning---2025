{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f423bd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-12 10:20:10.050172: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2026-01-12 10:20:10.059973: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-12 10:20:10.389963: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2026-01-12 10:20:11.847197: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2026-01-12 10:20:11.849397: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    }
   ],
   "source": [
    "ColabNotebook = 'google.colab' in str(get_ipython())\n",
    "\n",
    "if ColabNotebook:\n",
    "    # monta G-drive en entorno COLAB\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive/')\n",
    "\n",
    "    DATOS_DIR = '/content/drive/MyDrive/Colab Notebooks/DATOS/'  # carpeta donde se encuentran los datasets\n",
    "else:\n",
    "    FUENTES_DIR = '../Fuentes/' # carpeta LOCAL donde se encuentran los scripts\n",
    "    DATOS_DIR   = '../Datos/' # carpeta LOCAL donde se encuentran los datasets\n",
    "\n",
    "import sys\n",
    "sys.path.append(FUENTES_DIR)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chardet\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input, LeakyReLU\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def openFile(nomArch, sep=None):\n",
    "    file = DATOS_DIR + nomArch\n",
    "    #-- detectando la codificación de caracteres usada ----\n",
    "    with open(file, 'rb') as f:\n",
    "        result = chardet.detect(f.read()) \n",
    "    return pd.read_csv(file, encoding=result['encoding'], sep=sep, engine='python') # or readline if the file is large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e5b9da",
   "metadata": {},
   "source": [
    "#### Ejercicio 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d1f7e45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df =  openFile(\"Balance.csv\")\n",
    "\n",
    "X = df.drop(columns=[\"Balance\"]).to_numpy()\n",
    "y = df[\"Balance\"].to_numpy()\n",
    "\n",
    "binariazer = preprocessing.LabelBinarizer()\n",
    "y = binariazer.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Normalizar datos\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b2554e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRADAS: 4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m63\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,003</span> (3.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,003\u001b[0m (3.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,003</span> (3.92 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,003\u001b[0m (3.92 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cantidad de pasadas de los datos\n",
    "EPOCAS = 1000\n",
    "# cantidad de datos a procesar para actualizar pesos\n",
    "TAM_LOTE = X.shape[0] // 20\n",
    "\n",
    "ENTRADAS = X.shape[1]\n",
    "print(\"ENTRADAS:\", ENTRADAS)\n",
    "SALIDAS = len(df[\"Balance\"].unique())\n",
    "\n",
    "ACTIVACION = LeakyReLU()\n",
    "# ACTIVACION = 'ReLU'\n",
    "# ACTIVACION = 'tanh'\n",
    "# ACTIVACION = 'sigmoid'\n",
    "\n",
    "# OPTIMIZADOR = 'sgd'\n",
    "OPTIMIZADOR = 'rmsprop'\n",
    "# OPTIMIZADOR = 'adam'\n",
    "PACIENCIA = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(ENTRADAS,)))\n",
    "model.add(Dense(20, activation=ACTIVACION))\n",
    "model.add(Dense(20, activation=\"tanh\"))\n",
    "model.add(Dense(20, activation=\"tanh\"))\n",
    "model.add(Dense(SALIDAS, activation='softmax'))\n",
    "# model.add(Dense(SALIDAS))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# obtiene la arquitectura para el modelo y lo compila\n",
    "model.compile(optimizer=OPTIMIZADOR, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "be051e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6500 - loss: 0.8486 - val_accuracy: 0.8400 - val_loss: 0.6419\n",
      "Epoch 2/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8250 - loss: 0.6304 - val_accuracy: 0.8700 - val_loss: 0.5161\n",
      "Epoch 3/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8700 - loss: 0.5185 - val_accuracy: 0.8800 - val_loss: 0.4395\n",
      "Epoch 4/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8900 - loss: 0.4411 - val_accuracy: 0.8900 - val_loss: 0.3868\n",
      "Epoch 5/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8950 - loss: 0.3863 - val_accuracy: 0.8900 - val_loss: 0.3508\n",
      "Epoch 6/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.3477 - val_accuracy: 0.8900 - val_loss: 0.3245\n",
      "Epoch 7/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8975 - loss: 0.3172 - val_accuracy: 0.9000 - val_loss: 0.3032\n",
      "Epoch 8/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.2952 - val_accuracy: 0.9000 - val_loss: 0.2871\n",
      "Epoch 9/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9025 - loss: 0.2766 - val_accuracy: 0.9000 - val_loss: 0.2731\n",
      "Epoch 10/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9050 - loss: 0.2621 - val_accuracy: 0.9000 - val_loss: 0.2615\n",
      "Epoch 11/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9050 - loss: 0.2516 - val_accuracy: 0.9000 - val_loss: 0.2519\n",
      "Epoch 12/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9050 - loss: 0.2415 - val_accuracy: 0.9000 - val_loss: 0.2403\n",
      "Epoch 13/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9075 - loss: 0.2335 - val_accuracy: 0.9000 - val_loss: 0.2333\n",
      "Epoch 14/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2251 - val_accuracy: 0.9100 - val_loss: 0.2256\n",
      "Epoch 15/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2174 - val_accuracy: 0.9100 - val_loss: 0.2184\n",
      "Epoch 16/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9175 - loss: 0.2114 - val_accuracy: 0.9000 - val_loss: 0.2117\n",
      "Epoch 17/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9200 - loss: 0.2034 - val_accuracy: 0.9100 - val_loss: 0.2070\n",
      "Epoch 18/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.1988 - val_accuracy: 0.9100 - val_loss: 0.1986\n",
      "Epoch 19/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9225 - loss: 0.1924 - val_accuracy: 0.9100 - val_loss: 0.1912\n",
      "Epoch 20/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9250 - loss: 0.1886 - val_accuracy: 0.9100 - val_loss: 0.1853\n",
      "Epoch 21/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9350 - loss: 0.1828 - val_accuracy: 0.9100 - val_loss: 0.1824\n",
      "Epoch 22/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9275 - loss: 0.1765 - val_accuracy: 0.9100 - val_loss: 0.1750\n",
      "Epoch 23/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1715 - val_accuracy: 0.9100 - val_loss: 0.1690\n",
      "Epoch 24/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9375 - loss: 0.1677 - val_accuracy: 0.9100 - val_loss: 0.1631\n",
      "Epoch 25/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9450 - loss: 0.1625 - val_accuracy: 0.9100 - val_loss: 0.1600\n",
      "Epoch 26/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1573 - val_accuracy: 0.9100 - val_loss: 0.1529\n",
      "Epoch 27/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1538 - val_accuracy: 0.9100 - val_loss: 0.1483\n",
      "Epoch 28/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9450 - loss: 0.1483 - val_accuracy: 0.9100 - val_loss: 0.1450\n",
      "Epoch 29/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9425 - loss: 0.1459 - val_accuracy: 0.9100 - val_loss: 0.1425\n",
      "Epoch 30/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9475 - loss: 0.1387 - val_accuracy: 0.9200 - val_loss: 0.1455\n",
      "Epoch 31/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.1332 - val_accuracy: 0.9200 - val_loss: 0.1336\n",
      "Epoch 32/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9550 - loss: 0.1294 - val_accuracy: 0.9200 - val_loss: 0.1294\n",
      "Epoch 33/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9550 - loss: 0.1273 - val_accuracy: 0.9100 - val_loss: 0.1277\n",
      "Epoch 34/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9500 - loss: 0.1209 - val_accuracy: 0.9200 - val_loss: 0.1301\n",
      "Epoch 35/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9575 - loss: 0.1201 - val_accuracy: 0.9400 - val_loss: 0.1218\n",
      "Epoch 36/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9650 - loss: 0.1129 - val_accuracy: 0.9500 - val_loss: 0.1177\n",
      "Epoch 37/1000\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9725 - loss: 0.1113 - val_accuracy: 0.9700 - val_loss: 0.1139\n",
      "Epoch 38/1000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m42\u001b[39m, shuffle=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Entrena el modelo y guarda la historia del progreso\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m                \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m                \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m                \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mTAM_LOTE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCAS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stop\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m+\u001b[33m'\u001b[39m\u001b[33m-\u001b[39m\u001b[33m'\u001b[39m*\u001b[32m80\u001b[39m)\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mEpocas utilizadas: \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m'\u001b[39m % \u001b[38;5;28mlen\u001b[39m(history.epoch))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:375\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    373\u001b[39m callbacks.on_epoch_begin(epoch)\n\u001b[32m    374\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m epoch_iterator.catch_stop_iteration():\n\u001b[32m--> \u001b[39m\u001b[32m375\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mon_train_batch_begin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbegin_step\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlogs\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:742\u001b[39m, in \u001b[36mTFEpochIterator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    741\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m742\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_epoch_iterator\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/keras/src/trainers/epoch_iterator.py:111\u001b[39m, in \u001b[36mEpochIterator._enumerate_iterator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m steps_per_epoch > \u001b[32m0\u001b[39m:\n\u001b[32m    110\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._current_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.steps_per_epoch \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m111\u001b[39m         \u001b[38;5;28mself\u001b[39m._current_iterator = \u001b[38;5;28;43miter\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    112\u001b[39m         \u001b[38;5;28mself\u001b[39m._steps_seen = \u001b[32m0\u001b[39m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, steps_per_epoch, \u001b[38;5;28mself\u001b[39m.steps_per_execution):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/tensorflow/python/data/ops/dataset_ops.py:501\u001b[39m, in \u001b[36mDatasetV2.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    499\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m context.executing_eagerly() \u001b[38;5;129;01mor\u001b[39;00m ops.inside_function():\n\u001b[32m    500\u001b[39m   \u001b[38;5;28;01mwith\u001b[39;00m ops.colocate_with(\u001b[38;5;28mself\u001b[39m._variant_tensor):\n\u001b[32m--> \u001b[39m\u001b[32m501\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43miterator_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mOwnedIterator\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    503\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33m`tf.data.Dataset` only supports Python-style \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    504\u001b[39m                      \u001b[33m\"\u001b[39m\u001b[33miteration in eager mode or within tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:709\u001b[39m, in \u001b[36mOwnedIterator.__init__\u001b[39m\u001b[34m(self, dataset, components, element_spec)\u001b[39m\n\u001b[32m    705\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m (components \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m element_spec \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    706\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    707\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mWhen `dataset` is provided, `element_spec` and `components` must \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    708\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mnot be specified.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m   \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    711\u001b[39m \u001b[38;5;28mself\u001b[39m._get_next_call_count = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/tensorflow/python/data/ops/iterator_ops.py:748\u001b[39m, in \u001b[36mOwnedIterator._create_iterator\u001b[39m\u001b[34m(self, dataset)\u001b[39m\n\u001b[32m    745\u001b[39m   \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(fulltype.args[\u001b[32m0\u001b[39m].args[\u001b[32m0\u001b[39m].args) == \u001b[38;5;28mlen\u001b[39m(\n\u001b[32m    746\u001b[39m       \u001b[38;5;28mself\u001b[39m._flat_output_types)\n\u001b[32m    747\u001b[39m   \u001b[38;5;28mself\u001b[39m._iterator_resource.op.experimental_set_type(fulltype)\n\u001b[32m--> \u001b[39m\u001b[32m748\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmake_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds_variant\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Cuarto/Deep Learning/mi_entorno/lib/python3.12/site-packages/tensorflow/python/ops/gen_dataset_ops.py:3478\u001b[39m, in \u001b[36mmake_iterator\u001b[39m\u001b[34m(dataset, iterator, name)\u001b[39m\n\u001b[32m   3476\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tld.is_eager:\n\u001b[32m   3477\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3478\u001b[39m     _result = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3479\u001b[39m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mMakeIterator\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3480\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[32m   3481\u001b[39m   \u001b[38;5;28;01mexcept\u001b[39;00m _core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# El parámetro patience indica la cantidad de epocas que deben transcurrir\n",
    "# sin mejoras en el entrenamiento\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=PACIENCIA,\n",
    "                                    restore_best_weights=True\n",
    "                                )\n",
    "\n",
    "# Dividir datos de entrenamiento en entrenamiento y validación\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Entrena el modelo y guarda la historia del progreso\n",
    "history = model.fit(\n",
    "                x = X_train,\n",
    "                y = y_train,\n",
    "                batch_size = TAM_LOTE,\n",
    "                epochs = EPOCAS,\n",
    "                validation_data = (X_val, y_val),\n",
    "                callbacks=[early_stop],\n",
    "            )\n",
    "\n",
    "print('\\n'+'-'*80)\n",
    "print('Epocas utilizadas: %d' % len(history.epoch))\n",
    "\n",
    "# %% Evalua e informa resultado de entrenamiento, validación y testeo\n",
    "# evalua el modelo con los datos de entreanmiento\n",
    "pred = model.evaluate(X_train, y_train, verbose=False)\n",
    "print('\\nEfectividad del modelo con datos de entrenamiento para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (pred[0]))\n",
    "\n",
    "# evalua el modelo con los datos de validacion\n",
    "pred = model.evaluate(X_val, y_val, verbose=False)\n",
    "print('\\nEfectividad del modelo con datos de validacion para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12958eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efectividad del modelo con datos de testeo para:\n",
      " - Accuracy:  96.80%\n",
      " - Pérdida :   0.05529\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.evaluate(X_test, y_test, verbose=False)\n",
    "print('\\nEfectividad del modelo con datos de testeo para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (y_pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (y_pred[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe270383",
   "metadata": {},
   "source": [
    "#### Ejercicio 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680295f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = openFile('Iris.csv')\n",
    "\n",
    "X = df.drop(columns=[\"class\"]).to_numpy()\n",
    "y = df[\"class\"].to_numpy()\n",
    "\n",
    "# -----------  Normalizar datos  -----------\n",
    "y_encoder = preprocessing.LabelEncoder()\n",
    "y = y_encoder.fit_transform(y)\n",
    "# print(y)\n",
    "\n",
    "y_norm = tf.keras.utils.to_categorical(y)\n",
    "# print(y_binariazer)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_norm, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fcfb32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">210</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">55</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │           \u001b[38;5;34m210\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_22 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m)              │            \u001b[38;5;34m55\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_23 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m18\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">383</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m383\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">383</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m383\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cantidad de pasadas de los datos\n",
    "EPOCAS = 1000\n",
    "\n",
    "# cantidad de datos a procesar para actualizar pesos\n",
    "TAM_LOTE = X.shape[0] // 20\n",
    "\n",
    "ENTRADAS = X.shape[1]\n",
    "SALIDAS = len(df[\"class\"].unique())\n",
    "\n",
    "ACTIVACION = LeakyReLU()\n",
    "# ACTIVACION = 'ReLU'\n",
    "# ACTIVACION = 'tanh'\n",
    "# ACTIVACION = 'sigmoid'\n",
    "\n",
    "# OPTIMIZADOR = 'sgd'\n",
    "OPTIMIZADOR = 'rmsprop'\n",
    "# OPTIMIZADOR = 'adam'\n",
    "PACIENCIA = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(ENTRADAS,)))\n",
    "model.add(Dense(20, activation=ACTIVACION))\n",
    "model.add(Dense(10, activation=\"tanh\"))\n",
    "model.add(Dense(5, activation=\"tanh\"))\n",
    "model.add(Dense(SALIDAS, activation='softmax'))\n",
    "# model.add(Dense(SALIDAS))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# obtiene la arquitectura para el modelo y lo compila\n",
    "model.compile(optimizer=OPTIMIZADOR, loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7921d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.3125 - loss: 1.1862 - val_accuracy: 0.1667 - val_loss: 1.3409\n",
      "Epoch 2/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3854 - loss: 1.0590 - val_accuracy: 0.2083 - val_loss: 1.2364\n",
      "Epoch 3/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4792 - loss: 0.9619 - val_accuracy: 0.3333 - val_loss: 1.1429\n",
      "Epoch 4/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5938 - loss: 0.8757 - val_accuracy: 0.3333 - val_loss: 1.0596\n",
      "Epoch 5/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6458 - loss: 0.7971 - val_accuracy: 0.4167 - val_loss: 0.9811\n",
      "Epoch 6/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6771 - loss: 0.7296 - val_accuracy: 0.5000 - val_loss: 0.9155\n",
      "Epoch 7/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7292 - loss: 0.6708 - val_accuracy: 0.6250 - val_loss: 0.8561\n",
      "Epoch 8/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7500 - loss: 0.6179 - val_accuracy: 0.6667 - val_loss: 0.8033\n",
      "Epoch 9/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7604 - loss: 0.5728 - val_accuracy: 0.6667 - val_loss: 0.7568\n",
      "Epoch 10/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7917 - loss: 0.5350 - val_accuracy: 0.7083 - val_loss: 0.7170\n",
      "Epoch 11/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.5038 - val_accuracy: 0.7083 - val_loss: 0.6809\n",
      "Epoch 12/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8021 - loss: 0.4771 - val_accuracy: 0.7083 - val_loss: 0.6505\n",
      "Epoch 13/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7917 - loss: 0.4536 - val_accuracy: 0.7083 - val_loss: 0.6214\n",
      "Epoch 14/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8021 - loss: 0.4331 - val_accuracy: 0.7083 - val_loss: 0.5967\n",
      "Epoch 15/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.4146 - val_accuracy: 0.7083 - val_loss: 0.5742\n",
      "Epoch 16/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3997 - val_accuracy: 0.7083 - val_loss: 0.5539\n",
      "Epoch 17/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3855 - val_accuracy: 0.7083 - val_loss: 0.5344\n",
      "Epoch 18/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.3734 - val_accuracy: 0.7500 - val_loss: 0.5159\n",
      "Epoch 19/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3620 - val_accuracy: 0.7500 - val_loss: 0.5021\n",
      "Epoch 20/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.3516 - val_accuracy: 0.7500 - val_loss: 0.4854\n",
      "Epoch 21/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8229 - loss: 0.3422 - val_accuracy: 0.7500 - val_loss: 0.4724\n",
      "Epoch 22/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.3330 - val_accuracy: 0.7500 - val_loss: 0.4605\n",
      "Epoch 23/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8333 - loss: 0.3255 - val_accuracy: 0.7500 - val_loss: 0.4499\n",
      "Epoch 24/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3180 - val_accuracy: 0.7500 - val_loss: 0.4421\n",
      "Epoch 25/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3110 - val_accuracy: 0.7500 - val_loss: 0.4322\n",
      "Epoch 26/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.3048 - val_accuracy: 0.7500 - val_loss: 0.4219\n",
      "Epoch 27/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.2990 - val_accuracy: 0.7500 - val_loss: 0.4140\n",
      "Epoch 28/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8438 - loss: 0.2939 - val_accuracy: 0.7500 - val_loss: 0.4073\n",
      "Epoch 29/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.2889 - val_accuracy: 0.7500 - val_loss: 0.4018\n",
      "Epoch 30/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.2838 - val_accuracy: 0.7500 - val_loss: 0.3956\n",
      "Epoch 31/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.2791 - val_accuracy: 0.7500 - val_loss: 0.3889\n",
      "Epoch 32/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8542 - loss: 0.2746 - val_accuracy: 0.7500 - val_loss: 0.3838\n",
      "Epoch 33/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8646 - loss: 0.2703 - val_accuracy: 0.7500 - val_loss: 0.3799\n",
      "Epoch 34/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2658 - val_accuracy: 0.7917 - val_loss: 0.3728\n",
      "Epoch 35/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2609 - val_accuracy: 0.7917 - val_loss: 0.3664\n",
      "Epoch 36/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2568 - val_accuracy: 0.7917 - val_loss: 0.3622\n",
      "Epoch 37/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2532 - val_accuracy: 0.7917 - val_loss: 0.3584\n",
      "Epoch 38/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.2489 - val_accuracy: 0.8333 - val_loss: 0.3525\n",
      "Epoch 39/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8854 - loss: 0.2454 - val_accuracy: 0.8333 - val_loss: 0.3488\n",
      "Epoch 40/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2418 - val_accuracy: 0.8333 - val_loss: 0.3448\n",
      "Epoch 41/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2378 - val_accuracy: 0.8333 - val_loss: 0.3420\n",
      "Epoch 42/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2345 - val_accuracy: 0.8333 - val_loss: 0.3385\n",
      "Epoch 43/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8958 - loss: 0.2301 - val_accuracy: 0.8333 - val_loss: 0.3324\n",
      "Epoch 44/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.2276 - val_accuracy: 0.8333 - val_loss: 0.3297\n",
      "Epoch 45/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2235 - val_accuracy: 0.8333 - val_loss: 0.3271\n",
      "Epoch 46/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9271 - loss: 0.2198 - val_accuracy: 0.8333 - val_loss: 0.3224\n",
      "Epoch 47/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2165 - val_accuracy: 0.8333 - val_loss: 0.3180\n",
      "Epoch 48/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.2132 - val_accuracy: 0.8333 - val_loss: 0.3160\n",
      "Epoch 49/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.2099 - val_accuracy: 0.8333 - val_loss: 0.3141\n",
      "Epoch 50/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.2069 - val_accuracy: 0.7917 - val_loss: 0.3132\n",
      "Epoch 51/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.2038 - val_accuracy: 0.8333 - val_loss: 0.3086\n",
      "Epoch 52/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9375 - loss: 0.2003 - val_accuracy: 0.7917 - val_loss: 0.3067\n",
      "Epoch 53/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.1967 - val_accuracy: 0.8750 - val_loss: 0.3027\n",
      "Epoch 54/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.1940 - val_accuracy: 0.8750 - val_loss: 0.2994\n",
      "Epoch 55/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1905 - val_accuracy: 0.8750 - val_loss: 0.2951\n",
      "Epoch 56/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9479 - loss: 0.1879 - val_accuracy: 0.8750 - val_loss: 0.2936\n",
      "Epoch 57/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1850 - val_accuracy: 0.8750 - val_loss: 0.2910\n",
      "Epoch 58/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1821 - val_accuracy: 0.8750 - val_loss: 0.2886\n",
      "Epoch 59/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1791 - val_accuracy: 0.8750 - val_loss: 0.2858\n",
      "Epoch 60/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1757 - val_accuracy: 0.8333 - val_loss: 0.2830\n",
      "Epoch 61/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1728 - val_accuracy: 0.8750 - val_loss: 0.2794\n",
      "Epoch 62/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1702 - val_accuracy: 0.8333 - val_loss: 0.2792\n",
      "Epoch 63/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1674 - val_accuracy: 0.8333 - val_loss: 0.2776\n",
      "Epoch 64/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9583 - loss: 0.1650 - val_accuracy: 0.8333 - val_loss: 0.2745\n",
      "Epoch 65/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1621 - val_accuracy: 0.8333 - val_loss: 0.2740\n",
      "Epoch 66/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9688 - loss: 0.1614 - val_accuracy: 0.8333 - val_loss: 0.2725\n",
      "Epoch 67/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1576 - val_accuracy: 0.8333 - val_loss: 0.2706\n",
      "Epoch 68/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1557 - val_accuracy: 0.8333 - val_loss: 0.2681\n",
      "Epoch 69/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1531 - val_accuracy: 0.8333 - val_loss: 0.2630\n",
      "Epoch 70/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1507 - val_accuracy: 0.8333 - val_loss: 0.2613\n",
      "Epoch 71/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1481 - val_accuracy: 0.8333 - val_loss: 0.2619\n",
      "Epoch 72/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1463 - val_accuracy: 0.8333 - val_loss: 0.2605\n",
      "Epoch 73/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1440 - val_accuracy: 0.8750 - val_loss: 0.2574\n",
      "Epoch 74/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1413 - val_accuracy: 0.8750 - val_loss: 0.2543\n",
      "Epoch 75/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1393 - val_accuracy: 0.8750 - val_loss: 0.2527\n",
      "Epoch 76/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1375 - val_accuracy: 0.8750 - val_loss: 0.2522\n",
      "Epoch 77/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1349 - val_accuracy: 0.8750 - val_loss: 0.2483\n",
      "Epoch 78/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1325 - val_accuracy: 0.8750 - val_loss: 0.2488\n",
      "Epoch 79/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1313 - val_accuracy: 0.8750 - val_loss: 0.2449\n",
      "Epoch 80/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1288 - val_accuracy: 0.8750 - val_loss: 0.2430\n",
      "Epoch 81/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1268 - val_accuracy: 0.8750 - val_loss: 0.2385\n",
      "Epoch 82/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1243 - val_accuracy: 0.8750 - val_loss: 0.2331\n",
      "Epoch 83/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1227 - val_accuracy: 0.8750 - val_loss: 0.2345\n",
      "Epoch 84/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1208 - val_accuracy: 0.8750 - val_loss: 0.2334\n",
      "Epoch 85/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1184 - val_accuracy: 0.8750 - val_loss: 0.2335\n",
      "Epoch 86/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1170 - val_accuracy: 0.8750 - val_loss: 0.2319\n",
      "Epoch 87/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1151 - val_accuracy: 0.8750 - val_loss: 0.2304\n",
      "Epoch 88/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1132 - val_accuracy: 0.8750 - val_loss: 0.2303\n",
      "Epoch 89/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1117 - val_accuracy: 0.8750 - val_loss: 0.2302\n",
      "Epoch 90/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1099 - val_accuracy: 0.8750 - val_loss: 0.2286\n",
      "Epoch 91/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1086 - val_accuracy: 0.8750 - val_loss: 0.2266\n",
      "Epoch 92/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1070 - val_accuracy: 0.8750 - val_loss: 0.2256\n",
      "Epoch 93/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1056 - val_accuracy: 0.8750 - val_loss: 0.2242\n",
      "Epoch 94/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1038 - val_accuracy: 0.8750 - val_loss: 0.2252\n",
      "Epoch 95/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1028 - val_accuracy: 0.8750 - val_loss: 0.2237\n",
      "Epoch 96/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1012 - val_accuracy: 0.8750 - val_loss: 0.2210\n",
      "Epoch 97/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.1002 - val_accuracy: 0.8750 - val_loss: 0.2197\n",
      "Epoch 98/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0987 - val_accuracy: 0.8750 - val_loss: 0.2168\n",
      "Epoch 99/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0975 - val_accuracy: 0.8750 - val_loss: 0.2164\n",
      "Epoch 100/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0960 - val_accuracy: 0.8750 - val_loss: 0.2155\n",
      "Epoch 101/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0949 - val_accuracy: 0.8750 - val_loss: 0.2152\n",
      "Epoch 102/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0940 - val_accuracy: 0.8750 - val_loss: 0.2143\n",
      "Epoch 103/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0922 - val_accuracy: 0.8750 - val_loss: 0.2143\n",
      "Epoch 104/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0911 - val_accuracy: 0.8750 - val_loss: 0.2151\n",
      "Epoch 105/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0901 - val_accuracy: 0.8750 - val_loss: 0.2135\n",
      "Epoch 106/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0891 - val_accuracy: 0.8750 - val_loss: 0.2114\n",
      "Epoch 107/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0878 - val_accuracy: 0.8750 - val_loss: 0.2086\n",
      "Epoch 108/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0867 - val_accuracy: 0.8750 - val_loss: 0.2074\n",
      "Epoch 109/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0856 - val_accuracy: 0.8750 - val_loss: 0.2091\n",
      "Epoch 110/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0848 - val_accuracy: 0.8750 - val_loss: 0.2097\n",
      "Epoch 111/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0839 - val_accuracy: 0.8750 - val_loss: 0.2078\n",
      "Epoch 112/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0828 - val_accuracy: 0.8750 - val_loss: 0.2064\n",
      "Epoch 113/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0819 - val_accuracy: 0.8750 - val_loss: 0.2070\n",
      "Epoch 114/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0811 - val_accuracy: 0.8750 - val_loss: 0.2080\n",
      "Epoch 115/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0801 - val_accuracy: 0.8750 - val_loss: 0.2056\n",
      "Epoch 116/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0793 - val_accuracy: 0.8750 - val_loss: 0.2052\n",
      "Epoch 117/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0786 - val_accuracy: 0.8750 - val_loss: 0.2061\n",
      "Epoch 118/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0776 - val_accuracy: 0.8750 - val_loss: 0.2035\n",
      "Epoch 119/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0767 - val_accuracy: 0.8750 - val_loss: 0.2043\n",
      "Epoch 120/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0762 - val_accuracy: 0.8750 - val_loss: 0.2035\n",
      "Epoch 121/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0751 - val_accuracy: 0.8750 - val_loss: 0.1990\n",
      "Epoch 122/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0742 - val_accuracy: 0.8750 - val_loss: 0.2009\n",
      "Epoch 123/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0738 - val_accuracy: 0.8750 - val_loss: 0.2020\n",
      "Epoch 124/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0725 - val_accuracy: 0.8750 - val_loss: 0.2005\n",
      "Epoch 125/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0721 - val_accuracy: 0.8750 - val_loss: 0.2033\n",
      "Epoch 126/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0714 - val_accuracy: 0.8750 - val_loss: 0.2016\n",
      "Epoch 127/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0702 - val_accuracy: 0.8750 - val_loss: 0.1986\n",
      "Epoch 128/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0701 - val_accuracy: 0.8750 - val_loss: 0.1963\n",
      "Epoch 129/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0691 - val_accuracy: 0.8750 - val_loss: 0.1974\n",
      "Epoch 130/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0685 - val_accuracy: 0.8750 - val_loss: 0.1978\n",
      "Epoch 131/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0675 - val_accuracy: 0.8750 - val_loss: 0.2021\n",
      "Epoch 132/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0670 - val_accuracy: 0.8750 - val_loss: 0.2031\n",
      "Epoch 133/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0663 - val_accuracy: 0.8750 - val_loss: 0.2022\n",
      "Epoch 134/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0661 - val_accuracy: 0.8750 - val_loss: 0.1994\n",
      "Epoch 135/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0648 - val_accuracy: 0.8750 - val_loss: 0.2010\n",
      "Epoch 136/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0646 - val_accuracy: 0.8750 - val_loss: 0.1988\n",
      "Epoch 137/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0640 - val_accuracy: 0.8750 - val_loss: 0.2005\n",
      "Epoch 138/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0629 - val_accuracy: 0.8750 - val_loss: 0.1970\n",
      "Epoch 139/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0629 - val_accuracy: 0.8750 - val_loss: 0.1972\n",
      "Epoch 140/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0623 - val_accuracy: 0.8750 - val_loss: 0.1961\n",
      "Epoch 141/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0613 - val_accuracy: 0.8750 - val_loss: 0.1950\n",
      "Epoch 142/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0608 - val_accuracy: 0.8750 - val_loss: 0.1964\n",
      "Epoch 143/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0604 - val_accuracy: 0.8750 - val_loss: 0.1948\n",
      "Epoch 144/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0601 - val_accuracy: 0.8750 - val_loss: 0.1993\n",
      "Epoch 145/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0597 - val_accuracy: 0.8750 - val_loss: 0.1994\n",
      "Epoch 146/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0588 - val_accuracy: 0.8750 - val_loss: 0.1984\n",
      "Epoch 147/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9792 - loss: 0.0588 - val_accuracy: 0.8750 - val_loss: 0.2017\n",
      "Epoch 148/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0580 - val_accuracy: 0.8750 - val_loss: 0.2013\n",
      "Epoch 149/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9792 - loss: 0.0576 - val_accuracy: 0.8750 - val_loss: 0.2026\n",
      "Epoch 150/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0573 - val_accuracy: 0.8750 - val_loss: 0.2003\n",
      "Epoch 151/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0564 - val_accuracy: 0.8750 - val_loss: 0.2028\n",
      "Epoch 152/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0565 - val_accuracy: 0.8750 - val_loss: 0.2001\n",
      "Epoch 153/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0554 - val_accuracy: 0.8750 - val_loss: 0.1967\n",
      "Epoch 154/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0556 - val_accuracy: 0.8750 - val_loss: 0.1961\n",
      "Epoch 155/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0554 - val_accuracy: 0.8750 - val_loss: 0.1995\n",
      "Epoch 156/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0543 - val_accuracy: 0.8750 - val_loss: 0.1998\n",
      "Epoch 157/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0538 - val_accuracy: 0.8750 - val_loss: 0.1979\n",
      "Epoch 158/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0535 - val_accuracy: 0.8750 - val_loss: 0.2019\n",
      "Epoch 159/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0530 - val_accuracy: 0.8750 - val_loss: 0.1971\n",
      "Epoch 160/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0534 - val_accuracy: 0.8750 - val_loss: 0.1975\n",
      "Epoch 161/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0519 - val_accuracy: 0.8750 - val_loss: 0.1977\n",
      "Epoch 162/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0522 - val_accuracy: 0.8750 - val_loss: 0.1988\n",
      "Epoch 163/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9792 - loss: 0.0515 - val_accuracy: 0.8750 - val_loss: 0.2000\n",
      "Epoch 164/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0519 - val_accuracy: 0.8750 - val_loss: 0.2016\n",
      "Epoch 165/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0509 - val_accuracy: 0.8750 - val_loss: 0.2000\n",
      "Epoch 166/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0510 - val_accuracy: 0.8750 - val_loss: 0.2011\n",
      "Epoch 167/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0501 - val_accuracy: 0.8750 - val_loss: 0.1962\n",
      "Epoch 168/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0511 - val_accuracy: 0.8750 - val_loss: 0.2031\n",
      "Epoch 169/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9792 - loss: 0.0496 - val_accuracy: 0.8750 - val_loss: 0.2035\n",
      "Epoch 170/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0495 - val_accuracy: 0.8750 - val_loss: 0.2004\n",
      "Epoch 171/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0490 - val_accuracy: 0.9167 - val_loss: 0.1973\n",
      "Epoch 172/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0488 - val_accuracy: 0.9167 - val_loss: 0.2011\n",
      "Epoch 173/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0486 - val_accuracy: 0.9167 - val_loss: 0.2025\n",
      "Epoch 174/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0480 - val_accuracy: 0.9167 - val_loss: 0.2071\n",
      "Epoch 175/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0480 - val_accuracy: 0.9167 - val_loss: 0.2004\n",
      "Epoch 176/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0477 - val_accuracy: 0.9167 - val_loss: 0.2033\n",
      "Epoch 177/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0472 - val_accuracy: 0.9167 - val_loss: 0.2045\n",
      "Epoch 178/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0476 - val_accuracy: 0.9167 - val_loss: 0.2025\n",
      "Epoch 179/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0467 - val_accuracy: 0.9167 - val_loss: 0.2031\n",
      "Epoch 180/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0466 - val_accuracy: 0.9167 - val_loss: 0.2067\n",
      "Epoch 181/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0462 - val_accuracy: 0.9167 - val_loss: 0.2057\n",
      "Epoch 182/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0461 - val_accuracy: 0.9167 - val_loss: 0.2074\n",
      "Epoch 183/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0457 - val_accuracy: 0.9167 - val_loss: 0.2105\n",
      "Epoch 184/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0460 - val_accuracy: 0.9167 - val_loss: 0.2074\n",
      "Epoch 185/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0453 - val_accuracy: 0.9167 - val_loss: 0.2061\n",
      "Epoch 186/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0447 - val_accuracy: 0.9167 - val_loss: 0.2034\n",
      "Epoch 187/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0447 - val_accuracy: 0.9167 - val_loss: 0.1983\n",
      "Epoch 188/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0442 - val_accuracy: 0.9167 - val_loss: 0.2011\n",
      "Epoch 189/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0443 - val_accuracy: 0.9167 - val_loss: 0.2057\n",
      "Epoch 190/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0439 - val_accuracy: 0.9167 - val_loss: 0.2062\n",
      "Epoch 191/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0438 - val_accuracy: 0.9167 - val_loss: 0.2047\n",
      "Epoch 192/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0435 - val_accuracy: 0.9167 - val_loss: 0.2049\n",
      "Epoch 193/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0431 - val_accuracy: 0.9167 - val_loss: 0.2080\n",
      "Epoch 194/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0430 - val_accuracy: 0.9167 - val_loss: 0.2073\n",
      "Epoch 195/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0427 - val_accuracy: 0.9167 - val_loss: 0.2024\n",
      "Epoch 196/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9896 - loss: 0.0421 - val_accuracy: 0.9167 - val_loss: 0.2053\n",
      "Epoch 197/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0424 - val_accuracy: 0.9167 - val_loss: 0.2063\n",
      "Epoch 198/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0420 - val_accuracy: 0.9167 - val_loss: 0.2055\n",
      "Epoch 199/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0414 - val_accuracy: 0.9167 - val_loss: 0.2050\n",
      "Epoch 200/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0414 - val_accuracy: 0.9167 - val_loss: 0.2082\n",
      "Epoch 201/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0416 - val_accuracy: 0.9167 - val_loss: 0.2078\n",
      "Epoch 202/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0413 - val_accuracy: 0.9167 - val_loss: 0.2092\n",
      "Epoch 203/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0410 - val_accuracy: 0.9167 - val_loss: 0.2083\n",
      "Epoch 204/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0406 - val_accuracy: 0.9167 - val_loss: 0.2072\n",
      "Epoch 205/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0403 - val_accuracy: 0.9167 - val_loss: 0.2074\n",
      "Epoch 206/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0404 - val_accuracy: 0.9167 - val_loss: 0.2065\n",
      "Epoch 207/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0395 - val_accuracy: 0.9167 - val_loss: 0.2058\n",
      "Epoch 208/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0398 - val_accuracy: 0.9167 - val_loss: 0.2021\n",
      "Epoch 209/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0394 - val_accuracy: 0.9167 - val_loss: 0.2035\n",
      "Epoch 210/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0397 - val_accuracy: 0.9167 - val_loss: 0.2079\n",
      "Epoch 211/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9896 - loss: 0.0390 - val_accuracy: 0.9167 - val_loss: 0.2113\n",
      "Epoch 212/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0390 - val_accuracy: 0.9167 - val_loss: 0.2095\n",
      "Epoch 213/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9896 - loss: 0.0393 - val_accuracy: 0.9167 - val_loss: 0.2129\n",
      "Epoch 214/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0388 - val_accuracy: 0.9167 - val_loss: 0.2084\n",
      "Epoch 215/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0381 - val_accuracy: 0.9167 - val_loss: 0.2141\n",
      "Epoch 216/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0384 - val_accuracy: 0.9167 - val_loss: 0.2143\n",
      "Epoch 217/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0381 - val_accuracy: 0.9167 - val_loss: 0.2184\n",
      "Epoch 218/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0381 - val_accuracy: 0.9167 - val_loss: 0.2188\n",
      "Epoch 219/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0379 - val_accuracy: 0.9167 - val_loss: 0.2181\n",
      "Epoch 220/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0374 - val_accuracy: 0.9167 - val_loss: 0.2141\n",
      "Epoch 221/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0375 - val_accuracy: 0.9167 - val_loss: 0.2153\n",
      "Epoch 222/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0375 - val_accuracy: 0.9167 - val_loss: 0.2121\n",
      "Epoch 223/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0377 - val_accuracy: 0.9167 - val_loss: 0.2169\n",
      "Epoch 224/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0369 - val_accuracy: 0.9167 - val_loss: 0.2131\n",
      "Epoch 225/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0371 - val_accuracy: 0.9167 - val_loss: 0.2114\n",
      "Epoch 226/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0366 - val_accuracy: 0.9167 - val_loss: 0.2114\n",
      "Epoch 227/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0366 - val_accuracy: 0.9167 - val_loss: 0.2090\n",
      "Epoch 228/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0363 - val_accuracy: 0.9167 - val_loss: 0.2101\n",
      "Epoch 229/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0358 - val_accuracy: 0.9167 - val_loss: 0.2115\n",
      "Epoch 230/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0362 - val_accuracy: 0.9167 - val_loss: 0.2116\n",
      "Epoch 231/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0358 - val_accuracy: 0.9167 - val_loss: 0.2135\n",
      "Epoch 232/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0352 - val_accuracy: 0.9167 - val_loss: 0.2105\n",
      "Epoch 233/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0356 - val_accuracy: 0.9167 - val_loss: 0.2127\n",
      "Epoch 234/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0356 - val_accuracy: 0.9167 - val_loss: 0.2112\n",
      "Epoch 235/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9896 - loss: 0.0352 - val_accuracy: 0.9167 - val_loss: 0.2152\n",
      "Epoch 236/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0347 - val_accuracy: 0.9167 - val_loss: 0.2175\n",
      "Epoch 237/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0350 - val_accuracy: 0.9167 - val_loss: 0.2157\n",
      "Epoch 238/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0346 - val_accuracy: 0.9167 - val_loss: 0.2129\n",
      "Epoch 239/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0349 - val_accuracy: 0.9167 - val_loss: 0.2145\n",
      "Epoch 240/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9896 - loss: 0.0343 - val_accuracy: 0.9167 - val_loss: 0.2144\n",
      "Epoch 241/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0346 - val_accuracy: 0.9167 - val_loss: 0.2159\n",
      "Epoch 242/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0341 - val_accuracy: 0.9167 - val_loss: 0.2133\n",
      "Epoch 243/1000\n",
      "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0338 - val_accuracy: 0.9167 - val_loss: 0.2144\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "Epocas utilizadas: 243\n",
      "\n",
      "Efectividad del modelo con datos de entrenamiento para:\n",
      " - Accuracy:  97.92%\n",
      " - Pérdida :   0.05907\n",
      "\n",
      "Efectividad del modelo con datos de validacion para:\n",
      " - Accuracy:  87.50%\n",
      " - Pérdida :   0.19483\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Entrena el modelo y guarda la historia del progreso\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=PACIENCIA,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Entrena el modelo y guarda la historia del progreso\n",
    "history = model.fit(X_train, y_train, validation_data=(\n",
    "    X_val, y_val), epochs=EPOCAS, batch_size=TAM_LOTE, callbacks=[early_stop])\n",
    "\n",
    "print('\\n'+'-'*80)\n",
    "print('Epocas utilizadas: %d' % len(history.epoch))\n",
    "\n",
    "# %% Evalua e informa resultado de entrenamiento, validación y testeo\n",
    "# evalua el modelo con los datos de entreanmiento\n",
    "train_pred = model.evaluate(X_train, y_train, verbose=False)\n",
    "print('\\nEfectividad del modelo con datos de entrenamiento para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (train_pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (train_pred[0]))\n",
    "\n",
    "# evalua el modelo con los datos de validacion\n",
    "val_pred = model.evaluate(X_val, y_val, verbose=False)\n",
    "print('\\nEfectividad del modelo con datos de validacion para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (val_pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (val_pred[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ecb40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Efectividad del modelo con datos de testeo para:\n",
      " - Accuracy:  96.67%\n",
      " - Pérdida :   0.08761\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.evaluate(X_test, y_test, verbose=False)\n",
    "print('\\nEfectividad del modelo con datos de testeo para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (y_pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (y_pred[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7665bce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step \n",
      "['Iris-versicolor' 'Iris-setosa' 'Iris-virginica' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-setosa' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-virginica' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-virginica' 'Iris-versicolor' 'Iris-versicolor' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-virginica' 'Iris-setosa' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-setosa' 'Iris-setosa']\n",
      "Efectividad test:  96.67%\n",
      "Efectividad train:  97.92%\n"
     ]
    }
   ],
   "source": [
    "# Cálculo manual de métricas\n",
    "# Obtener las probabilidades predichas por el modelo\n",
    "y_test_pred_probs = model.predict(X_test)\n",
    "y_train_pred_probs = model.predict(X_train)\n",
    "\n",
    "# Convertir las probabilidades a índices de clase\n",
    "y_test_pred_indices = np.argmax(y_test_pred_probs, axis=1)\n",
    "y_train_pred_indices = np.argmax(y_train_pred_probs, axis=1)\n",
    "\n",
    "# Transformar los índices a etiquetas originales\n",
    "y_test_pred_transformado = y_encoder.inverse_transform(y_test_pred_indices)\n",
    "y_train_pred_transformado = y_encoder.inverse_transform(y_train_pred_indices)\n",
    "print(y_test_pred_transformado)\n",
    "\n",
    "# Si quieres calcular la efectividad manualmente:\n",
    "y_test_true_indices = np.argmax(y_test, axis=1)\n",
    "y_train_true_indices = np.argmax(y_train, axis=1)\n",
    "y_test_true_transformado = y_encoder.inverse_transform(y_test_true_indices)\n",
    "y_train_true_transformado = y_encoder.inverse_transform(y_train_true_indices)\n",
    "\n",
    "print('Efectividad test: %6.2f%%' % (100 * (y_test_pred_transformado == y_test_true_transformado).sum() / len(y_test_true_transformado)))\n",
    "print('Efectividad train: %6.2f%%' % (100 * (y_train_pred_transformado == y_train_true_transformado).sum() / len(y_train_true_transformado)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6b1ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcular_metricas(conf_mat):\n",
    "    precision = np.zeros(conf_mat.shape[0])\n",
    "    for i in range(0, len(conf_mat)):\n",
    "        precision[i] = conf_mat[i][i]/sum(conf_mat.T[i])\n",
    "\n",
    "    recall = np.zeros(conf_mat.shape[0])\n",
    "    for i in range(0, len(conf_mat)):\n",
    "        recall[i] = conf_mat[i][i]/sum(conf_mat[i])\n",
    "\n",
    "    f1_score = 2* (precision*recall) /(precision+recall)\n",
    "\n",
    "    accuracy =  0\n",
    "    for i in range(0, len(conf_mat)):\n",
    "        accuracy+=conf_mat[i][i]\n",
    "    accuracy/= conf_mat.sum()\n",
    "\n",
    "    return ( precision, recall, f1_score, accuracy )\n",
    "\n",
    "# el parámetro metricas es una tupla ( precision, recall, f1_score, accuracy )\n",
    "def imprimir_metricas( metricas ):\n",
    "    (precision, recall, f1_score, accuracy) = metricas\n",
    "    print('\\n clase   precision    recall    f1-score')\n",
    "    for i in range(0, len(precision)):\n",
    "        print('%5d %10.2f %10.2f %10.2f' % (i, precision[i], recall[i], f1_score[i]))\n",
    "    print('\\naccuracy: %6.2f\\n' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9f415",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " clase   precision    recall    f1-score\n",
      "    0       1.00       1.00       1.00\n",
      "    1       1.00       0.89       0.94\n",
      "    2       0.92       1.00       0.96\n",
      "\n",
      "accuracy:   0.97\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conf_mat_test = tf.math.confusion_matrix(y_test_true_indices, y_test_pred_indices).numpy()\n",
    "\n",
    "metricas = calcular_metricas(conf_mat_test)\n",
    "imprimir_metricas(metricas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7cd95c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 precision    recall  f1-score   support\n",
      "\n",
      "    Iris-setosa       1.00      1.00      1.00        10\n",
      "Iris-versicolor       1.00      0.89      0.94         9\n",
      " Iris-virginica       0.92      1.00      0.96        11\n",
      "\n",
      "       accuracy                           0.97        30\n",
      "      macro avg       0.97      0.96      0.97        30\n",
      "   weighted avg       0.97      0.97      0.97        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_true_transformado, y_test_pred_transformado, zero_division=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5125a5f",
   "metadata": {},
   "source": [
    "#### Ejercicio 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "786ecc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = openFile('autos.csv')\n",
    "\n",
    "# Elimina filas con valores faltantes en la columna 'price'\n",
    "df = df[df['price'] != '?']\n",
    "\n",
    "df.replace('?', np.nan, inplace=True)\n",
    "\n",
    "#-- seleccionar los atributos numéricos --\n",
    "df[\"normalized-losses\"] = pd.to_numeric(df[\"normalized-losses\"], errors='coerce')\n",
    "df[\"bore\"] = pd.to_numeric(df[\"bore\"], errors='coerce')\n",
    "df[\"stroke\"] = pd.to_numeric(df[\"stroke\"], errors='coerce')\n",
    "df[\"horsepower\"] = pd.to_numeric(df[\"horsepower\"], errors='coerce')\n",
    "df[\"peak-rpm\"] = pd.to_numeric(df[\"peak-rpm\"], errors='coerce')\n",
    "df[\"price\"] = pd.to_numeric(df[\"price\"], errors='coerce')\n",
    "\n",
    "df = df.select_dtypes(include = [\"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"])\n",
    "\n",
    "values = {\n",
    "    'normalized-losses': df['normalized-losses'].mean(),\n",
    "          'bore': df['bore'].mean(),\n",
    "            'stroke': df['stroke'].mean(),\n",
    "            'horsepower': df['horsepower'].mean(),\n",
    "            'peak-rpm': df['peak-rpm'].mean(),\n",
    "}\n",
    "\n",
    "df = df.fillna(value=values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd4938c",
   "metadata": {},
   "source": [
    "Predicción del atributo \"price\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "32768e6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔄 Probando: SGD + tanh\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x742738540c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x742738540c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "   ✅ Épocas promedio: 71, ECM: 35,361,175\n",
      "\n",
      "🔄 Probando: SGD + sigmoid\n",
      "   ✅ Épocas promedio: 139, ECM: 30,104,716\n",
      "\n",
      "🔄 Probando: SGD + ReLU\n",
      "   ✅ Épocas promedio: 66, ECM: 22,953,349\n",
      "\n",
      "🔄 Probando: SGD + LeakyReLU\n",
      "   ✅ Épocas promedio: 42, ECM: 28,308,042\n",
      "\n",
      "🔄 Probando: RMSprop + tanh\n",
      "   ✅ Épocas promedio: 188, ECM: 30,886,861\n",
      "\n",
      "🔄 Probando: RMSprop + sigmoid\n",
      "   ✅ Épocas promedio: 334, ECM: 33,150,822\n",
      "\n",
      "🔄 Probando: RMSprop + ReLU\n",
      "   ✅ Épocas promedio: 184, ECM: 24,067,889\n",
      "\n",
      "🔄 Probando: RMSprop + LeakyReLU\n",
      "   ✅ Épocas promedio: 164, ECM: 21,494,081\n",
      "\n",
      "🔄 Probando: Adam + tanh\n",
      "   ✅ Épocas promedio: 332, ECM: 27,460,848\n",
      "\n",
      "🔄 Probando: Adam + sigmoid\n",
      "   ✅ Épocas promedio: 477, ECM: 32,151,434\n",
      "\n",
      "🔄 Probando: Adam + ReLU\n",
      "   ✅ Épocas promedio: 237, ECM: 29,298,616\n",
      "\n",
      "🔄 Probando: Adam + LeakyReLU\n",
      "   ✅ Épocas promedio: 211, ECM: 26,306,921\n",
      "\n",
      "================================================================================\n",
      "RESULTADOS FINALES\n",
      "================================================================================\n",
      "\n",
      "📊 ÉPOCAS PROMEDIO:\n",
      "Optimizador         Adam  RMSprop  SGD\n",
      "Función activación                    \n",
      "LeakyReLU            211      164   42\n",
      "ReLU                 237      184   66\n",
      "sigmoid              477      334  139\n",
      "tanh                 332      188   71\n",
      "\n",
      "📊 ECM PROMEDIO:\n",
      "Optimizador                 Adam       RMSprop           SGD\n",
      "Función activación                                          \n",
      "LeakyReLU           2.630692e+07  2.149408e+07  2.830804e+07\n",
      "ReLU                2.929862e+07  2.406789e+07  2.295335e+07\n",
      "sigmoid             3.215143e+07  3.315082e+07  3.010472e+07\n",
      "tanh                2.746085e+07  3.088686e+07  3.536118e+07\n",
      "\n",
      "📊 RMSE PROMEDIO (Error en dólares):\n",
      "Optimizador           Adam RMSprop     SGD\n",
      "Función activación                        \n",
      "LeakyReLU           $5,129  $4,636  $5,321\n",
      "ReLU                $5,413  $4,906  $4,791\n",
      "sigmoid             $5,670  $5,758  $5,487\n",
      "tanh                $5,240  $5,558  $5,947\n",
      "\n",
      "🏆 MEJOR COMBINACIÓN:\n",
      "   Optimizador: RMSprop\n",
      "   Activación: LeakyReLU\n",
      "   Épocas: 164.0\n",
      "   ECM: 21,494,081\n",
      "   RMSE: $4,636\n",
      "\n",
      "📋 TABLA COMPLETA DE RESULTADOS:\n",
      "Optimizador Función activación  Épocas promedio ECM Promedio   RMSE\n",
      "        SGD               tanh               71   35,361,175 $5,947\n",
      "        SGD            sigmoid              139   30,104,716 $5,487\n",
      "        SGD               ReLU               66   22,953,349 $4,791\n",
      "        SGD          LeakyReLU               42   28,308,042 $5,321\n",
      "    RMSprop               tanh              188   30,886,861 $5,558\n",
      "    RMSprop            sigmoid              334   33,150,822 $5,758\n",
      "    RMSprop               ReLU              184   24,067,889 $4,906\n",
      "    RMSprop          LeakyReLU              164   21,494,081 $4,636\n",
      "       Adam               tanh              332   27,460,848 $5,240\n",
      "       Adam            sigmoid              477   32,151,434 $5,670\n",
      "       Adam               ReLU              237   29,298,616 $5,413\n",
      "       Adam          LeakyReLU              211   26,306,921 $5,129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_29108/1816075736.py:154: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  print(tabla_rmse.applymap(lambda x: f\"${x:,.0f}\"))\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "X = df.drop(columns=[\"price\"]).to_numpy()\n",
    "y = df[\"price\"].to_numpy().reshape(-1, 1) # para que y sea una matriz columna\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "\n",
    "# Normalizar datos\n",
    "scaler_x = preprocessing.StandardScaler()\n",
    "X_train_scaled = scaler_x.fit_transform(X_train)\n",
    "X_test_scaled = scaler_x.transform(X_test)\n",
    "\n",
    "scaler_y = preprocessing.StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train)\n",
    "y_test_scaled = scaler_y.transform(y_test)\n",
    "\n",
    "# Parámetros de la red\n",
    "EPOCAS = 1000\n",
    "TAM_LOTE = 50\n",
    "PACIENCIA = 15\n",
    "ENTRADAS = X.shape[1]\n",
    "\n",
    "# Definir combinaciones a probar\n",
    "optimizadores = ['SGD', 'RMSprop', 'Adam']\n",
    "activaciones = ['tanh', 'sigmoid', 'ReLU', 'LeakyReLU']\n",
    "\n",
    "# Crear DataFrame para resultados\n",
    "resultados = []\n",
    "\n",
    "# Experimento sistemático\n",
    "for opt_name in optimizadores:\n",
    "    for act_name in activaciones:\n",
    "        print(f\"\\n🔄 Probando: {opt_name} + {act_name}\")\n",
    "\n",
    "        total_epochs = 0\n",
    "        total_ecm = 0\n",
    "        for i in range(20):  # Repetir cada combinación 20 veces\n",
    "            # Crear modelo\n",
    "            model = Sequential()\n",
    "            model.add(Input(shape=(ENTRADAS,)))\n",
    "            \n",
    "            # Seleccionar función de activación\n",
    "            if act_name == 'tanh':\n",
    "                activacion = 'tanh'\n",
    "            elif act_name == 'sigmoid':\n",
    "                activacion = 'sigmoid'\n",
    "            elif act_name == 'ReLU':\n",
    "                activacion = 'relu'\n",
    "            elif act_name == 'LeakyReLU':\n",
    "                activacion = LeakyReLU()\n",
    "            \n",
    "            model.add(Dense(10, activation=activacion))\n",
    "            model.add(Dense(1, activation='linear'))  # Regresión\n",
    "            \n",
    "            # Seleccionar optimizador\n",
    "            if opt_name == 'SGD':\n",
    "                optimizador = SGD(momentum=0.9)\n",
    "            elif opt_name == 'RMSprop':\n",
    "                optimizador = RMSprop()\n",
    "            elif opt_name == 'Adam':\n",
    "                optimizador = Adam()\n",
    "            \n",
    "            # Compilar modelo\n",
    "            model.compile(optimizer=optimizador, loss='mse', metrics=['mae'])\n",
    "            \n",
    "            # Early stopping\n",
    "            early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                monitor='val_loss',\n",
    "                patience=PACIENCIA,\n",
    "                restore_best_weights=True\n",
    "            )\n",
    "            \n",
    "            # Dividir train en train/validation\n",
    "            X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "                X_train_scaled, y_train_scaled, test_size=0.2, shuffle=True\n",
    "            )\n",
    "            \n",
    "            # Entrenar modelo\n",
    "            history = model.fit(\n",
    "                X_train_split, y_train_split,\n",
    "                epochs=EPOCAS,\n",
    "                batch_size=TAM_LOTE,\n",
    "                validation_data=(X_val_split, y_val_split),\n",
    "                callbacks=[early_stop],\n",
    "                verbose=0\n",
    "            )\n",
    "            \n",
    "            # Calcular métricas\n",
    "            epocas_usadas = len(history.history['loss'])\n",
    "            total_epochs += epocas_usadas\n",
    "            \n",
    "            # Evaluar en test\n",
    "            test_loss, test_mae = model.evaluate(X_test_scaled, y_test_scaled, verbose=0)\n",
    "            \n",
    "            # Hacer predicciones para calcular ECM en escala original\n",
    "            y_pred_scaled = model.predict(X_test_scaled, verbose=0)\n",
    "            y_pred_real = scaler_y.inverse_transform(y_pred_scaled)\n",
    "            y_test_real = scaler_y.inverse_transform(y_test_scaled)\n",
    "\n",
    "            # Calcular ECM en escala original\n",
    "            ecm = np.mean((y_test_real - y_pred_real)**2)\n",
    "            total_ecm += ecm\n",
    "        \n",
    "        # ECM en escala original\n",
    "        ecm_promedio = total_ecm / 20\n",
    "        epocas_promedio = total_epochs // 20\n",
    "        \n",
    "        # Guardar resultados\n",
    "        resultado = {\n",
    "            'Optimizador': opt_name,\n",
    "            'Función activación': act_name,\n",
    "            'Épocas promedio': epocas_promedio,\n",
    "            'ECM Promedio': ecm_promedio\n",
    "        }\n",
    "        resultados.append(resultado)\n",
    "        \n",
    "        print(f\"   ✅ Épocas promedio: {epocas_promedio}, ECM: {ecm_promedio:,.0f}\")\n",
    "            \n",
    "# Crear DataFrame con resultados\n",
    "df_resultados = pd.DataFrame(resultados)\n",
    "\n",
    "# Crear tabla pivote\n",
    "tabla_epocas = df_resultados.pivot(index='Función activación', \n",
    "                                   columns='Optimizador', \n",
    "                                   values='Épocas promedio')\n",
    "\n",
    "tabla_ecm = df_resultados.pivot(index='Función activación', \n",
    "                                columns='Optimizador', \n",
    "                                values='ECM Promedio')\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESULTADOS FINALES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n📊 ÉPOCAS PROMEDIO:\")\n",
    "print(tabla_epocas)\n",
    "\n",
    "print(\"\\n📊 ECM PROMEDIO:\")\n",
    "print(tabla_ecm)\n",
    "\n",
    "# Encontrar mejor combinación\n",
    "df_validos = df_resultados[df_resultados['ECM Promedio'] != 'Error'].copy()\n",
    "df_validos['ECM Promedio'] = pd.to_numeric(df_validos['ECM Promedio'])\n",
    "\n",
    "# ✅ Agregar tabla de RMSE (más interpretable)\n",
    "df_resultados['RMSE'] = np.sqrt(df_resultados['ECM Promedio'])\n",
    "tabla_rmse = df_resultados.pivot(\n",
    "    index='Función activación', \n",
    "    columns='Optimizador', \n",
    "    values='RMSE'\n",
    ")\n",
    "\n",
    "print(\"\\n📊 RMSE PROMEDIO (Error en dólares):\")\n",
    "print(tabla_rmse.applymap(lambda x: f\"${x:,.0f}\"))\n",
    "\n",
    "# Encontrar mejor combinación\n",
    "mejor = df_resultados.loc[df_resultados['ECM Promedio'].idxmin()]\n",
    "print(f\"\\n🏆 MEJOR COMBINACIÓN:\")\n",
    "print(f\"   Optimizador: {mejor['Optimizador']}\")\n",
    "print(f\"   Activación: {mejor['Función activación']}\")\n",
    "print(f\"   Épocas: {mejor['Épocas promedio']:.1f}\")\n",
    "print(f\"   ECM: {mejor['ECM Promedio']:,.0f}\")\n",
    "print(f\"   RMSE: ${mejor['RMSE']:,.0f}\")\n",
    "\n",
    "# Tabla completa\n",
    "print(f\"\\n📋 TABLA COMPLETA DE RESULTADOS:\")\n",
    "df_display = df_resultados.copy()\n",
    "df_display['ECM Promedio'] = df_display['ECM Promedio'].apply(lambda x: f\"{x:,.0f}\")\n",
    "df_display['RMSE'] = df_display['RMSE'].apply(lambda x: f\"${x:,.0f}\")\n",
    "df_display['Épocas promedio'] = df_display['Épocas promedio'].round(1)\n",
    "print(df_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afab170e",
   "metadata": {},
   "source": [
    "#### Ejercicio 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8350b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "from skimage.measure import regionprops, label\n",
    "from skimage.filters import threshold_otsu\n",
    "from skimage.morphology import closing, disk\n",
    "from skimage.segmentation import clear_border"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a9a41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                area:     1892.0\n",
      "           area_bbox:     4278.0\n",
      "         area_convex:     3064.0\n",
      "         area_filled:     1892.0\n",
      "   axis_major_length:     67.49455955508728\n",
      "   axis_minor_length:     47.37266683356695\n",
      "                bbox:     (24, 29, 93, 91)\n",
      "            centroid:     (np.float64(63.58562367864693), np.float64(62.811310782241016))\n",
      "      centroid_local:     [39.58562368 33.81131078]\n",
      "              coords:     [[24 56]\n",
      " [24 57]\n",
      " [24 58]\n",
      " ...\n",
      " [92 57]\n",
      " [92 58]\n",
      " [92 59]]\n",
      "        eccentricity:     0.7123012628261987\n",
      "equivalent_diameter_area:     49.08125119267976\n",
      "        euler_number:     1\n",
      "              extent:     0.442262739597943\n",
      "  feret_diameter_max:     70.2353187506115\n",
      "               image:     [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "        image_convex:     [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "        image_filled:     [[False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " ...\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]\n",
      " [False False False ... False False False]]\n",
      "      inertia_tensor:     [[142.4902949   17.80810378]\n",
      " [ 17.80810378 282.49002588]]\n",
      "inertia_tensor_eigvals:     [np.float64(284.7197230959515), np.float64(140.2605976827584)]\n",
      "               label:     1\n",
      "             moments:     [[1.89200000e+03 6.39710000e+04 2.43253500e+06 9.97752050e+07]\n",
      " [7.48960000e+04 2.49863900e+06 9.41998550e+07 3.82246489e+09]\n",
      " [3.49927600e+06 1.14971945e+08 4.27793087e+09 1.71198053e+11]\n",
      " [1.77923776e+08 5.78225400e+09 2.12727821e+11 8.41393058e+12]]\n",
      "     moments_central:     [[ 1.89200000e+03  1.34292577e-12  2.69591638e+05 -7.02485184e+05]\n",
      " [ 1.28750344e-11 -3.36929323e+04  1.84844318e+05 -3.03945531e+07]\n",
      " [ 5.34471129e+05 -6.75651868e+05  6.65251647e+07 -1.71089488e+08]\n",
      " [-2.91199284e+06  5.04887332e+06 -3.72516309e+08 -3.53957959e+09]]\n",
      "          moments_hu:     [ 2.24619620e-01  5.82972003e-03  5.68015965e-04  3.85108522e-04\n",
      "  9.13694631e-08  1.10663356e-05 -1.55221757e-07]\n",
      "  moments_normalized:     [[        nan         nan  0.075312   -0.00451164]\n",
      " [        nan -0.00941232  0.00118714 -0.00448779]\n",
      " [ 0.14930762 -0.0043393   0.00982251 -0.00058076]\n",
      " [-0.01870198  0.00074547 -0.00126451 -0.00027623]]\n",
      "         orientation:     -0.12455869232440826\n",
      "           perimeter:     344.97770542341357\n",
      "   perimeter_crofton:     329.7408903714803\n",
      "               slice:     (slice(24, 93, None), slice(29, 91, None))\n",
      "            solidity:     0.6174934725848564\n"
     ]
    }
   ],
   "source": [
    "\n",
    "img_path = \"/home/santi/Documentos/Cuarto/Deep Learning/Prácticas/Datos/archive/fingers/test/0a4d7cbc-2522-4e51-968a-1a86d3b7ee19_5L.png\"\n",
    "\n",
    "imagen = io.imread(img_path)\n",
    "\n",
    "# busca umbral global con método estadístico de Otsu\n",
    "umbral = threshold_otsu(imagen)\n",
    "\n",
    "# binariza la imagen\n",
    "imagen_bn = (imagen > umbral)*1\n",
    "\n",
    "# cierra pequeños huecos/cortes que pudiera tener la imagen de la mano\n",
    "imagen_bn = closing(imagen_bn, disk(2))\n",
    "\n",
    "# remueve artefactos que pudiera tener la imagen en los bordes\n",
    "imagen_lista = clear_border(imagen_bn)\n",
    "\n",
    "# obtiene valores geométricos a partir de las regiones (objetos \"aislados\") en la imagen\n",
    "regiones = regionprops(imagen_lista)\n",
    "\n",
    "# datos de la primera región. Debería ser la única si la mano fue segmentada correctamente\n",
    "region = regiones[0]\n",
    "\n",
    "for prop in region:\n",
    "  #if prop not in ['convex_image', 'coords', 'image_filled', 'image', 'image_convex', 'moments', 'moments_central', 'moments_normalized', 'moments_hu']:\n",
    "  print('%20s:    '% prop, region[prop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a599ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_from_image(img_path):\n",
    "    \"\"\"\n",
    "    Extrae características de una imagen usando regionprops\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Leer imagen\n",
    "        img = io.imread(img_path)\n",
    "        \n",
    "        # Si la imagen no está binarizada, binarizarla\n",
    "        if img.max() > 1:\n",
    "            # Binarizar usando Otsu\n",
    "            threshold = threshold_otsu(img)\n",
    "            img_binary = img > threshold\n",
    "        else:\n",
    "            img_binary = img.astype(bool)\n",
    "        \n",
    "        # ✅ CORREGIDO: Usar disk en lugar de square\n",
    "        img_clean = closing(img_binary, disk(2))\n",
    "        img_clean = clear_border(img_clean)\n",
    "        \n",
    "        # Etiquetar regiones conectadas\n",
    "        labeled_img = label(img_clean, connectivity=2)\n",
    "        \n",
    "        # Obtener propiedades de las regiones\n",
    "        regions = regionprops(labeled_img)\n",
    "        \n",
    "        if len(regions) == 0:\n",
    "            return None\n",
    "        \n",
    "        # Tomar la región más grande (probablemente la mano)\n",
    "        largest_region = max(regions, key=lambda r: r.area)\n",
    "        \n",
    "        # Extraer características específicas\n",
    "        features = {\n",
    "            'filename': os.path.basename(img_path),\n",
    "            'filled_area': largest_region.filled_area,\n",
    "            'major_axis_length': largest_region.major_axis_length,\n",
    "            'minor_axis_length': largest_region.minor_axis_length,\n",
    "            'perimeter': largest_region.perimeter,\n",
    "            'eccentricity': largest_region.eccentricity,\n",
    "            'solidity': largest_region.solidity,\n",
    "            'extent': largest_region.extent,\n",
    "            'num_of_fingers': img_path.split('_')[-1].split('.')[0][0] # Extrae número de dedos del nombre del archivo\n",
    "        }\n",
    "        \n",
    "        return features\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {img_path}: {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e966fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(folder_path, output_filename):\n",
    "    \"\"\"\n",
    "    Procesa todas las imágenes en una carpeta y guarda las características en CSV\n",
    "    \"\"\"\n",
    "    print(f\"Procesando carpeta: {folder_path}\")\n",
    "    \n",
    "    # Lista para almacenar todas las características\n",
    "    all_features = []\n",
    "    \n",
    "    # Obtener lista de archivos de imagen\n",
    "    image_extensions = ['.png', '.jpg', '.jpeg', '.bmp', '.tiff']\n",
    "    image_files = []\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        if any(filename.lower().endswith(ext) for ext in image_extensions):\n",
    "            image_files.append(filename)\n",
    "    \n",
    "    print(f\"Encontradas {len(image_files)} imágenes\")\n",
    "    \n",
    "    # Procesar cada imagen\n",
    "    for i, img_name in enumerate(image_files):\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        \n",
    "        # Mostrar progreso\n",
    "        if (i + 1) % 50 == 0 or (i + 1) == len(image_files):\n",
    "            print(f\"Procesando imagen {i + 1}/{len(image_files)}: {img_name}\")\n",
    "        \n",
    "        # Extraer características\n",
    "        features = extract_features_from_image(img_path)\n",
    "    \n",
    "        if features is not None:\n",
    "            all_features.append(features)\n",
    "    \n",
    "    # Crear DataFrame\n",
    "    df = pd.DataFrame(all_features)\n",
    "    \n",
    "    # Guardar CSV\n",
    "    df.to_csv(output_filename, index=False)\n",
    "    print(f\"Archivo guardado: {output_filename}\")\n",
    "    print(f\"Características extraídas de {len(df)} imágenes\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f579fc98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Carpeta train encontrada: 18000 archivos\n",
      "✅ Carpeta test encontrada: 3600 archivos\n",
      "\n",
      "==================================================\n",
      "PROCESANDO CARPETA TRAIN\n",
      "==================================================\n",
      "Procesando carpeta: /home/santi/Documentos/Cuarto/Deep Learning/Prácticas/Datos/archive/fingers/train\n",
      "Encontradas 18000 imágenes\n",
      "Procesando imagen 50/18000: 33fc7ff2-bf5c-44a4-9dd8-a5bb502b52ce_3L.png\n",
      "Procesando imagen 100/18000: b1406cbe-82b8-43e7-a4ad-d7b14635ad84_2R.png\n",
      "Procesando imagen 150/18000: 338d8f16-735f-4ef7-9be8-b75f7fbc7763_4L.png\n",
      "Procesando imagen 200/18000: dbb9bdab-f31e-4e6c-9f53-d7bac457802a_3L.png\n",
      "Procesando imagen 250/18000: 43528d0b-62ad-4ba3-b1a9-6a6bee4cccbe_0R.png\n",
      "Procesando imagen 300/18000: d596a2f5-526e-4a1d-ac8b-35c1f7ddba47_4L.png\n",
      "Procesando imagen 350/18000: bb483295-9c42-431e-9d00-f6f8c25c1b0f_3L.png\n",
      "Procesando imagen 400/18000: a9768946-1151-4ac5-8ee3-4d0aed510d21_5L.png\n",
      "Procesando imagen 450/18000: 7f7c10e0-420c-43f0-8978-771b8093c93b_4L.png\n",
      "Procesando imagen 500/18000: 03c72043-b23f-48bc-88e4-e6de323b7aff_4R.png\n",
      "Procesando imagen 550/18000: 3ccd2db0-676e-458a-8a07-08714d677f07_2L.png\n",
      "Procesando imagen 600/18000: 35ba5464-3839-4bd6-aa74-f79a66970470_4L.png\n",
      "Procesando imagen 650/18000: e6b9c8a1-d639-49d2-8826-03f8e00e8e4e_2R.png\n",
      "Procesando imagen 700/18000: 6aecdf6a-2d91-4f8c-b25c-a272627fd172_3R.png\n",
      "Procesando imagen 750/18000: f6fd6851-9bab-48de-9f9d-5de9766a2256_1L.png\n",
      "Procesando imagen 800/18000: 9f22679b-5b6d-438a-88dc-74734bcca553_1R.png\n",
      "Procesando imagen 850/18000: 316e39a2-82b4-43d5-ab29-b81c3350b0a1_1R.png\n",
      "Procesando imagen 900/18000: 2a6f8be8-db23-4320-a67f-1f52b15226e8_0L.png\n",
      "Procesando imagen 950/18000: a2503a64-4294-4b45-974d-6cecd256a169_4L.png\n",
      "Procesando imagen 1000/18000: 6140661b-e5af-46d7-b656-47ec98c4bb2d_3R.png\n",
      "Procesando imagen 1050/18000: 2f6e4c90-9401-4d1d-b019-c404fed95332_3L.png\n",
      "Procesando imagen 1100/18000: b015fea0-9636-4bf8-a26f-41af0c064476_0L.png\n",
      "Procesando imagen 1150/18000: 8b4e94e8-8a1a-433f-9517-5a876df736a4_2R.png\n",
      "Procesando imagen 1200/18000: ee2506c6-2096-47db-9df9-d24fdb142a75_2R.png\n",
      "Procesando imagen 1250/18000: d9faa85d-6c12-4d2f-a794-6bde790285cc_3R.png\n",
      "Procesando imagen 1300/18000: a9ee17dc-419a-4936-8aef-515f1015998b_4R.png\n",
      "Procesando imagen 1350/18000: b74b1fa2-a8c9-4772-b4b4-c6ed39103514_5R.png\n",
      "Procesando imagen 1400/18000: bd0a2ce9-69fb-4b2d-9da9-e2688c20e37e_5R.png\n",
      "Procesando imagen 1450/18000: ee5b2c51-3f42-4f9d-ab6f-69fb0430dc26_0R.png\n",
      "Procesando imagen 1500/18000: 9f4106b8-67a2-4304-9f75-2c7937d43262_4R.png\n",
      "Procesando imagen 1550/18000: 0ea5e993-26c0-4070-93c8-6258ef744bc9_2L.png\n",
      "Procesando imagen 1600/18000: 465b8ecd-7d07-46b8-bea1-4346773db0fa_0R.png\n",
      "Procesando imagen 1650/18000: a6e7fdea-9003-40c4-83ff-4c514a022fb5_4L.png\n",
      "Procesando imagen 1700/18000: fc7af5ba-222c-4986-b688-1b078f759ea5_1L.png\n",
      "Procesando imagen 1750/18000: ab117fa0-34c2-4709-ab04-1e2adfc2ef2a_2R.png\n",
      "Procesando imagen 1800/18000: 2286920f-2c89-4e9d-bd6f-6d9cfd122cb0_2L.png\n",
      "Procesando imagen 1850/18000: 089cb54a-70d7-42d3-9eb2-5963c0bd2f06_5L.png\n",
      "Procesando imagen 1900/18000: 18c6aeb0-30f1-4832-b06b-bf4d1582a1c9_0R.png\n",
      "Procesando imagen 1950/18000: dcbbb28e-feab-4098-8b30-db8942194b62_5R.png\n",
      "Procesando imagen 2000/18000: 7a32fb40-6469-4975-9d2a-fe9d8c333bc4_3L.png\n",
      "Procesando imagen 2050/18000: 3a667539-ef38-4ee4-8562-aa2516e89554_3L.png\n",
      "Procesando imagen 2100/18000: 868ac20a-6ed4-4fd2-99f0-46d87c7d1900_4R.png\n",
      "Procesando imagen 2150/18000: c10cfbaa-0066-4436-9ed9-0493741132f8_5L.png\n",
      "Procesando imagen 2200/18000: 61596faa-735b-4b34-b7aa-8272308ad350_2R.png\n",
      "Procesando imagen 2250/18000: e691ec8b-7b3f-44ca-99a4-001f298f909d_3R.png\n",
      "Procesando imagen 2300/18000: edd918e3-aec7-4fd3-9f48-3d5e2a52ce8c_0R.png\n",
      "Procesando imagen 2350/18000: 49066be8-8310-404d-8a60-1305f9a3adda_1R.png\n",
      "Procesando imagen 2400/18000: 9c8ed952-bbfc-4bfb-a64b-bca063f26056_1R.png\n",
      "Procesando imagen 2450/18000: ee975a1f-58d7-4e37-884e-c036b86b0093_2L.png\n",
      "Procesando imagen 2500/18000: b548e7fb-7ac3-4cc4-85e2-d616042f349f_3R.png\n",
      "Procesando imagen 2550/18000: a5861e17-a29d-444c-8e37-5477180eb2c0_4L.png\n",
      "Procesando imagen 2600/18000: ce908e7c-22e8-4869-8954-27addce173d8_2L.png\n",
      "Procesando imagen 2650/18000: e0e6e9a4-64e9-4886-b7fd-d39822a2b6d7_4L.png\n",
      "Procesando imagen 2700/18000: 9c0dd62f-876e-42b5-9e21-f7a96f8fe90c_3R.png\n",
      "Procesando imagen 2750/18000: ecabceee-4512-436c-92fd-440298b46659_1L.png\n",
      "Procesando imagen 2800/18000: 0aaf2977-fe98-4f58-9d42-d7ad0ead6b82_2L.png\n",
      "Procesando imagen 2850/18000: 2df28e65-53a8-4935-b7af-6abdb0f3f4d8_5L.png\n",
      "Procesando imagen 2900/18000: 18e1877b-b4ca-43ad-89c6-6bfb0697090b_0L.png\n",
      "Procesando imagen 2950/18000: 9bc59e28-bc09-40b7-b1e3-81640d402651_3R.png\n",
      "Procesando imagen 3000/18000: c9da7b97-79f9-409d-9342-029b83fae07c_2L.png\n",
      "Procesando imagen 3050/18000: c0331b64-d67f-481d-96be-018ecd69602b_3R.png\n",
      "Procesando imagen 3100/18000: 7ada9b82-e54e-454b-a793-458587d49d75_5L.png\n",
      "Procesando imagen 3150/18000: 42319db1-d0d8-4f1c-97de-0e644bd87612_0L.png\n",
      "Procesando imagen 3200/18000: c7b28a9b-9381-44de-8d34-dc33d173a59c_1R.png\n",
      "Procesando imagen 3250/18000: ad43c358-4983-4a02-9f11-b5f93bfcd0fe_3R.png\n",
      "Procesando imagen 3300/18000: 5908493f-09aa-4955-a7a7-562d83c05bbe_5L.png\n",
      "Procesando imagen 3350/18000: 8beaeb8b-c72d-4e5f-b906-a881f14841b7_2R.png\n",
      "Procesando imagen 3400/18000: 8d371830-16e5-486c-905f-42a650e0ce4d_1L.png\n",
      "Procesando imagen 3450/18000: 0c3cfa87-51fb-430e-8033-b94ac0e66fc9_4R.png\n",
      "Procesando imagen 3500/18000: 6bde8ae9-b712-4a7d-88e7-f95274f18998_3L.png\n",
      "Procesando imagen 3550/18000: 551a4faf-12a5-49d0-b968-88f57db63740_1R.png\n",
      "Procesando imagen 3600/18000: 0903c086-9825-4e20-b778-6103fe271e49_1L.png\n",
      "Procesando imagen 3650/18000: 072377ff-5199-4d5c-ba0e-0b387feacace_5L.png\n",
      "Procesando imagen 3700/18000: d366c35d-e7da-4187-9198-0052021a6652_2L.png\n",
      "Procesando imagen 3750/18000: 3ae9438d-e12f-4c8d-9040-d96bd2dd0aed_3R.png\n",
      "Procesando imagen 3800/18000: 8c24b355-e377-4964-8578-47770dfb3fe6_2R.png\n",
      "Procesando imagen 3850/18000: f8b275d2-aa9d-4d0b-aa12-def2990dc040_1L.png\n",
      "Procesando imagen 3900/18000: 489c94aa-62a0-4920-8842-04314fe34c11_5R.png\n",
      "Procesando imagen 3950/18000: 31772e2d-2300-499c-8d1b-6202a05e412e_2L.png\n",
      "Procesando imagen 4000/18000: 4902dd41-468f-44e6-9cf9-ea0ab5d351d9_3L.png\n",
      "Procesando imagen 4050/18000: 20257308-a833-4ee5-814a-999ac19ddf21_5L.png\n",
      "Procesando imagen 4100/18000: 60121a2a-b98f-4640-8906-cbd44d1d19b8_0L.png\n",
      "Procesando imagen 4150/18000: ab6c3e85-ecc9-4211-b48d-3570cc8ce20b_0L.png\n",
      "Procesando imagen 4200/18000: 688d11a7-6139-43cc-b9db-ddac245b4966_5R.png\n",
      "Procesando imagen 4250/18000: 34352892-4c21-4d66-9a06-27259614a3c6_5R.png\n",
      "Procesando imagen 4300/18000: 389c1d60-7818-42fa-b4b8-f1a1ad35aa18_1R.png\n",
      "Procesando imagen 4350/18000: 5ac31799-d1a7-4b95-9c7a-18114e5725a1_5L.png\n",
      "Procesando imagen 4400/18000: eb70dddf-7dd5-458f-81e4-f15bae5dffa3_1L.png\n",
      "Procesando imagen 4450/18000: 63587bf1-ba10-4c32-846d-e8d28c107229_3R.png\n",
      "Procesando imagen 4500/18000: 7870dcfc-70a4-411b-9c72-ccc64ec933f5_4R.png\n",
      "Procesando imagen 4550/18000: 898fcbe9-1f9f-4e16-81a8-ff6fac067d70_5R.png\n",
      "Procesando imagen 4600/18000: 4d196030-54b2-45fa-822c-8e9f53868e44_3L.png\n",
      "Procesando imagen 4650/18000: be432465-ddd9-4d51-871c-b8c7e9b9e13f_5R.png\n",
      "Procesando imagen 4700/18000: c5df501d-7928-4a33-8698-c761fa428fc0_1R.png\n",
      "Procesando imagen 4750/18000: 0c3826c3-c91e-402d-9ee6-e2a846b7559c_3R.png\n",
      "Procesando imagen 4800/18000: 1730c685-430a-4929-aa4b-889ef49a8b0a_3L.png\n",
      "Procesando imagen 4850/18000: 66b4922b-ed2b-4a8a-82bd-24db8f11ed1f_4L.png\n",
      "Procesando imagen 4900/18000: d802cdab-5ecd-41f9-8a74-8cfa72c04386_2L.png\n",
      "Procesando imagen 4950/18000: 070d3404-5ead-4552-bfe8-bac70ed5b3cd_3L.png\n",
      "Procesando imagen 5000/18000: 203c9290-206c-49ff-88d0-012b17008547_4R.png\n",
      "Procesando imagen 5050/18000: 3b6a9dbc-597e-47b4-9812-7825b0bb373b_1L.png\n",
      "Procesando imagen 5100/18000: d0600d5e-f051-4185-8a4b-7b19e30169aa_0L.png\n",
      "Procesando imagen 5150/18000: c278f311-79aa-4462-9843-3448fd4e34dd_0L.png\n",
      "Procesando imagen 5200/18000: ac5f28eb-ceac-4a63-aa2e-31bcdef8c88a_4L.png\n",
      "Procesando imagen 5250/18000: 47b6193c-ea92-4567-900d-aa68c4642190_2L.png\n",
      "Procesando imagen 5300/18000: 3d1f4137-52f1-4d38-a01a-f5cb69309ead_1L.png\n",
      "Procesando imagen 5350/18000: f6ffdee8-203c-45fc-ad21-072206e5dc6e_0L.png\n",
      "Procesando imagen 5400/18000: 8113d6d9-41fa-43bf-a5a2-f0e424b39292_1R.png\n",
      "Procesando imagen 5450/18000: c233615c-d494-4b67-aa62-72248a1901f5_0L.png\n",
      "Procesando imagen 5500/18000: 085e8edd-8cae-4da2-a6ec-a9f095eaa2ad_1R.png\n",
      "Procesando imagen 5550/18000: 2126345a-1214-407f-a60a-3c706c15abf7_2R.png\n",
      "Procesando imagen 5600/18000: 6c132543-6405-476d-872e-096a8f215ae8_2L.png\n",
      "Procesando imagen 5650/18000: ea373b3f-d96f-4dff-b9af-34a1082f7163_0R.png\n",
      "Procesando imagen 5700/18000: 8982974e-f94e-437b-a674-e3c0401766e7_1L.png\n",
      "Procesando imagen 5750/18000: 34c166b8-f68c-42cf-972e-8acb5dc12876_5R.png\n",
      "Procesando imagen 5800/18000: e847d8d4-d205-4734-99b6-c96814eb6b36_1R.png\n",
      "Procesando imagen 5850/18000: 766f76e7-0629-4795-a598-e00c2824aba8_1L.png\n",
      "Procesando imagen 5900/18000: ab4f18aa-8dce-44dc-8e95-96f7398a1a36_2R.png\n",
      "Procesando imagen 5950/18000: 22e88f0f-6797-423d-9ced-262c22eface2_4R.png\n",
      "Procesando imagen 6000/18000: fd030a63-87b0-4c91-bc26-dfea81dbf698_1R.png\n",
      "Procesando imagen 6050/18000: ca8f30c3-31c6-455e-9b7a-2e0f7bb32a34_2L.png\n",
      "Procesando imagen 6100/18000: 93647073-44ab-45d3-a7d8-6ff277f7d406_2L.png\n",
      "Procesando imagen 6150/18000: d5709afb-5723-43f2-808c-8226b4ec691c_0L.png\n",
      "Procesando imagen 6200/18000: 594d9c42-f084-41e4-8f4f-5387706d0b58_0L.png\n",
      "Procesando imagen 6250/18000: 9542de6e-f946-4e03-9919-fd09c6fb9731_4R.png\n",
      "Procesando imagen 6300/18000: 600d29e4-7964-4f4e-9e64-f9f7124237b3_3L.png\n",
      "Procesando imagen 6350/18000: 767ec66a-ff0e-48ea-9036-fd9891e91d36_4L.png\n",
      "Procesando imagen 6400/18000: e1087ccb-97eb-49e9-b264-86df0c65238f_1L.png\n",
      "Procesando imagen 6450/18000: e7863f55-3705-4e71-b127-1d57f5edc771_3R.png\n",
      "Procesando imagen 6500/18000: 5e55d265-1fdd-4db1-85dc-9479ace9689a_1L.png\n",
      "Procesando imagen 6550/18000: 5df17338-b762-48c0-bccf-76e30c659b23_0R.png\n",
      "Procesando imagen 6600/18000: ec213094-ee8d-4b16-909a-55c8c1964240_2L.png\n",
      "Procesando imagen 6650/18000: 17556f09-b9b4-441c-aef7-d3dc9054d1eb_2L.png\n",
      "Procesando imagen 6700/18000: 6d0eaeb2-03ae-403c-8cda-1b4e8b7a53f1_3L.png\n",
      "Procesando imagen 6750/18000: 54c2bb66-02d8-4ca9-b91b-c86fefa05a5f_4L.png\n",
      "Procesando imagen 6800/18000: 3d076937-58ce-44d5-be1c-c3cc03e42b98_3L.png\n",
      "Procesando imagen 6850/18000: 0c94ef90-5187-48f5-94db-47f784c892f6_2R.png\n",
      "Procesando imagen 6900/18000: deba9f80-2c78-4225-a0ac-3cda45c8734b_4L.png\n",
      "Procesando imagen 6950/18000: 0962ab66-13e0-4040-805e-8e90d0887992_1L.png\n",
      "Procesando imagen 7000/18000: 8a62bd28-c3d0-49a6-bcd6-70f6af55b6a3_2L.png\n",
      "Procesando imagen 7050/18000: 0de450da-9355-4c42-98e4-34896c8dc6af_1R.png\n",
      "Procesando imagen 7100/18000: 3359f05c-36de-45e8-978d-77b7bbeda0e5_3L.png\n",
      "Procesando imagen 7150/18000: bb6884be-863a-408c-a9c1-ff20742cf41d_2R.png\n",
      "Procesando imagen 7200/18000: 4c549ca2-8cd9-4a40-a469-609bab3539f3_3R.png\n",
      "Procesando imagen 7250/18000: b9bcac5c-020e-43ac-9cb7-0d61377d4c25_2L.png\n",
      "Procesando imagen 7300/18000: 0273bd82-30ab-4101-930c-c547cc47ee21_1R.png\n",
      "Procesando imagen 7350/18000: b89afb21-228d-4984-af57-11468b733bcc_0R.png\n",
      "Procesando imagen 7400/18000: d435ed06-29dd-4093-95bf-aae40b15f718_0R.png\n",
      "Procesando imagen 7450/18000: f53491cb-3f2a-41a2-b6f9-e4e97f074342_3R.png\n",
      "Procesando imagen 7500/18000: cedb4be4-60ac-498e-9114-1d46adcce23e_4R.png\n",
      "Procesando imagen 7550/18000: aa64935e-2ec0-4bd7-abf0-52175e861fa1_4L.png\n",
      "Procesando imagen 7600/18000: 9f6eedff-bc71-4554-81f1-589a1c0b2f0a_0R.png\n",
      "Procesando imagen 7650/18000: 1c5c891e-58dd-4a26-a383-900a57a858b3_4R.png\n",
      "Procesando imagen 7700/18000: efc963f9-7146-42c3-a71b-39d235a64ce7_3L.png\n",
      "Procesando imagen 7750/18000: d07c6d4a-d10a-4920-afde-ce62d21d21b3_0R.png\n",
      "Procesando imagen 7800/18000: eac64d9c-c787-4cc3-8a6c-4b81adac7731_4R.png\n",
      "Procesando imagen 7850/18000: e58d322e-3465-4335-9ec8-8ffd1856be46_4R.png\n",
      "Procesando imagen 7900/18000: 48416e38-e690-405a-b263-9fef37ae3944_3R.png\n",
      "Procesando imagen 7950/18000: 405d0054-d762-4157-9b5b-cfbc4fc5447e_0R.png\n",
      "Procesando imagen 8000/18000: 9d8e16ac-3c5a-4d7f-8910-27111922d813_2L.png\n",
      "Procesando imagen 8050/18000: ce2f7f83-12de-42c1-9c24-7dc2d13272dd_0R.png\n",
      "Procesando imagen 8100/18000: 263b47cc-9787-4e94-b66f-4ad928b5626a_2L.png\n",
      "Procesando imagen 8150/18000: d0f8c2a9-da85-490b-a04a-2f24086e9bcb_2L.png\n",
      "Procesando imagen 8200/18000: 74bf6662-f84e-4ff1-87b1-ac8364c1b233_1L.png\n",
      "Procesando imagen 8250/18000: 9d61f57b-cade-451d-a962-21faf51d37e3_3R.png\n",
      "Procesando imagen 8300/18000: 3999a6ad-6713-4f16-9bd5-ab6a7451d036_5R.png\n",
      "Procesando imagen 8350/18000: 96e754d4-3a3a-408e-ab5c-e62e73a5952d_1R.png\n",
      "Procesando imagen 8400/18000: c4d2e6ac-41a2-49c9-91d3-0a71eeef7ea8_0L.png\n",
      "Procesando imagen 8450/18000: 7365ab7e-247c-4cfd-9b7e-8a6e3e75beca_5L.png\n",
      "Procesando imagen 8500/18000: 68136feb-4d40-4101-927c-6e47a60fd982_5L.png\n",
      "Procesando imagen 8550/18000: 87147377-830e-4b31-aaab-8b411fa61435_4L.png\n",
      "Procesando imagen 8600/18000: 3f214285-dedf-4abf-a525-f3fb8d6d5871_4R.png\n",
      "Procesando imagen 8650/18000: 0624d9d7-7616-4c2d-be8b-f8e2725b2f50_3R.png\n",
      "Procesando imagen 8700/18000: 24ab3269-1e8d-41e5-9a73-bccbaffb0e34_5L.png\n",
      "Procesando imagen 8750/18000: 4c17e2eb-81b6-474f-9a27-4100a08695c7_2L.png\n",
      "Procesando imagen 8800/18000: 5f704e4e-b315-4ca3-8575-6b51a039b33a_4L.png\n",
      "Procesando imagen 8850/18000: 4754a875-30af-4d9a-9d74-4a3852d82474_4R.png\n",
      "Procesando imagen 8900/18000: d7f5ea83-2d45-47c7-b57b-8222660a38af_2L.png\n",
      "Procesando imagen 8950/18000: 6e4ddbea-da8f-4f95-ae21-8563f33beccf_3R.png\n",
      "Procesando imagen 9000/18000: f092f148-c234-4148-a29e-952002a0455f_2L.png\n",
      "Procesando imagen 9050/18000: 78b2c591-7e9e-4e9b-ab30-e9676d646407_2R.png\n",
      "Procesando imagen 9100/18000: c228fee9-c9f5-4896-aa43-a1343e7e51ef_5L.png\n",
      "Procesando imagen 9150/18000: 559f319c-1bca-4aab-b950-7b7384309790_4L.png\n",
      "Procesando imagen 9200/18000: 8652e7da-e111-4309-bdb5-76965021b21f_2R.png\n",
      "Procesando imagen 9250/18000: 67ef67d5-5685-42ee-a96f-d295c41f8505_0L.png\n",
      "Procesando imagen 9300/18000: 5573ad90-213a-4030-881d-650bfe4aa50a_2L.png\n",
      "Procesando imagen 9350/18000: f2c3179c-0be8-47d6-84a0-0e5f3513c976_1R.png\n",
      "Procesando imagen 9400/18000: 5407845b-7eff-4ec5-b9f5-b4fa12a5282f_4R.png\n",
      "Procesando imagen 9450/18000: 3d0355ed-3436-4909-8ac5-7e9bf4a4fac9_2R.png\n",
      "Procesando imagen 9500/18000: 12266880-aa16-4ba6-9e26-8ee7e6eccc12_1L.png\n",
      "Procesando imagen 9550/18000: 6a5586dd-4747-43bf-829a-1d6ccf5dee50_4R.png\n",
      "Procesando imagen 9600/18000: ca345503-03b3-4a06-bc8e-19d7c1ed6be3_0R.png\n",
      "Procesando imagen 9650/18000: efe6194e-cb81-411e-9eab-f7662cfb42f0_1R.png\n",
      "Procesando imagen 9700/18000: b3c96e0c-a7e9-4eb3-a647-6cac93f1718c_5L.png\n",
      "Procesando imagen 9750/18000: 04412382-6564-4889-820d-ff42ab45c0c8_1L.png\n",
      "Procesando imagen 9800/18000: bdeea5c8-e034-4988-b544-e6533aa0ed6f_4R.png\n",
      "Procesando imagen 9850/18000: 62107ef2-cde9-4f49-b471-840885633a6c_4L.png\n",
      "Procesando imagen 9900/18000: 08bec5f3-3f50-4eb8-8a14-9046679893aa_3L.png\n",
      "Procesando imagen 9950/18000: 5a835f20-d2f6-4e7a-8a79-00c6c288c2b4_4R.png\n",
      "Procesando imagen 10000/18000: e6eae8b3-564e-4c4d-9634-ce9282a12541_0R.png\n",
      "Procesando imagen 10050/18000: ebbcaee9-1c65-4b8c-8244-511f27967796_0R.png\n",
      "Procesando imagen 10100/18000: 4abccb72-9cb2-4e1b-82f3-3b6b2e57165d_2L.png\n",
      "Procesando imagen 10150/18000: 8be921b0-2e96-4000-aff7-67a8b6caaf95_4L.png\n",
      "Procesando imagen 10200/18000: dd0c513e-7992-4b9f-b6eb-14d234190d02_1L.png\n",
      "Procesando imagen 10250/18000: 1360ddbb-9547-4441-ae31-ea6ed7fc8102_2L.png\n",
      "Procesando imagen 10300/18000: b77a6b8d-848d-44ee-83fc-4ae4acf6013a_0R.png\n",
      "Procesando imagen 10350/18000: e902e980-1e1a-4477-b4ca-475c2ae9db40_4L.png\n",
      "Procesando imagen 10400/18000: b89d2a47-af2a-4ddb-ad27-520dca6c844f_0R.png\n",
      "Procesando imagen 10450/18000: 07450ab5-3f58-4946-9568-4a5a27abd6bc_1R.png\n",
      "Procesando imagen 10500/18000: 398871fd-f110-4730-9911-33ae87a2dc54_2L.png\n",
      "Procesando imagen 10550/18000: fb7388e6-a1fc-4a60-b52d-154bc1befce0_0R.png\n",
      "Procesando imagen 10600/18000: 30026ce8-c1a6-4823-a6a5-c2e9e5e8a896_5R.png\n",
      "Procesando imagen 10650/18000: 74946ea9-9180-4174-8b87-fe59b4638cb0_3L.png\n",
      "Procesando imagen 10700/18000: 8f6058a7-768c-4776-a728-c4f5d14e3870_0L.png\n",
      "Procesando imagen 10750/18000: a517a72b-4a07-4542-8130-b7dcd79e7ec3_5L.png\n",
      "Procesando imagen 10800/18000: 6b6f4ba4-bce9-4e30-9f76-cca141449084_2L.png\n",
      "Procesando imagen 10850/18000: aa6233fc-4fc6-482a-ae04-4058fa5d698a_2R.png\n",
      "Procesando imagen 10900/18000: ba5fac3f-f796-42cd-8d23-0bfa3d24839b_5L.png\n",
      "Procesando imagen 10950/18000: b48cdc96-b9e4-46d5-88c7-6710dd80b529_2R.png\n",
      "Procesando imagen 11000/18000: d1fe3558-d19d-463d-a57f-db3cb8e8f71a_3R.png\n",
      "Procesando imagen 11050/18000: 21825c5e-4b54-4e22-8984-10c444212346_1L.png\n",
      "Procesando imagen 11100/18000: 29767806-6479-4dad-a09e-4b33d265371d_5R.png\n",
      "Procesando imagen 11150/18000: ba4ccabf-ae67-43ac-9cfd-dadcd656c605_1L.png\n",
      "Procesando imagen 11200/18000: b94eeafd-efa8-4fe7-8c2e-be1fb2678491_0L.png\n",
      "Procesando imagen 11250/18000: e261e5c9-9bfb-40e1-84d3-f82dc6dbe9c0_4L.png\n",
      "Procesando imagen 11300/18000: 17d9b767-c775-4663-b279-79ac6b4d37f2_5L.png\n",
      "Procesando imagen 11350/18000: 390e6f16-888e-4f8f-a8c8-8b2518dc74b0_0L.png\n",
      "Procesando imagen 11400/18000: 99fc2fb2-c2a1-4485-a2ee-12caf16ab66d_4R.png\n",
      "Procesando imagen 11450/18000: 1464fe85-e931-4643-9c3c-2298b92a6a49_3L.png\n",
      "Procesando imagen 11500/18000: cb8e7026-d331-4cf9-8fd9-785148e35064_4R.png\n",
      "Procesando imagen 11550/18000: f03d3873-7f0a-4bdd-8681-6af504a9bfaa_3L.png\n",
      "Procesando imagen 11600/18000: bc76158a-c3dd-46ae-95d6-6489c74fa853_2R.png\n",
      "Procesando imagen 11650/18000: 82ad4922-990f-4ba8-bba5-7cf3490d2a7a_3R.png\n",
      "Procesando imagen 11700/18000: d2db98b7-b144-443e-924c-f3cf72c73731_1L.png\n",
      "Procesando imagen 11750/18000: fd566d43-7351-49d1-a18a-69c7041c2bbb_2R.png\n",
      "Procesando imagen 11800/18000: ae939ee5-3611-4a26-a7fc-8074dd8b7b38_4L.png\n",
      "Procesando imagen 11850/18000: 4626b5e2-f757-4ba1-a3eb-cfd31eaafb16_0L.png\n",
      "Procesando imagen 11900/18000: a34f0798-adb2-47be-ae52-5ab13e264744_1L.png\n",
      "Procesando imagen 11950/18000: 0e2784b1-df9f-46eb-9808-07d3649ac059_2R.png\n",
      "Procesando imagen 12000/18000: 52e6a2af-2890-4313-a4a2-81df50b4e5e4_0R.png\n",
      "Procesando imagen 12050/18000: 4bb34312-7fc9-47aa-a67a-d8a7c571885d_2R.png\n",
      "Procesando imagen 12100/18000: d796a5d4-e75e-4000-a8e0-c968d563cda3_2L.png\n",
      "Procesando imagen 12150/18000: fd236485-b673-413d-92c4-07f1dd385c23_3L.png\n",
      "Procesando imagen 12200/18000: 93262248-0418-453a-a4ff-ea33bed9cd9c_1R.png\n",
      "Procesando imagen 12250/18000: 81648e40-8828-441f-89a5-0ec6ecefd96d_1R.png\n",
      "Procesando imagen 12300/18000: 99dccf08-5a49-4cad-a13d-d95fe1634511_4L.png\n",
      "Procesando imagen 12350/18000: e5890d9b-7d6f-4cfe-97d5-4dd9be541b08_1L.png\n",
      "Procesando imagen 12400/18000: 29e15744-8ff5-4ba9-8ddd-5d0ebf04c569_5L.png\n",
      "Procesando imagen 12450/18000: b7a5d9b5-2489-4186-bc9b-c71d6af88c27_0R.png\n",
      "Procesando imagen 12500/18000: 37b14521-f340-4493-a149-9f984d7d238b_1R.png\n",
      "Procesando imagen 12550/18000: aafdab4a-4528-46c6-ae51-b442f9e6a5b9_5L.png\n",
      "Procesando imagen 12600/18000: 5ad4e995-b78a-44be-bb51-85f76e4ae5bf_0R.png\n",
      "Procesando imagen 12650/18000: 71058631-af26-49fd-a9d0-c76de4996a83_5L.png\n",
      "Procesando imagen 12700/18000: 9ec1e122-fd93-4f17-9a2b-41da21532352_3R.png\n",
      "Procesando imagen 12750/18000: bba16668-e75a-46ca-a5ed-426bf3727914_4L.png\n",
      "Procesando imagen 12800/18000: 6f8bd980-1459-44c0-a7e6-74ac9e8f645b_3L.png\n",
      "Procesando imagen 12850/18000: 5146ed99-ccc4-43bd-8cc4-03f02d873321_0L.png\n",
      "Procesando imagen 12900/18000: 0dec0402-51ee-4576-b20a-6d2b26574d5f_2L.png\n",
      "Procesando imagen 12950/18000: fb3033df-0f0c-460b-bae1-af561108c248_3L.png\n",
      "Procesando imagen 13000/18000: a1ddc279-4acb-4ae5-9581-62a8a024d9d1_4L.png\n",
      "Procesando imagen 13050/18000: d9e6bb74-ea6e-4e50-b11a-2f66b4ef4a98_3L.png\n",
      "Procesando imagen 13100/18000: fa8f2b4c-a2d0-46f8-80ac-83a6840e5125_4L.png\n",
      "Procesando imagen 13150/18000: e2c139d8-4496-47f5-8291-6415551a7a5e_3L.png\n",
      "Procesando imagen 13200/18000: 9ef20730-28f0-4bf2-a7ce-7f91b9be77de_0L.png\n",
      "Procesando imagen 13250/18000: 2f435f9d-f45f-4d9a-b683-e3d218c11100_5R.png\n",
      "Procesando imagen 13300/18000: e65f8eec-cd4e-46d6-88cb-a944da23d92c_4L.png\n",
      "Procesando imagen 13350/18000: d105dc88-e710-469b-a722-f8bba4558a80_0R.png\n",
      "Procesando imagen 13400/18000: 3d51c026-5db4-4959-b7ac-8f1b1a85d960_5R.png\n",
      "Procesando imagen 13450/18000: fa017e0e-7f88-4053-9fd3-22638f9ebf3f_5R.png\n",
      "Procesando imagen 13500/18000: 71aac386-423b-40a0-b7c4-fc0f00b70463_5L.png\n",
      "Procesando imagen 13550/18000: 43a754da-85c1-448b-82a7-a933dc7cd7b6_5R.png\n",
      "Procesando imagen 13600/18000: 808fe887-639e-4ada-ba96-4e043f677f8f_4L.png\n",
      "Procesando imagen 13650/18000: e4d0430b-83b6-48c0-adf8-7294e6ee96e5_3R.png\n",
      "Procesando imagen 13700/18000: 5178269b-d1e0-43bf-803e-dfffd747dabc_5L.png\n",
      "Procesando imagen 13750/18000: 6eb41467-3c8a-44ca-83bc-9cc4eff52b94_5L.png\n",
      "Procesando imagen 13800/18000: 23f1802c-a76e-4f53-aeb0-7d75e0947301_2L.png\n",
      "Procesando imagen 13850/18000: 1682d177-db9d-4d9b-87ff-e8a546861035_2L.png\n",
      "Procesando imagen 13900/18000: 375d33e7-7cb1-4c7f-ba4b-81f18663d647_0L.png\n",
      "Procesando imagen 13950/18000: ff66aa70-d1bb-4fca-9919-441b3f128e24_2L.png\n",
      "Procesando imagen 14000/18000: 2cc98609-4c89-47ec-9214-36440ba99906_1L.png\n",
      "Procesando imagen 14050/18000: 0c4607cd-d932-4be9-9bd4-5066c8cb598f_5L.png\n",
      "Procesando imagen 14100/18000: 6c5d5175-99e7-42f5-9985-da3087fff8cd_1R.png\n",
      "Procesando imagen 14150/18000: 3d809548-d335-45da-ae1d-6647c20c2d2b_0L.png\n",
      "Procesando imagen 14200/18000: 765e8d2c-208a-4361-afbc-6735eab7e5de_1R.png\n",
      "Procesando imagen 14250/18000: 78e5be94-46a9-4f03-8846-a05c304c8eee_2L.png\n",
      "Procesando imagen 14300/18000: 7e31649b-435b-493d-b269-0982f71e4f76_3R.png\n",
      "Procesando imagen 14350/18000: 2b0756c0-3585-4c40-be9f-a0236fbcc7d0_0L.png\n",
      "Procesando imagen 14400/18000: 56365d30-0062-4c68-be9f-2ffd18705790_0R.png\n",
      "Procesando imagen 14450/18000: 78590bbc-904f-4e8b-a882-4cf080eebdf2_1R.png\n",
      "Procesando imagen 14500/18000: 1c59021e-8566-49de-bd5a-ab618ad74659_4R.png\n",
      "Procesando imagen 14550/18000: 1c72293d-9dcc-4175-943b-98e8c04ea58c_4L.png\n",
      "Procesando imagen 14600/18000: 826f2d4d-208d-4b20-84a5-e07587360728_1R.png\n",
      "Procesando imagen 14650/18000: 3f0f09c7-4093-4b0c-a4a5-1647e88a2db7_1R.png\n",
      "Procesando imagen 14700/18000: c10bddf2-b52e-4914-b92c-83bebea23a8a_1R.png\n",
      "Procesando imagen 14750/18000: 3efa24e7-367f-4ac0-a9c8-89b4e2897928_3L.png\n",
      "Procesando imagen 14800/18000: f1121da0-7e27-41bc-b039-f32e702cdf81_5R.png\n",
      "Procesando imagen 14850/18000: 64005b0a-4e3c-4540-be2e-7262f22eedbb_2R.png\n",
      "Procesando imagen 14900/18000: d552d031-dfa3-419d-8fef-bce95611ea94_1L.png\n",
      "Procesando imagen 14950/18000: bfb70394-e7e2-4d27-bd34-583d0f824a71_2L.png\n",
      "Procesando imagen 15000/18000: 9c693cc9-37d1-485d-8be4-dcfd92a4d881_4R.png\n",
      "Procesando imagen 15050/18000: 61910925-5777-4f3e-9d0c-56db4b7b4eb8_4L.png\n",
      "Procesando imagen 15100/18000: 47630e20-8399-42e6-9241-99482f0b66d9_5R.png\n",
      "Procesando imagen 15150/18000: ba54bafd-3238-4037-8863-d176c6e8a8ce_4L.png\n",
      "Procesando imagen 15200/18000: 3ff7f9d1-f266-4155-9c8d-3d5ebb394143_3R.png\n",
      "Procesando imagen 15250/18000: 65a00b2f-6ae9-4fb3-bada-fa7853d42ac8_2L.png\n",
      "Procesando imagen 15300/18000: 1a4fa352-b43b-46ba-9ad5-e58ff8a468a9_2L.png\n",
      "Procesando imagen 15350/18000: 73a5ef97-3815-4c71-9a5b-fde61a051701_2L.png\n",
      "Procesando imagen 15400/18000: 53348a1a-f5d3-4a21-b31e-1b40b68629ee_2L.png\n",
      "Procesando imagen 15450/18000: 4b613ca6-ac68-4bf7-85d3-f625f686ff80_0R.png\n",
      "Procesando imagen 15500/18000: 3c1ee354-edbc-4d26-85a0-79cb67e57555_4R.png\n",
      "Procesando imagen 15550/18000: 8ea3d8e8-ce56-4400-bce1-cd4ce7182479_5L.png\n",
      "Procesando imagen 15600/18000: b955e105-4fd3-4830-9d14-9442dc1e7fa1_5R.png\n",
      "Procesando imagen 15650/18000: e9e1aa7b-bd40-4983-a422-cd37cca39db9_0R.png\n",
      "Procesando imagen 15700/18000: 06ab985a-0baa-4a61-9257-d8673fa9aa3d_5R.png\n",
      "Procesando imagen 15750/18000: 04805432-d1a3-415a-87c7-093c4382fb92_2R.png\n",
      "Procesando imagen 15800/18000: 377ec982-c129-4cb9-829c-8eb48dd8e909_5L.png\n",
      "Procesando imagen 15850/18000: 348eb5d7-197e-484a-b10e-9aa8b1446885_3L.png\n",
      "Procesando imagen 15900/18000: 4a2ed3bd-532b-42a9-8386-8abef97e34d4_2R.png\n",
      "Procesando imagen 15950/18000: bea43d6b-429f-445c-b7c0-4a25a4a8f9ba_1R.png\n",
      "Procesando imagen 16000/18000: faa9d2f0-c143-4754-aa54-5e26922d264f_1L.png\n",
      "Procesando imagen 16050/18000: 6847bde6-c144-4a1d-b312-a9eb393882d6_1R.png\n",
      "Procesando imagen 16100/18000: 51ad55d9-5e90-4c57-839c-a09267baefa6_2L.png\n",
      "Procesando imagen 16150/18000: 2fe6ad9e-2dfd-4f7c-94cf-4321981bdd4b_1R.png\n",
      "Procesando imagen 16200/18000: fba5e2a4-f283-4197-9da2-060f754befb2_3L.png\n",
      "Procesando imagen 16250/18000: 073d6d82-946c-4e6f-a6f7-394d36f58040_3R.png\n",
      "Procesando imagen 16300/18000: 111ad462-9bb2-4c69-8268-63a7585c8dad_0L.png\n",
      "Procesando imagen 16350/18000: 6ed2500d-a230-46e5-a7df-c0ba4a571dff_1L.png\n",
      "Procesando imagen 16400/18000: b084557c-0aa0-4272-aa92-924821832531_4L.png\n",
      "Procesando imagen 16450/18000: 71c7e7cf-6af2-4581-a2f6-74c842039757_5L.png\n",
      "Procesando imagen 16500/18000: 789e77d8-d38e-435c-a007-be3cca3aa841_3L.png\n",
      "Procesando imagen 16550/18000: 8d09c901-da18-4971-90c9-6e8daf38fd5e_5L.png\n",
      "Procesando imagen 16600/18000: 218302ee-ea4a-4562-b98a-7d2d684eac82_1R.png\n",
      "Procesando imagen 16650/18000: 47a8f05e-cb71-48c3-9387-08d1da0444a7_2R.png\n",
      "Procesando imagen 16700/18000: b3d0c490-d204-44ba-9872-4c08a14d0c06_0R.png\n",
      "Procesando imagen 16750/18000: 701369fc-27c6-4879-9db4-e8c393695809_2L.png\n",
      "Procesando imagen 16800/18000: 49427730-5c36-4ad8-8f98-a3aa86d942e5_5L.png\n",
      "Procesando imagen 16850/18000: 94e01cad-7758-49f2-b179-b6c050047c53_0R.png\n",
      "Procesando imagen 16900/18000: 2f5ecc43-fb55-4d96-8ee0-f9c530aa019d_5R.png\n",
      "Procesando imagen 16950/18000: ded574ec-18d7-4d98-8fd8-fec808add508_5L.png\n",
      "Procesando imagen 17000/18000: 2993e407-ec77-4653-a24b-c504cb364788_5R.png\n",
      "Procesando imagen 17050/18000: 0ce7752d-da26-4607-bb04-11a8a82299b7_2L.png\n",
      "Procesando imagen 17100/18000: adbcb775-7351-42ce-85c5-b0422881537e_5R.png\n",
      "Procesando imagen 17150/18000: 4ab96aeb-132f-4f69-a8ce-c086b85b4bda_3R.png\n",
      "Procesando imagen 17200/18000: 3a56837a-ca33-4813-849d-82de2684c924_2L.png\n",
      "Procesando imagen 17250/18000: 0cd03229-bce4-4218-9908-aa97d072f9d9_3R.png\n",
      "Procesando imagen 17300/18000: fbdc116e-de73-4e79-a8d2-bfea262cec82_0R.png\n",
      "Procesando imagen 17350/18000: 180ddaff-f197-4b7f-bbe7-3a826b0cd4e4_4L.png\n",
      "Procesando imagen 17400/18000: e4551223-bd45-4af6-bc67-4b74451bd117_1L.png\n",
      "Procesando imagen 17450/18000: f10c9731-906a-49c4-9dc5-ad72159200b4_2L.png\n",
      "Procesando imagen 17500/18000: ac2a86d8-b517-4874-a4c8-15fc2283c3b8_2L.png\n",
      "Procesando imagen 17550/18000: be53a5e3-530d-437f-8d3a-113df5dd02b5_5R.png\n",
      "Procesando imagen 17600/18000: f68634a8-5bb5-43b8-aab5-97e3e001ae55_4R.png\n",
      "Procesando imagen 17650/18000: a07ab284-d0c2-4d01-bf6d-a2757ceb80b9_3L.png\n",
      "Procesando imagen 17700/18000: 78844f57-51fa-4c70-ae8e-d79d64cdf9be_5R.png\n",
      "Procesando imagen 17750/18000: e87de841-8506-4376-8c7b-ac96f0cc54b5_1R.png\n",
      "Procesando imagen 17800/18000: 0010095b-2e3d-4517-a511-1f688c378f96_5L.png\n",
      "Procesando imagen 17850/18000: 11ee2b5b-13c1-412d-8159-3f7f3c1941fc_2L.png\n",
      "Procesando imagen 17900/18000: 331a2ec6-56e2-4162-b0a4-b93c75dbe624_4L.png\n",
      "Procesando imagen 17950/18000: e66c31ff-2359-4efe-8d79-bf166858f890_5R.png\n",
      "Procesando imagen 18000/18000: 0246f689-9e3f-4dc2-9ea6-b0beca1e2652_1R.png\n",
      "Archivo guardado: train_fingers_features.csv\n",
      "Características extraídas de 18000 imágenes\n",
      "\n",
      "==================================================\n",
      "PROCESANDO CARPETA TEST\n",
      "==================================================\n",
      "Procesando carpeta: /home/santi/Documentos/Cuarto/Deep Learning/Prácticas/Datos/archive/fingers/test\n",
      "Encontradas 3600 imágenes\n",
      "Procesando imagen 50/3600: 17eb58c2-4692-4f84-bc0a-4bb43bce20cc_5R.png\n",
      "Procesando imagen 100/3600: 8bb45bd4-2c93-4988-a9bc-e0858a257fe2_1R.png\n",
      "Procesando imagen 150/3600: 3e7bfd3d-345f-4b3a-8547-672a6cf263b0_4R.png\n",
      "Procesando imagen 200/3600: 6cdcbd5a-e72d-45b2-8641-acc3f65b9645_1R.png\n",
      "Procesando imagen 250/3600: 61f2d20f-16bb-42e4-a21e-a3b7d41523cd_1R.png\n",
      "Procesando imagen 300/3600: 369cec1b-d773-4ad4-ae72-8772d06e5735_1L.png\n",
      "Procesando imagen 350/3600: 8864480a-1fbb-4a6a-b0b2-22e2ca1366dd_5L.png\n",
      "Procesando imagen 400/3600: c33008a0-bd5d-4f0e-b595-0047c339f1a4_0R.png\n",
      "Procesando imagen 450/3600: b7022a15-5689-4019-870c-ca5908119e21_5L.png\n",
      "Procesando imagen 500/3600: 05f411fa-afad-4ea6-a14e-dcdb87bb1bff_4L.png\n",
      "Procesando imagen 550/3600: ef204636-7193-43eb-8764-a4cd1bad5b00_3R.png\n",
      "Procesando imagen 600/3600: 835cc178-39f0-4124-9342-5866f16f47fe_4L.png\n",
      "Procesando imagen 650/3600: ee5b1ce4-f09f-457f-83b7-0258269686e2_3L.png\n",
      "Procesando imagen 700/3600: d5dcc4b2-6f6d-4f04-8d67-fc8f0086c078_0R.png\n",
      "Procesando imagen 750/3600: 04dc487f-c195-4288-a976-5039c3e84d4f_3R.png\n",
      "Procesando imagen 800/3600: d6ccdd53-e8d6-4419-ba2f-a7285074d786_1R.png\n",
      "Procesando imagen 850/3600: 0fc02035-767b-4222-a416-29cc45c8c008_0R.png\n",
      "Procesando imagen 900/3600: 5c58ec12-a97a-4c2c-b92a-a64c8ba7f60c_2R.png\n",
      "Procesando imagen 950/3600: cdd3c737-62eb-41db-972e-26b0f8d1e368_3L.png\n",
      "Procesando imagen 1000/3600: c4b65c67-0aa9-4abf-9251-18dcc0689731_4L.png\n",
      "Procesando imagen 1050/3600: 06fccc5e-c9e3-4033-8e54-71a657e789fb_1L.png\n",
      "Procesando imagen 1100/3600: ccaec368-4f27-4601-a076-8eb0d0af5a37_2L.png\n",
      "Procesando imagen 1150/3600: 96f51a2c-6df8-47b4-8fd7-7a6c56eba7d0_0R.png\n",
      "Procesando imagen 1200/3600: b87c4b17-e6a3-415d-9587-9bd2d23ca0e7_1R.png\n",
      "Procesando imagen 1250/3600: 17d193f2-3302-4314-bd9f-11868f13c11e_5R.png\n",
      "Procesando imagen 1300/3600: cacf778a-ec03-45d0-8cfb-356ea1174f71_2R.png\n",
      "Procesando imagen 1350/3600: e9cbb674-03e1-4303-858c-f3bee8531b0f_1R.png\n",
      "Procesando imagen 1400/3600: 4810bfe8-d6eb-4e15-afee-ce89b5799dcf_3R.png\n",
      "Procesando imagen 1450/3600: 4c3d1c67-572d-48a6-b758-8fb4ff78c8a1_2R.png\n",
      "Procesando imagen 1500/3600: fbebb627-0bf0-4588-9cde-661bb79d2fd2_0R.png\n",
      "Procesando imagen 1550/3600: 91edd57b-48e1-4d28-9fd2-17153a490592_5R.png\n",
      "Procesando imagen 1600/3600: bf34553c-eb3e-4f37-b4a8-e5058bfa6c9b_3R.png\n",
      "Procesando imagen 1650/3600: 8e16938f-e457-402e-b55b-996aeb300b31_3R.png\n",
      "Procesando imagen 1700/3600: 96f60f58-2389-4507-a112-0fbc357d94f8_4R.png\n",
      "Procesando imagen 1750/3600: e0d90cc0-af9c-421a-b974-59fbe8929e34_2R.png\n",
      "Procesando imagen 1800/3600: 672f812f-271a-44c9-8192-8ebe124489f6_3L.png\n",
      "Procesando imagen 1850/3600: f1b729d8-22e6-41ab-aea0-e20f383b7677_4R.png\n",
      "Procesando imagen 1900/3600: 76468026-5416-43e4-bb42-1999b4826913_4R.png\n",
      "Procesando imagen 1950/3600: 71ea2681-f3db-48b8-8532-5d4e1c9e1813_2R.png\n",
      "Procesando imagen 2000/3600: 3744fa46-d530-4535-8029-3d54d5139918_1L.png\n",
      "Procesando imagen 2050/3600: 730c6921-ad14-4fbf-9e7b-114f82022a4e_5R.png\n",
      "Procesando imagen 2100/3600: de8d6242-20e8-42d1-8f89-33292b0f4b1c_0L.png\n",
      "Procesando imagen 2150/3600: 0dff476c-c330-401c-a816-fc4bf1eaeac5_5R.png\n",
      "Procesando imagen 2200/3600: f929f5ed-a56d-4dd8-8c54-1bc10b53ffaf_0L.png\n",
      "Procesando imagen 2250/3600: f79df6a0-cde9-4fd3-a978-de79807dbf73_4L.png\n",
      "Procesando imagen 2300/3600: 2751393d-465d-4e2c-951b-4f866d54c9e9_2R.png\n",
      "Procesando imagen 2350/3600: 3bb86400-840e-464b-81f8-bd1f0edc5750_4R.png\n",
      "Procesando imagen 2400/3600: b0aad63e-d9a8-459e-b74c-5342f99f09cb_0R.png\n",
      "Procesando imagen 2450/3600: 3929a8c3-f6bd-478b-b808-4ec8a7c3e1f6_0R.png\n",
      "Procesando imagen 2500/3600: 50afaab3-fb3d-4971-a710-b2a222059690_0R.png\n",
      "Procesando imagen 2550/3600: a3c859ca-d7c1-4360-b5cf-f62f9b6c92a2_5L.png\n",
      "Procesando imagen 2600/3600: 7b66bd3d-9a34-4d73-bc38-2c8647b64d96_0R.png\n",
      "Procesando imagen 2650/3600: 5cc06827-e9fc-4e83-8960-88d32cf1a411_2R.png\n",
      "Procesando imagen 2700/3600: c2d63925-dd62-442c-b3ca-275fd7b06aec_1R.png\n",
      "Procesando imagen 2750/3600: 93fa700c-c873-432b-992e-bb970e0b1524_5L.png\n",
      "Procesando imagen 2800/3600: 0989e7ce-12df-4839-8f16-e519f8da2870_1L.png\n",
      "Procesando imagen 2850/3600: 803b5b72-9a4f-4d8a-8ade-3523e6eecb9b_5R.png\n",
      "Procesando imagen 2900/3600: d9acdccb-308c-43ed-a868-66b395d9ef58_3R.png\n",
      "Procesando imagen 2950/3600: f1d45ad6-aa0c-4938-98e7-ae317c8d9dc5_4R.png\n",
      "Procesando imagen 3000/3600: 07619134-93d5-44d6-bffe-ff96db9205a0_2R.png\n",
      "Procesando imagen 3050/3600: cfd83001-151a-4124-948e-67ea846ac4a1_0L.png\n",
      "Procesando imagen 3100/3600: 9d2a0963-64be-4876-92a2-733fd08437bf_0R.png\n",
      "Procesando imagen 3150/3600: 50ec77a6-0dc4-4cf4-835f-d219a2e3aa18_4L.png\n",
      "Procesando imagen 3200/3600: 7bca972a-6c05-4c78-a97c-3603d6d54583_1L.png\n",
      "Procesando imagen 3250/3600: 11968742-2ebf-457d-85a1-a039ad97b997_0R.png\n",
      "Procesando imagen 3300/3600: 915a6e71-77ff-4270-bfc6-8695412cfad6_2R.png\n",
      "Procesando imagen 3350/3600: 8e5e7ff2-be3d-4f8f-bb93-53993fe4d029_1L.png\n",
      "Procesando imagen 3400/3600: 1f8c2e27-f94a-4008-979f-e8f250f2f5e7_2L.png\n",
      "Procesando imagen 3450/3600: d2a7aadc-1efc-46d2-ac66-a3edb99cc4ab_5R.png\n",
      "Procesando imagen 3500/3600: f99580a2-bf22-447b-94eb-615da7f9f278_4L.png\n",
      "Procesando imagen 3550/3600: 02296f11-9ee0-4c5d-ae19-c323cd328d54_0R.png\n",
      "Procesando imagen 3600/3600: 53b43068-a1df-4a0f-a5c1-e3e1a4b83f8e_1L.png\n",
      "Archivo guardado: test_fingers_features.csv\n",
      "Características extraídas de 3600 imágenes\n",
      "\n",
      "==================================================\n",
      "RESUMEN DE DATOS EXTRAÍDOS\n",
      "==================================================\n",
      "\n",
      "DATOS DE ENTRENAMIENTO:\n",
      "Número de imágenes procesadas: 18000\n",
      "\n",
      "Primeras 5 filas:\n",
      "                                      filename  filled_area  \\\n",
      "0  f0f620b3-49cf-40db-97cb-50955881b2ce_0R.png       1477.0   \n",
      "1  162db3ed-3618-4618-80cc-4e161a47e064_1L.png       1648.0   \n",
      "2  441e7930-0bb4-4421-a9ae-6caabe6457a8_1R.png       1527.0   \n",
      "3  f2c6398c-70e4-4d57-9bfa-c1df7e89ebd0_4R.png       1919.0   \n",
      "4  00a4ef2f-d6fe-49b9-acdf-c0d1092916da_1R.png       1552.0   \n",
      "\n",
      "   major_axis_length  minor_axis_length   perimeter  eccentricity  solidity  \\\n",
      "0          50.036089          41.492640  232.249783      0.558872  0.846633   \n",
      "1          76.829598          32.693783  237.480231      0.904941  0.813347   \n",
      "2          73.612129          36.452617  260.592929      0.868780  0.724040   \n",
      "3          71.228407          44.243914  323.563492      0.783687  0.672154   \n",
      "4          73.693203          32.613769  237.622366      0.896738  0.800000   \n",
      "\n",
      "     extent num_of_fingers  \n",
      "0  0.617273              0  \n",
      "1  0.536045              1  \n",
      "2  0.443895              1  \n",
      "3  0.453236              4  \n",
      "4  0.467564              1  \n",
      "\n",
      "Estadísticas:\n",
      "        filled_area  major_axis_length  minor_axis_length     perimeter  \\\n",
      "count  18000.000000       18000.000000       18000.000000  18000.000000   \n",
      "mean    1936.036333          73.787030          43.118638    312.475198   \n",
      "std      414.496025          12.322415           8.261946     78.973951   \n",
      "min      837.000000          36.880490          25.456969    120.568542   \n",
      "25%     1619.750000          70.679721          36.441934    244.894444   \n",
      "50%     1918.000000          75.661874          40.522209    318.527958   \n",
      "75%     2239.000000          83.090208          50.039492    376.776695   \n",
      "max     2955.000000          93.109537          63.054673    474.658946   \n",
      "\n",
      "       eccentricity      solidity        extent  \n",
      "count  18000.000000  18000.000000  18000.000000  \n",
      "mean       0.787543      0.711683      0.507577  \n",
      "std        0.096130      0.106596      0.101601  \n",
      "min        0.427609      0.539452      0.338409  \n",
      "25%        0.703917      0.632776      0.422340  \n",
      "50%        0.805349      0.681526      0.501233  \n",
      "75%        0.878246      0.792527      0.583366  \n",
      "max        0.950485      0.958845      0.763763  \n",
      "\n",
      "DATOS DE PRUEBA:\n",
      "Número de imágenes procesadas: 3600\n",
      "\n",
      "Primeras 5 filas:\n",
      "                                      filename  filled_area  \\\n",
      "0  d98868c5-db5f-4a83-a681-99a25b8ac746_4R.png       1916.0   \n",
      "1  bfc24ecf-ec37-4edd-bd58-633e16ea6605_1L.png       1568.0   \n",
      "2  14b27201-39a6-41f9-a58e-b09285aa896c_2L.png       2208.0   \n",
      "3  01eed593-fd93-4d96-b41f-bbe3c0584712_1R.png       1702.0   \n",
      "4  8f3da36d-eb9d-4631-ade0-58f79a48d464_0L.png       1354.0   \n",
      "\n",
      "   major_axis_length  minor_axis_length   perimeter  eccentricity  solidity  \\\n",
      "0          76.487499          41.190138  340.048773      0.842612  0.681366   \n",
      "1          75.318346          32.572973  236.858910      0.901648  0.768080   \n",
      "2          90.492722          40.319271  346.391919      0.895256  0.693662   \n",
      "3          77.002452          34.420608  253.036580      0.894531  0.782527   \n",
      "4          49.034316          38.327010  202.001046      0.623734  0.879592   \n",
      "\n",
      "     extent num_of_fingers  \n",
      "0  0.449133              4  \n",
      "1  0.515395              1  \n",
      "2  0.553795              2  \n",
      "3  0.508547              1  \n",
      "4  0.628280              0  \n",
      "\n",
      "Estadísticas:\n",
      "       filled_area  major_axis_length  minor_axis_length    perimeter  \\\n",
      "count  3600.000000        3600.000000        3600.000000  3600.000000   \n",
      "mean   1936.606111          73.866574          43.066266   312.401092   \n",
      "std     422.313449          12.356563           8.373414    80.536204   \n",
      "min     828.000000          38.308608          25.502273   123.811183   \n",
      "25%    1598.750000          70.929094          36.484648   242.626677   \n",
      "50%    1924.000000          75.819567          40.432849   320.149278   \n",
      "75%    2255.250000          83.119349          50.109351   378.108171   \n",
      "max    2932.000000          92.152154          62.483634   471.002092   \n",
      "\n",
      "       eccentricity     solidity       extent  \n",
      "count   3600.000000  3600.000000  3600.000000  \n",
      "mean       0.789303     0.712477     0.508886  \n",
      "std        0.094695     0.107297     0.102847  \n",
      "min        0.430462     0.540257     0.342500  \n",
      "25%        0.707277     0.633445     0.420459  \n",
      "50%        0.806945     0.681052     0.505660  \n",
      "75%        0.879295     0.795164     0.582395  \n",
      "max        0.949671     0.956840     0.748284  \n",
      "\n",
      "==============================\n",
      "VERIFICACIÓN DE CALIDAD\n",
      "==============================\n",
      "\n",
      "Valores faltantes en train:\n",
      "filename             0\n",
      "filled_area          0\n",
      "major_axis_length    0\n",
      "minor_axis_length    0\n",
      "perimeter            0\n",
      "eccentricity         0\n",
      "solidity             0\n",
      "extent               0\n",
      "num_of_fingers       0\n",
      "dtype: int64\n",
      "\n",
      "Valores faltantes en test:\n",
      "filename             0\n",
      "filled_area          0\n",
      "major_axis_length    0\n",
      "minor_axis_length    0\n",
      "perimeter            0\n",
      "eccentricity         0\n",
      "solidity             0\n",
      "extent               0\n",
      "num_of_fingers       0\n",
      "dtype: int64\n",
      "\n",
      "Rangos de características (train):\n",
      "filled_area         :   837.00 -  2955.00\n",
      "major_axis_length   :    36.88 -    93.11\n",
      "minor_axis_length   :    25.46 -    63.05\n",
      "perimeter           :   120.57 -   474.66\n",
      "eccentricity        :     0.43 -     0.95\n",
      "solidity            :     0.54 -     0.96\n",
      "extent              :     0.34 -     0.76\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning, module=\"skimage.morphology\")\n",
    "\n",
    "\n",
    "# Rutas de las carpetas\n",
    "base_path = \"/home/santi/Documentos/Cuarto/Deep Learning/Prácticas/Datos/archive/fingers/\"\n",
    "train_path = os.path.join(base_path, \"train\")\n",
    "test_path = os.path.join(base_path, \"test\")\n",
    "\n",
    "# Verificar que las carpetas existen\n",
    "if not os.path.exists(train_path):\n",
    "    print(f\"❌ No se encuentra la carpeta: {train_path}\")\n",
    "else:\n",
    "    print(f\"✅ Carpeta train encontrada: {len(os.listdir(train_path))} archivos\")\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    print(f\"❌ No se encuentra la carpeta: {test_path}\")\n",
    "else:\n",
    "    print(f\"✅ Carpeta test encontrada: {len(os.listdir(test_path))} archivos\")\n",
    "\n",
    "# Procesar carpeta train\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESANDO CARPETA TRAIN\")\n",
    "print(\"=\"*50)\n",
    "train_df = process_folder(train_path, \"train_fingers_features.csv\")\n",
    "\n",
    "# Procesar carpeta test\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"PROCESANDO CARPETA TEST\")\n",
    "print(\"=\"*50)\n",
    "test_df = process_folder(test_path, \"test_fingers_features.csv\")\n",
    "\n",
    "# Mostrar resumen de los datos\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RESUMEN DE DATOS EXTRAÍDOS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nDATOS DE ENTRENAMIENTO:\")\n",
    "print(f\"Número de imágenes procesadas: {len(train_df)}\")\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(train_df.head())\n",
    "print(\"\\nEstadísticas:\")\n",
    "print(train_df.describe())\n",
    "\n",
    "print(\"\\nDATOS DE PRUEBA:\")\n",
    "print(f\"Número de imágenes procesadas: {len(test_df)}\")\n",
    "print(\"\\nPrimeras 5 filas:\")\n",
    "print(test_df.head())\n",
    "print(\"\\nEstadísticas:\")\n",
    "print(test_df.describe())\n",
    "\n",
    "# Verificar si hay valores faltantes\n",
    "print(\"\\n\" + \"=\"*30)\n",
    "print(\"VERIFICACIÓN DE CALIDAD\")\n",
    "print(\"=\"*30)\n",
    "\n",
    "print(\"\\nValores faltantes en train:\")\n",
    "print(train_df.isnull().sum())\n",
    "\n",
    "print(\"\\nValores faltantes en test:\")\n",
    "print(test_df.isnull().sum())\n",
    "\n",
    "# Mostrar rangos de las características\n",
    "print(\"\\nRangos de características (train):\")\n",
    "numeric_cols = ['filled_area', 'major_axis_length', 'minor_axis_length', \n",
    "                'perimeter', 'eccentricity', 'solidity', 'extent']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in train_df.columns:\n",
    "        print(f\"{col:20s}: {train_df[col].min():8.2f} - {train_df[col].max():8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "67b4959f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRADAS TRAIN: 7\n",
      "SALIDAS TRAIN: 6\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_9\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_9\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">420</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_30 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_31 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_34 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │           \u001b[38;5;34m420\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_35 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │           \u001b[38;5;34m126\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,966</span> (7.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,966\u001b[0m (7.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,966</span> (7.68 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,966\u001b[0m (7.68 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.1831 - loss: 51.8536 - mse: 0.2432 - val_accuracy: 0.1842 - val_loss: 1.9394 - val_mse: 0.1535\n",
      "Epoch 2/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2525 - loss: 2.0709 - mse: 0.1518 - val_accuracy: 0.4419 - val_loss: 1.3890 - val_mse: 0.1161\n",
      "Epoch 3/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3235 - loss: 1.6426 - mse: 0.1327 - val_accuracy: 0.5089 - val_loss: 1.2847 - val_mse: 0.1092\n",
      "Epoch 4/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3808 - loss: 1.4858 - mse: 0.1230 - val_accuracy: 0.6278 - val_loss: 1.1301 - val_mse: 0.0987\n",
      "Epoch 5/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4136 - loss: 1.3879 - mse: 0.1173 - val_accuracy: 0.5694 - val_loss: 1.0613 - val_mse: 0.0946\n",
      "Epoch 6/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4873 - loss: 1.2210 - mse: 0.1054 - val_accuracy: 0.7314 - val_loss: 0.8761 - val_mse: 0.0770\n",
      "Epoch 7/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5206 - loss: 1.1411 - mse: 0.0998 - val_accuracy: 0.7275 - val_loss: 0.7842 - val_mse: 0.0694\n",
      "Epoch 8/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5642 - loss: 1.0389 - mse: 0.0923 - val_accuracy: 0.7617 - val_loss: 0.7947 - val_mse: 0.0713\n",
      "Epoch 9/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5715 - loss: 1.0048 - mse: 0.0905 - val_accuracy: 0.7344 - val_loss: 0.7297 - val_mse: 0.0659\n",
      "Epoch 10/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5866 - loss: 0.9666 - mse: 0.0879 - val_accuracy: 0.7672 - val_loss: 0.6801 - val_mse: 0.0622\n",
      "Epoch 11/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6049 - loss: 0.9044 - mse: 0.0838 - val_accuracy: 0.8306 - val_loss: 0.5897 - val_mse: 0.0535\n",
      "Epoch 12/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6242 - loss: 0.8697 - mse: 0.0809 - val_accuracy: 0.8089 - val_loss: 0.5982 - val_mse: 0.0539\n",
      "Epoch 13/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6369 - loss: 0.8254 - mse: 0.0778 - val_accuracy: 0.8367 - val_loss: 0.5362 - val_mse: 0.0484\n",
      "Epoch 14/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6670 - loss: 0.7638 - mse: 0.0722 - val_accuracy: 0.8100 - val_loss: 0.5294 - val_mse: 0.0488\n",
      "Epoch 15/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6687 - loss: 0.7561 - mse: 0.0720 - val_accuracy: 0.8194 - val_loss: 0.5263 - val_mse: 0.0495\n",
      "Epoch 16/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6727 - loss: 0.7466 - mse: 0.0712 - val_accuracy: 0.7703 - val_loss: 0.6040 - val_mse: 0.0578\n",
      "Epoch 17/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6787 - loss: 0.7229 - mse: 0.0695 - val_accuracy: 0.7892 - val_loss: 0.5275 - val_mse: 0.0505\n",
      "Epoch 18/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6845 - loss: 0.7257 - mse: 0.0699 - val_accuracy: 0.7300 - val_loss: 0.6067 - val_mse: 0.0596\n",
      "Epoch 19/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7081 - loss: 0.6672 - mse: 0.0647 - val_accuracy: 0.7783 - val_loss: 0.5246 - val_mse: 0.0522\n",
      "Epoch 20/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7178 - loss: 0.6445 - mse: 0.0624 - val_accuracy: 0.8622 - val_loss: 0.4256 - val_mse: 0.0402\n",
      "Epoch 21/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7228 - loss: 0.6371 - mse: 0.0622 - val_accuracy: 0.6814 - val_loss: 0.6738 - val_mse: 0.0670\n",
      "Epoch 22/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.6283 - mse: 0.0611 - val_accuracy: 0.8092 - val_loss: 0.4358 - val_mse: 0.0418\n",
      "Epoch 23/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7022 - loss: 0.6747 - mse: 0.0656 - val_accuracy: 0.7919 - val_loss: 0.4604 - val_mse: 0.0462\n",
      "Epoch 24/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7437 - loss: 0.5887 - mse: 0.0576 - val_accuracy: 0.7878 - val_loss: 0.5203 - val_mse: 0.0516\n",
      "Epoch 25/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.5925 - mse: 0.0582 - val_accuracy: 0.7922 - val_loss: 0.4781 - val_mse: 0.0475\n",
      "Epoch 26/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5884 - mse: 0.0577 - val_accuracy: 0.8153 - val_loss: 0.4328 - val_mse: 0.0420\n",
      "Epoch 27/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7471 - loss: 0.5730 - mse: 0.0562 - val_accuracy: 0.8308 - val_loss: 0.4223 - val_mse: 0.0405\n",
      "Epoch 28/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7660 - loss: 0.5321 - mse: 0.0526 - val_accuracy: 0.8344 - val_loss: 0.3790 - val_mse: 0.0369\n",
      "Epoch 29/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7650 - loss: 0.5406 - mse: 0.0531 - val_accuracy: 0.8161 - val_loss: 0.4484 - val_mse: 0.0449\n",
      "Epoch 30/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7649 - loss: 0.5459 - mse: 0.0536 - val_accuracy: 0.8164 - val_loss: 0.4270 - val_mse: 0.0419\n",
      "Epoch 31/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7540 - loss: 0.5607 - mse: 0.0551 - val_accuracy: 0.8294 - val_loss: 0.4501 - val_mse: 0.0445\n",
      "Epoch 32/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.5250 - mse: 0.0518 - val_accuracy: 0.8411 - val_loss: 0.3757 - val_mse: 0.0370\n",
      "Epoch 33/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7728 - loss: 0.5225 - mse: 0.0512 - val_accuracy: 0.7922 - val_loss: 0.4500 - val_mse: 0.0457\n",
      "Epoch 34/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7774 - loss: 0.5047 - mse: 0.0500 - val_accuracy: 0.8667 - val_loss: 0.3565 - val_mse: 0.0340\n",
      "Epoch 35/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.4916 - mse: 0.0480 - val_accuracy: 0.7639 - val_loss: 0.4603 - val_mse: 0.0471\n",
      "Epoch 36/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7924 - loss: 0.4813 - mse: 0.0473 - val_accuracy: 0.8444 - val_loss: 0.3857 - val_mse: 0.0374\n",
      "Epoch 37/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.5260 - mse: 0.0513 - val_accuracy: 0.7983 - val_loss: 0.4465 - val_mse: 0.0444\n",
      "Epoch 38/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8047 - loss: 0.4574 - mse: 0.0449 - val_accuracy: 0.7975 - val_loss: 0.4413 - val_mse: 0.0450\n",
      "Epoch 39/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.4916 - mse: 0.0485 - val_accuracy: 0.7669 - val_loss: 0.5107 - val_mse: 0.0507\n",
      "Epoch 40/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7869 - loss: 0.4938 - mse: 0.0478 - val_accuracy: 0.8706 - val_loss: 0.3332 - val_mse: 0.0321\n",
      "Epoch 41/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7992 - loss: 0.4655 - mse: 0.0459 - val_accuracy: 0.8672 - val_loss: 0.3617 - val_mse: 0.0348\n",
      "Epoch 42/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8050 - loss: 0.4612 - mse: 0.0454 - val_accuracy: 0.8658 - val_loss: 0.3516 - val_mse: 0.0342\n",
      "Epoch 43/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7822 - loss: 0.5052 - mse: 0.0494 - val_accuracy: 0.8592 - val_loss: 0.3525 - val_mse: 0.0339\n",
      "Epoch 44/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7903 - loss: 0.4911 - mse: 0.0481 - val_accuracy: 0.8289 - val_loss: 0.3905 - val_mse: 0.0389\n",
      "Epoch 45/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7888 - loss: 0.4925 - mse: 0.0480 - val_accuracy: 0.8750 - val_loss: 0.3583 - val_mse: 0.0347\n",
      "Epoch 46/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7985 - loss: 0.4641 - mse: 0.0456 - val_accuracy: 0.8361 - val_loss: 0.3731 - val_mse: 0.0370\n",
      "Epoch 47/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8031 - loss: 0.4562 - mse: 0.0450 - val_accuracy: 0.8503 - val_loss: 0.3556 - val_mse: 0.0350\n",
      "Epoch 48/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8109 - loss: 0.4392 - mse: 0.0434 - val_accuracy: 0.8444 - val_loss: 0.3685 - val_mse: 0.0371\n",
      "Epoch 49/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8155 - loss: 0.4307 - mse: 0.0421 - val_accuracy: 0.8633 - val_loss: 0.3515 - val_mse: 0.0336\n",
      "Epoch 50/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8110 - loss: 0.4399 - mse: 0.0432 - val_accuracy: 0.8717 - val_loss: 0.3572 - val_mse: 0.0345\n",
      "Epoch 51/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8070 - loss: 0.4538 - mse: 0.0445 - val_accuracy: 0.8719 - val_loss: 0.3431 - val_mse: 0.0332\n",
      "Epoch 52/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8214 - loss: 0.4256 - mse: 0.0417 - val_accuracy: 0.8517 - val_loss: 0.3619 - val_mse: 0.0354\n",
      "Epoch 53/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8082 - loss: 0.4436 - mse: 0.0437 - val_accuracy: 0.8489 - val_loss: 0.3595 - val_mse: 0.0350\n",
      "Epoch 54/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8153 - loss: 0.4293 - mse: 0.0421 - val_accuracy: 0.8247 - val_loss: 0.4256 - val_mse: 0.0415\n",
      "Epoch 55/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8112 - loss: 0.4411 - mse: 0.0432 - val_accuracy: 0.8469 - val_loss: 0.3609 - val_mse: 0.0352\n",
      "Epoch 56/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8099 - loss: 0.4540 - mse: 0.0443 - val_accuracy: 0.8639 - val_loss: 0.3641 - val_mse: 0.0358\n",
      "Epoch 57/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8028 - loss: 0.4622 - mse: 0.0451 - val_accuracy: 0.8258 - val_loss: 0.3839 - val_mse: 0.0384\n",
      "Epoch 58/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4251 - mse: 0.0418 - val_accuracy: 0.8728 - val_loss: 0.3181 - val_mse: 0.0313\n",
      "Epoch 59/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8253 - loss: 0.4147 - mse: 0.0406 - val_accuracy: 0.8800 - val_loss: 0.3117 - val_mse: 0.0301\n",
      "Epoch 60/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8314 - loss: 0.3998 - mse: 0.0393 - val_accuracy: 0.8269 - val_loss: 0.3863 - val_mse: 0.0387\n",
      "Epoch 61/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8065 - loss: 0.4507 - mse: 0.0440 - val_accuracy: 0.8228 - val_loss: 0.4219 - val_mse: 0.0404\n",
      "Epoch 62/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8233 - loss: 0.4211 - mse: 0.0411 - val_accuracy: 0.8636 - val_loss: 0.3341 - val_mse: 0.0331\n",
      "Epoch 63/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.3924 - mse: 0.0385 - val_accuracy: 0.8761 - val_loss: 0.3195 - val_mse: 0.0310\n",
      "Epoch 64/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8260 - loss: 0.4167 - mse: 0.0407 - val_accuracy: 0.7933 - val_loss: 0.4359 - val_mse: 0.0435\n",
      "Epoch 65/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8247 - loss: 0.4160 - mse: 0.0408 - val_accuracy: 0.8772 - val_loss: 0.3090 - val_mse: 0.0302\n",
      "Epoch 66/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8212 - loss: 0.4151 - mse: 0.0409 - val_accuracy: 0.8583 - val_loss: 0.3324 - val_mse: 0.0325\n",
      "Epoch 67/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8190 - loss: 0.4252 - mse: 0.0417 - val_accuracy: 0.8583 - val_loss: 0.3480 - val_mse: 0.0342\n",
      "Epoch 68/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8176 - loss: 0.4229 - mse: 0.0415 - val_accuracy: 0.7839 - val_loss: 0.4457 - val_mse: 0.0463\n",
      "Epoch 69/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8376 - loss: 0.3878 - mse: 0.0380 - val_accuracy: 0.8542 - val_loss: 0.3424 - val_mse: 0.0333\n",
      "Epoch 70/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3827 - mse: 0.0378 - val_accuracy: 0.8800 - val_loss: 0.3389 - val_mse: 0.0331\n",
      "Epoch 71/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8329 - loss: 0.3927 - mse: 0.0388 - val_accuracy: 0.8772 - val_loss: 0.3313 - val_mse: 0.0324\n",
      "Epoch 72/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8410 - loss: 0.3816 - mse: 0.0374 - val_accuracy: 0.8756 - val_loss: 0.3111 - val_mse: 0.0302\n",
      "Epoch 73/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8358 - loss: 0.3910 - mse: 0.0384 - val_accuracy: 0.8389 - val_loss: 0.3659 - val_mse: 0.0376\n",
      "Epoch 74/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8206 - loss: 0.4253 - mse: 0.0416 - val_accuracy: 0.8461 - val_loss: 0.3491 - val_mse: 0.0342\n",
      "Epoch 75/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8241 - loss: 0.4126 - mse: 0.0408 - val_accuracy: 0.8603 - val_loss: 0.3251 - val_mse: 0.0321\n",
      "Epoch 76/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8369 - loss: 0.3860 - mse: 0.0380 - val_accuracy: 0.8753 - val_loss: 0.3240 - val_mse: 0.0315\n",
      "Epoch 77/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8320 - loss: 0.3935 - mse: 0.0387 - val_accuracy: 0.8756 - val_loss: 0.3146 - val_mse: 0.0306\n",
      "Epoch 78/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8322 - loss: 0.4028 - mse: 0.0394 - val_accuracy: 0.8753 - val_loss: 0.3199 - val_mse: 0.0313\n",
      "Epoch 79/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3869 - mse: 0.0380 - val_accuracy: 0.8797 - val_loss: 0.3179 - val_mse: 0.0310\n",
      "Epoch 80/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8222 - loss: 0.4166 - mse: 0.0409 - val_accuracy: 0.8811 - val_loss: 0.3192 - val_mse: 0.0313\n",
      "Epoch 81/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8399 - loss: 0.3788 - mse: 0.0373 - val_accuracy: 0.8253 - val_loss: 0.3938 - val_mse: 0.0397\n",
      "Epoch 82/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3819 - mse: 0.0374 - val_accuracy: 0.8669 - val_loss: 0.3276 - val_mse: 0.0321\n",
      "Epoch 83/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8389 - loss: 0.3823 - mse: 0.0376 - val_accuracy: 0.8758 - val_loss: 0.3064 - val_mse: 0.0303\n",
      "Epoch 84/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3893 - mse: 0.0385 - val_accuracy: 0.8408 - val_loss: 0.3525 - val_mse: 0.0344\n",
      "Epoch 85/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8333 - loss: 0.3924 - mse: 0.0385 - val_accuracy: 0.8683 - val_loss: 0.3421 - val_mse: 0.0334\n",
      "Epoch 86/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8409 - loss: 0.3772 - mse: 0.0372 - val_accuracy: 0.8478 - val_loss: 0.3457 - val_mse: 0.0348\n",
      "Epoch 87/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8373 - loss: 0.3830 - mse: 0.0378 - val_accuracy: 0.8383 - val_loss: 0.3891 - val_mse: 0.0389\n",
      "Epoch 88/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8374 - loss: 0.3820 - mse: 0.0379 - val_accuracy: 0.8892 - val_loss: 0.2861 - val_mse: 0.0281\n",
      "Epoch 89/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8453 - loss: 0.3699 - mse: 0.0366 - val_accuracy: 0.8733 - val_loss: 0.3047 - val_mse: 0.0302\n",
      "Epoch 90/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8406 - loss: 0.3784 - mse: 0.0373 - val_accuracy: 0.8508 - val_loss: 0.3399 - val_mse: 0.0349\n",
      "Epoch 91/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3671 - mse: 0.0361 - val_accuracy: 0.8603 - val_loss: 0.3132 - val_mse: 0.0309\n",
      "Epoch 92/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8379 - loss: 0.3754 - mse: 0.0374 - val_accuracy: 0.8794 - val_loss: 0.3064 - val_mse: 0.0303\n",
      "Epoch 93/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8405 - loss: 0.3748 - mse: 0.0372 - val_accuracy: 0.7817 - val_loss: 0.4401 - val_mse: 0.0452\n",
      "Epoch 94/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8419 - loss: 0.3753 - mse: 0.0370 - val_accuracy: 0.8433 - val_loss: 0.3621 - val_mse: 0.0361\n",
      "Epoch 95/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8421 - loss: 0.3749 - mse: 0.0369 - val_accuracy: 0.8417 - val_loss: 0.3701 - val_mse: 0.0366\n",
      "Epoch 96/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8431 - loss: 0.3701 - mse: 0.0367 - val_accuracy: 0.8783 - val_loss: 0.2945 - val_mse: 0.0293\n",
      "Epoch 97/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8397 - loss: 0.3800 - mse: 0.0373 - val_accuracy: 0.8772 - val_loss: 0.3040 - val_mse: 0.0300\n",
      "Epoch 98/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8414 - loss: 0.3772 - mse: 0.0370 - val_accuracy: 0.8650 - val_loss: 0.3259 - val_mse: 0.0323\n",
      "Epoch 99/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8533 - loss: 0.3539 - mse: 0.0348 - val_accuracy: 0.8672 - val_loss: 0.3139 - val_mse: 0.0312\n",
      "Epoch 100/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8441 - loss: 0.3691 - mse: 0.0366 - val_accuracy: 0.8900 - val_loss: 0.3007 - val_mse: 0.0289\n",
      "Epoch 101/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8387 - loss: 0.3792 - mse: 0.0374 - val_accuracy: 0.8803 - val_loss: 0.3162 - val_mse: 0.0303\n",
      "Epoch 102/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8500 - loss: 0.3632 - mse: 0.0357 - val_accuracy: 0.7800 - val_loss: 0.4799 - val_mse: 0.0468\n",
      "Epoch 103/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.8440 - loss: 0.3687 - mse: 0.0367 - val_accuracy: 0.8858 - val_loss: 0.2841 - val_mse: 0.0278\n",
      "Epoch 104/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8506 - loss: 0.3517 - mse: 0.0346 - val_accuracy: 0.8686 - val_loss: 0.3004 - val_mse: 0.0298\n",
      "Epoch 105/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8541 - loss: 0.3505 - mse: 0.0344 - val_accuracy: 0.8944 - val_loss: 0.2777 - val_mse: 0.0270\n",
      "Epoch 106/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8547 - loss: 0.3457 - mse: 0.0341 - val_accuracy: 0.8642 - val_loss: 0.3235 - val_mse: 0.0327\n",
      "Epoch 107/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8473 - loss: 0.3602 - mse: 0.0355 - val_accuracy: 0.8636 - val_loss: 0.3188 - val_mse: 0.0320\n",
      "Epoch 108/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3475 - mse: 0.0344 - val_accuracy: 0.8858 - val_loss: 0.2861 - val_mse: 0.0280\n",
      "Epoch 109/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8481 - loss: 0.3642 - mse: 0.0358 - val_accuracy: 0.8786 - val_loss: 0.3020 - val_mse: 0.0299\n",
      "Epoch 110/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8467 - loss: 0.3604 - mse: 0.0356 - val_accuracy: 0.8858 - val_loss: 0.2916 - val_mse: 0.0287\n",
      "Epoch 111/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8506 - loss: 0.3524 - mse: 0.0347 - val_accuracy: 0.8808 - val_loss: 0.2856 - val_mse: 0.0282\n",
      "Epoch 112/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3407 - mse: 0.0336 - val_accuracy: 0.8775 - val_loss: 0.2942 - val_mse: 0.0290\n",
      "Epoch 113/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8558 - loss: 0.3373 - mse: 0.0336 - val_accuracy: 0.8778 - val_loss: 0.2984 - val_mse: 0.0295\n",
      "Epoch 114/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.3536 - mse: 0.0348 - val_accuracy: 0.8061 - val_loss: 0.4225 - val_mse: 0.0421\n",
      "Epoch 115/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8447 - loss: 0.3675 - mse: 0.0363 - val_accuracy: 0.8714 - val_loss: 0.2910 - val_mse: 0.0288\n",
      "Epoch 116/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8527 - loss: 0.3517 - mse: 0.0347 - val_accuracy: 0.8778 - val_loss: 0.2978 - val_mse: 0.0298\n",
      "Epoch 117/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8511 - loss: 0.3509 - mse: 0.0347 - val_accuracy: 0.8831 - val_loss: 0.2936 - val_mse: 0.0284\n",
      "Epoch 118/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8330 - loss: 0.3874 - mse: 0.0382 - val_accuracy: 0.7714 - val_loss: 0.4870 - val_mse: 0.0487\n",
      "Epoch 119/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8522 - loss: 0.3528 - mse: 0.0348 - val_accuracy: 0.8881 - val_loss: 0.2790 - val_mse: 0.0275\n",
      "Epoch 120/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8388 - loss: 0.3784 - mse: 0.0372 - val_accuracy: 0.8619 - val_loss: 0.3308 - val_mse: 0.0325\n",
      "Epoch 121/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8579 - loss: 0.3411 - mse: 0.0336 - val_accuracy: 0.8647 - val_loss: 0.3169 - val_mse: 0.0311\n",
      "Epoch 122/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.3439 - mse: 0.0340 - val_accuracy: 0.8839 - val_loss: 0.2785 - val_mse: 0.0275\n",
      "Epoch 123/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8581 - loss: 0.3320 - mse: 0.0330 - val_accuracy: 0.8703 - val_loss: 0.2951 - val_mse: 0.0295\n",
      "Epoch 124/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8501 - loss: 0.3523 - mse: 0.0349 - val_accuracy: 0.8744 - val_loss: 0.3022 - val_mse: 0.0294\n",
      "Epoch 125/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8508 - loss: 0.3588 - mse: 0.0353 - val_accuracy: 0.8672 - val_loss: 0.3124 - val_mse: 0.0317\n",
      "Epoch 126/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8624 - loss: 0.3298 - mse: 0.0326 - val_accuracy: 0.8811 - val_loss: 0.2863 - val_mse: 0.0280\n",
      "Epoch 127/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3399 - mse: 0.0337 - val_accuracy: 0.8736 - val_loss: 0.2904 - val_mse: 0.0292\n",
      "Epoch 128/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8521 - loss: 0.3460 - mse: 0.0344 - val_accuracy: 0.8767 - val_loss: 0.3089 - val_mse: 0.0306\n",
      "Epoch 129/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8502 - loss: 0.3497 - mse: 0.0348 - val_accuracy: 0.8803 - val_loss: 0.2833 - val_mse: 0.0284\n",
      "Epoch 130/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8551 - loss: 0.3403 - mse: 0.0338 - val_accuracy: 0.8567 - val_loss: 0.3376 - val_mse: 0.0338\n",
      "Epoch 131/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8536 - loss: 0.3436 - mse: 0.0340 - val_accuracy: 0.8861 - val_loss: 0.2835 - val_mse: 0.0282\n",
      "Epoch 132/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3276 - mse: 0.0322 - val_accuracy: 0.8672 - val_loss: 0.3032 - val_mse: 0.0308\n",
      "Epoch 133/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8597 - loss: 0.3322 - mse: 0.0331 - val_accuracy: 0.8892 - val_loss: 0.2732 - val_mse: 0.0271\n",
      "Epoch 134/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3296 - mse: 0.0328 - val_accuracy: 0.8303 - val_loss: 0.3940 - val_mse: 0.0381\n",
      "Epoch 135/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8425 - loss: 0.3606 - mse: 0.0359 - val_accuracy: 0.8803 - val_loss: 0.2866 - val_mse: 0.0286\n",
      "Epoch 136/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8436 - loss: 0.3720 - mse: 0.0367 - val_accuracy: 0.8283 - val_loss: 0.3681 - val_mse: 0.0386\n",
      "Epoch 137/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8569 - loss: 0.3434 - mse: 0.0340 - val_accuracy: 0.8842 - val_loss: 0.2835 - val_mse: 0.0281\n",
      "Epoch 138/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8622 - loss: 0.3336 - mse: 0.0330 - val_accuracy: 0.8319 - val_loss: 0.4061 - val_mse: 0.0402\n",
      "Epoch 139/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3242 - mse: 0.0319 - val_accuracy: 0.8964 - val_loss: 0.2610 - val_mse: 0.0257\n",
      "Epoch 140/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8575 - loss: 0.3391 - mse: 0.0335 - val_accuracy: 0.8908 - val_loss: 0.2751 - val_mse: 0.0272\n",
      "Epoch 141/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8609 - loss: 0.3264 - mse: 0.0324 - val_accuracy: 0.8314 - val_loss: 0.3354 - val_mse: 0.0350\n",
      "Epoch 142/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8588 - loss: 0.3371 - mse: 0.0331 - val_accuracy: 0.8453 - val_loss: 0.3491 - val_mse: 0.0355\n",
      "Epoch 143/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8574 - loss: 0.3340 - mse: 0.0332 - val_accuracy: 0.8064 - val_loss: 0.3779 - val_mse: 0.0393\n",
      "Epoch 144/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8665 - loss: 0.3242 - mse: 0.0320 - val_accuracy: 0.8850 - val_loss: 0.2883 - val_mse: 0.0286\n",
      "Epoch 145/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8626 - loss: 0.3262 - mse: 0.0321 - val_accuracy: 0.8825 - val_loss: 0.2687 - val_mse: 0.0271\n",
      "Epoch 146/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8634 - loss: 0.3235 - mse: 0.0320 - val_accuracy: 0.8853 - val_loss: 0.2695 - val_mse: 0.0268\n",
      "Epoch 147/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8578 - loss: 0.3366 - mse: 0.0335 - val_accuracy: 0.8867 - val_loss: 0.2741 - val_mse: 0.0273\n",
      "Epoch 148/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8645 - loss: 0.3243 - mse: 0.0320 - val_accuracy: 0.8836 - val_loss: 0.2768 - val_mse: 0.0277\n",
      "Epoch 149/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8606 - loss: 0.3326 - mse: 0.0329 - val_accuracy: 0.8819 - val_loss: 0.2969 - val_mse: 0.0292\n",
      "Epoch 150/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8512 - loss: 0.3449 - mse: 0.0343 - val_accuracy: 0.8797 - val_loss: 0.2971 - val_mse: 0.0293\n",
      "Epoch 151/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8630 - loss: 0.3276 - mse: 0.0323 - val_accuracy: 0.8944 - val_loss: 0.2676 - val_mse: 0.0264\n",
      "Epoch 152/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8589 - loss: 0.3336 - mse: 0.0330 - val_accuracy: 0.8811 - val_loss: 0.2894 - val_mse: 0.0287\n",
      "Epoch 153/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3156 - mse: 0.0311 - val_accuracy: 0.8700 - val_loss: 0.3207 - val_mse: 0.0319\n",
      "Epoch 154/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3196 - mse: 0.0316 - val_accuracy: 0.8811 - val_loss: 0.2737 - val_mse: 0.0278\n",
      "Epoch 155/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8595 - loss: 0.3316 - mse: 0.0331 - val_accuracy: 0.8878 - val_loss: 0.2844 - val_mse: 0.0281\n",
      "Epoch 156/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8679 - loss: 0.3162 - mse: 0.0312 - val_accuracy: 0.8861 - val_loss: 0.2737 - val_mse: 0.0273\n",
      "Epoch 157/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8631 - loss: 0.3284 - mse: 0.0325 - val_accuracy: 0.8469 - val_loss: 0.3173 - val_mse: 0.0328\n",
      "Epoch 158/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8605 - loss: 0.3327 - mse: 0.0328 - val_accuracy: 0.8739 - val_loss: 0.2779 - val_mse: 0.0278\n",
      "Epoch 159/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3110 - mse: 0.0308 - val_accuracy: 0.8881 - val_loss: 0.2985 - val_mse: 0.0285\n",
      "Epoch 160/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8688 - loss: 0.3148 - mse: 0.0312 - val_accuracy: 0.8856 - val_loss: 0.2790 - val_mse: 0.0278\n",
      "Epoch 161/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8691 - loss: 0.3108 - mse: 0.0308 - val_accuracy: 0.8694 - val_loss: 0.2984 - val_mse: 0.0306\n",
      "Epoch 162/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8564 - loss: 0.3377 - mse: 0.0337 - val_accuracy: 0.8817 - val_loss: 0.2767 - val_mse: 0.0277\n",
      "Epoch 163/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8656 - loss: 0.3201 - mse: 0.0316 - val_accuracy: 0.8708 - val_loss: 0.2999 - val_mse: 0.0306\n",
      "Epoch 164/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8676 - loss: 0.3173 - mse: 0.0314 - val_accuracy: 0.8875 - val_loss: 0.2559 - val_mse: 0.0260\n",
      "Epoch 165/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8697 - loss: 0.3151 - mse: 0.0309 - val_accuracy: 0.8850 - val_loss: 0.2650 - val_mse: 0.0266\n",
      "Epoch 166/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8715 - loss: 0.3108 - mse: 0.0308 - val_accuracy: 0.8869 - val_loss: 0.2583 - val_mse: 0.0263\n",
      "Epoch 167/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8650 - loss: 0.3240 - mse: 0.0320 - val_accuracy: 0.8967 - val_loss: 0.2483 - val_mse: 0.0246\n",
      "Epoch 168/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8659 - loss: 0.3238 - mse: 0.0318 - val_accuracy: 0.8847 - val_loss: 0.2751 - val_mse: 0.0273\n",
      "Epoch 169/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8709 - loss: 0.3106 - mse: 0.0307 - val_accuracy: 0.8950 - val_loss: 0.2629 - val_mse: 0.0260\n",
      "Epoch 170/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8758 - loss: 0.3034 - mse: 0.0300 - val_accuracy: 0.8878 - val_loss: 0.2675 - val_mse: 0.0270\n",
      "Epoch 171/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8611 - loss: 0.3305 - mse: 0.0327 - val_accuracy: 0.8789 - val_loss: 0.2921 - val_mse: 0.0288\n",
      "Epoch 172/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.3159 - mse: 0.0311 - val_accuracy: 0.8828 - val_loss: 0.2728 - val_mse: 0.0275\n",
      "Epoch 173/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8560 - loss: 0.3386 - mse: 0.0336 - val_accuracy: 0.8803 - val_loss: 0.2789 - val_mse: 0.0278\n",
      "Epoch 174/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8603 - loss: 0.3291 - mse: 0.0326 - val_accuracy: 0.8956 - val_loss: 0.2537 - val_mse: 0.0250\n",
      "Epoch 175/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8525 - loss: 0.3497 - mse: 0.0345 - val_accuracy: 0.8944 - val_loss: 0.2616 - val_mse: 0.0257\n",
      "Epoch 176/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8677 - loss: 0.3172 - mse: 0.0311 - val_accuracy: 0.8928 - val_loss: 0.2545 - val_mse: 0.0252\n",
      "Epoch 177/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.3026 - mse: 0.0300 - val_accuracy: 0.8725 - val_loss: 0.3103 - val_mse: 0.0309\n",
      "Epoch 178/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8737 - loss: 0.3042 - mse: 0.0299 - val_accuracy: 0.8967 - val_loss: 0.2584 - val_mse: 0.0257\n",
      "Epoch 179/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8735 - loss: 0.2980 - mse: 0.0296 - val_accuracy: 0.8942 - val_loss: 0.2472 - val_mse: 0.0248\n",
      "Epoch 180/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8748 - loss: 0.3031 - mse: 0.0298 - val_accuracy: 0.8808 - val_loss: 0.2773 - val_mse: 0.0282\n",
      "Epoch 181/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8648 - loss: 0.3234 - mse: 0.0320 - val_accuracy: 0.8939 - val_loss: 0.2456 - val_mse: 0.0245\n",
      "Epoch 182/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.2957 - mse: 0.0292 - val_accuracy: 0.8956 - val_loss: 0.2493 - val_mse: 0.0249\n",
      "Epoch 183/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8625 - loss: 0.3303 - mse: 0.0323 - val_accuracy: 0.8772 - val_loss: 0.2815 - val_mse: 0.0285\n",
      "Epoch 184/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8703 - loss: 0.3097 - mse: 0.0307 - val_accuracy: 0.8819 - val_loss: 0.2683 - val_mse: 0.0273\n",
      "Epoch 185/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8658 - loss: 0.3162 - mse: 0.0312 - val_accuracy: 0.8650 - val_loss: 0.2966 - val_mse: 0.0300\n",
      "Epoch 186/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8662 - loss: 0.3127 - mse: 0.0311 - val_accuracy: 0.9008 - val_loss: 0.2477 - val_mse: 0.0246\n",
      "Epoch 187/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8721 - loss: 0.3078 - mse: 0.0304 - val_accuracy: 0.8947 - val_loss: 0.2443 - val_mse: 0.0248\n",
      "Epoch 188/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8738 - loss: 0.3048 - mse: 0.0301 - val_accuracy: 0.8933 - val_loss: 0.2493 - val_mse: 0.0250\n",
      "Epoch 189/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.2947 - mse: 0.0289 - val_accuracy: 0.8919 - val_loss: 0.2499 - val_mse: 0.0251\n",
      "Epoch 190/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8716 - loss: 0.3025 - mse: 0.0300 - val_accuracy: 0.8964 - val_loss: 0.2601 - val_mse: 0.0256\n",
      "Epoch 191/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.2968 - mse: 0.0292 - val_accuracy: 0.9033 - val_loss: 0.2404 - val_mse: 0.0237\n",
      "Epoch 192/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8744 - loss: 0.2985 - mse: 0.0295 - val_accuracy: 0.8875 - val_loss: 0.2782 - val_mse: 0.0277\n",
      "Epoch 193/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8771 - loss: 0.2983 - mse: 0.0295 - val_accuracy: 0.8933 - val_loss: 0.2578 - val_mse: 0.0252\n",
      "Epoch 194/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8667 - loss: 0.3187 - mse: 0.0315 - val_accuracy: 0.8950 - val_loss: 0.2653 - val_mse: 0.0260\n",
      "Epoch 195/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8693 - loss: 0.3161 - mse: 0.0310 - val_accuracy: 0.8831 - val_loss: 0.2661 - val_mse: 0.0270\n",
      "Epoch 196/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8708 - loss: 0.3066 - mse: 0.0305 - val_accuracy: 0.8903 - val_loss: 0.2580 - val_mse: 0.0261\n",
      "Epoch 197/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8778 - loss: 0.2945 - mse: 0.0290 - val_accuracy: 0.9022 - val_loss: 0.2359 - val_mse: 0.0235\n",
      "Epoch 198/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.2825 - mse: 0.0278 - val_accuracy: 0.8997 - val_loss: 0.2414 - val_mse: 0.0238\n",
      "Epoch 199/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.2993 - mse: 0.0296 - val_accuracy: 0.8525 - val_loss: 0.3186 - val_mse: 0.0334\n",
      "Epoch 200/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.2963 - mse: 0.0292 - val_accuracy: 0.9011 - val_loss: 0.2387 - val_mse: 0.0240\n",
      "Epoch 201/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8690 - loss: 0.3069 - mse: 0.0307 - val_accuracy: 0.8911 - val_loss: 0.2517 - val_mse: 0.0255\n",
      "Epoch 202/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8760 - loss: 0.2915 - mse: 0.0289 - val_accuracy: 0.8997 - val_loss: 0.2426 - val_mse: 0.0240\n",
      "Epoch 203/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8695 - loss: 0.3113 - mse: 0.0309 - val_accuracy: 0.8697 - val_loss: 0.2871 - val_mse: 0.0297\n",
      "Epoch 204/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8831 - loss: 0.2776 - mse: 0.0276 - val_accuracy: 0.8792 - val_loss: 0.2972 - val_mse: 0.0295\n",
      "Epoch 205/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8667 - loss: 0.3209 - mse: 0.0316 - val_accuracy: 0.8906 - val_loss: 0.2662 - val_mse: 0.0264\n",
      "Epoch 206/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8700 - loss: 0.3053 - mse: 0.0303 - val_accuracy: 0.8889 - val_loss: 0.2682 - val_mse: 0.0269\n",
      "Epoch 207/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8792 - loss: 0.2905 - mse: 0.0288 - val_accuracy: 0.8953 - val_loss: 0.2525 - val_mse: 0.0249\n",
      "Epoch 208/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8813 - loss: 0.2839 - mse: 0.0279 - val_accuracy: 0.8792 - val_loss: 0.2984 - val_mse: 0.0290\n",
      "Epoch 209/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8660 - loss: 0.3155 - mse: 0.0313 - val_accuracy: 0.8964 - val_loss: 0.2466 - val_mse: 0.0248\n",
      "Epoch 210/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8777 - loss: 0.2984 - mse: 0.0293 - val_accuracy: 0.8506 - val_loss: 0.3139 - val_mse: 0.0324\n",
      "Epoch 211/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8739 - loss: 0.3015 - mse: 0.0299 - val_accuracy: 0.8978 - val_loss: 0.2486 - val_mse: 0.0248\n",
      "Epoch 212/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8787 - loss: 0.2920 - mse: 0.0286 - val_accuracy: 0.8883 - val_loss: 0.2731 - val_mse: 0.0267\n",
      "Epoch 213/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8801 - loss: 0.2863 - mse: 0.0283 - val_accuracy: 0.9025 - val_loss: 0.2267 - val_mse: 0.0226\n",
      "Epoch 214/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8776 - loss: 0.2917 - mse: 0.0290 - val_accuracy: 0.8944 - val_loss: 0.2474 - val_mse: 0.0249\n",
      "Epoch 215/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8795 - loss: 0.2923 - mse: 0.0288 - val_accuracy: 0.8961 - val_loss: 0.2638 - val_mse: 0.0263\n",
      "Epoch 216/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8819 - loss: 0.2829 - mse: 0.0278 - val_accuracy: 0.9000 - val_loss: 0.2359 - val_mse: 0.0235\n",
      "Epoch 217/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8770 - loss: 0.2949 - mse: 0.0290 - val_accuracy: 0.8897 - val_loss: 0.2437 - val_mse: 0.0249\n",
      "Epoch 218/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8755 - loss: 0.2967 - mse: 0.0293 - val_accuracy: 0.8958 - val_loss: 0.2507 - val_mse: 0.0255\n",
      "Epoch 219/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8799 - loss: 0.2934 - mse: 0.0288 - val_accuracy: 0.8936 - val_loss: 0.2615 - val_mse: 0.0255\n",
      "Epoch 220/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8827 - loss: 0.2821 - mse: 0.0279 - val_accuracy: 0.8878 - val_loss: 0.2719 - val_mse: 0.0270\n",
      "Epoch 221/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2805 - mse: 0.0274 - val_accuracy: 0.8939 - val_loss: 0.2375 - val_mse: 0.0242\n",
      "Epoch 222/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8705 - loss: 0.3027 - mse: 0.0302 - val_accuracy: 0.8978 - val_loss: 0.2567 - val_mse: 0.0255\n",
      "Epoch 223/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8806 - loss: 0.2841 - mse: 0.0282 - val_accuracy: 0.8903 - val_loss: 0.2807 - val_mse: 0.0272\n",
      "Epoch 224/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8770 - loss: 0.2895 - mse: 0.0287 - val_accuracy: 0.8986 - val_loss: 0.2443 - val_mse: 0.0242\n",
      "Epoch 225/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8684 - loss: 0.3063 - mse: 0.0306 - val_accuracy: 0.8939 - val_loss: 0.2492 - val_mse: 0.0253\n",
      "Epoch 226/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.2865 - mse: 0.0285 - val_accuracy: 0.8975 - val_loss: 0.2406 - val_mse: 0.0243\n",
      "Epoch 227/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8797 - loss: 0.2923 - mse: 0.0287 - val_accuracy: 0.9019 - val_loss: 0.2301 - val_mse: 0.0231\n",
      "Epoch 228/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2825 - mse: 0.0278 - val_accuracy: 0.8842 - val_loss: 0.2609 - val_mse: 0.0267\n",
      "Epoch 229/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.2765 - mse: 0.0275 - val_accuracy: 0.9042 - val_loss: 0.2236 - val_mse: 0.0225\n",
      "Epoch 230/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.2823 - mse: 0.0278 - val_accuracy: 0.8878 - val_loss: 0.2774 - val_mse: 0.0278\n",
      "Epoch 231/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8835 - loss: 0.2863 - mse: 0.0282 - val_accuracy: 0.9000 - val_loss: 0.2422 - val_mse: 0.0242\n",
      "Epoch 232/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2752 - mse: 0.0273 - val_accuracy: 0.8975 - val_loss: 0.2497 - val_mse: 0.0243\n",
      "Epoch 233/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.2848 - mse: 0.0281 - val_accuracy: 0.9064 - val_loss: 0.2228 - val_mse: 0.0224\n",
      "Epoch 234/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2907 - mse: 0.0287 - val_accuracy: 0.8794 - val_loss: 0.2825 - val_mse: 0.0287\n",
      "Epoch 235/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8880 - loss: 0.2692 - mse: 0.0267 - val_accuracy: 0.8833 - val_loss: 0.2849 - val_mse: 0.0284\n",
      "Epoch 236/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8724 - loss: 0.3091 - mse: 0.0304 - val_accuracy: 0.9036 - val_loss: 0.2410 - val_mse: 0.0233\n",
      "Epoch 237/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8837 - loss: 0.2775 - mse: 0.0275 - val_accuracy: 0.8847 - val_loss: 0.2794 - val_mse: 0.0279\n",
      "Epoch 238/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2740 - mse: 0.0272 - val_accuracy: 0.9028 - val_loss: 0.2339 - val_mse: 0.0239\n",
      "Epoch 239/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8828 - loss: 0.2795 - mse: 0.0278 - val_accuracy: 0.8964 - val_loss: 0.2516 - val_mse: 0.0249\n",
      "Epoch 240/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8839 - loss: 0.2861 - mse: 0.0280 - val_accuracy: 0.8883 - val_loss: 0.2501 - val_mse: 0.0256\n",
      "Epoch 241/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8773 - loss: 0.2926 - mse: 0.0291 - val_accuracy: 0.8994 - val_loss: 0.2336 - val_mse: 0.0237\n",
      "Epoch 242/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8815 - loss: 0.2814 - mse: 0.0278 - val_accuracy: 0.9044 - val_loss: 0.2269 - val_mse: 0.0227\n",
      "Epoch 243/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2806 - mse: 0.0276 - val_accuracy: 0.8803 - val_loss: 0.2923 - val_mse: 0.0286\n",
      "Epoch 244/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3009 - mse: 0.0295 - val_accuracy: 0.8703 - val_loss: 0.3052 - val_mse: 0.0296\n",
      "Epoch 245/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8850 - loss: 0.2824 - mse: 0.0278 - val_accuracy: 0.9028 - val_loss: 0.2338 - val_mse: 0.0231\n",
      "Epoch 246/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2809 - mse: 0.0278 - val_accuracy: 0.9006 - val_loss: 0.2414 - val_mse: 0.0242\n",
      "Epoch 247/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2653 - mse: 0.0262 - val_accuracy: 0.8736 - val_loss: 0.2806 - val_mse: 0.0286\n",
      "Epoch 248/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8796 - loss: 0.2898 - mse: 0.0287 - val_accuracy: 0.8944 - val_loss: 0.2506 - val_mse: 0.0252\n",
      "Epoch 249/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2722 - mse: 0.0267 - val_accuracy: 0.8817 - val_loss: 0.2774 - val_mse: 0.0281\n",
      "Epoch 250/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.2793 - mse: 0.0275 - val_accuracy: 0.9031 - val_loss: 0.2286 - val_mse: 0.0227\n",
      "Epoch 251/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8838 - loss: 0.2829 - mse: 0.0280 - val_accuracy: 0.8808 - val_loss: 0.2703 - val_mse: 0.0272\n",
      "Epoch 252/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8809 - loss: 0.2825 - mse: 0.0280 - val_accuracy: 0.8986 - val_loss: 0.2316 - val_mse: 0.0236\n",
      "Epoch 253/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8870 - loss: 0.2717 - mse: 0.0267 - val_accuracy: 0.9006 - val_loss: 0.2439 - val_mse: 0.0244\n",
      "Epoch 254/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8748 - loss: 0.3042 - mse: 0.0300 - val_accuracy: 0.8900 - val_loss: 0.2553 - val_mse: 0.0257\n",
      "Epoch 255/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8849 - loss: 0.2766 - mse: 0.0273 - val_accuracy: 0.8900 - val_loss: 0.2530 - val_mse: 0.0258\n",
      "Epoch 256/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8826 - loss: 0.2833 - mse: 0.0279 - val_accuracy: 0.7772 - val_loss: 0.4964 - val_mse: 0.0511\n",
      "Epoch 257/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2879 - mse: 0.0284 - val_accuracy: 0.8733 - val_loss: 0.2857 - val_mse: 0.0296\n",
      "Epoch 258/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2736 - mse: 0.0272 - val_accuracy: 0.8914 - val_loss: 0.2453 - val_mse: 0.0251\n",
      "Epoch 259/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8761 - loss: 0.2980 - mse: 0.0293 - val_accuracy: 0.9036 - val_loss: 0.2348 - val_mse: 0.0235\n",
      "Epoch 260/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2809 - mse: 0.0276 - val_accuracy: 0.8933 - val_loss: 0.2448 - val_mse: 0.0248\n",
      "Epoch 261/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2819 - mse: 0.0277 - val_accuracy: 0.8983 - val_loss: 0.2342 - val_mse: 0.0238\n",
      "Epoch 262/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8741 - loss: 0.2955 - mse: 0.0293 - val_accuracy: 0.9019 - val_loss: 0.2332 - val_mse: 0.0234\n",
      "Epoch 263/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2710 - mse: 0.0268 - val_accuracy: 0.9056 - val_loss: 0.2306 - val_mse: 0.0228\n",
      "Epoch 264/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2687 - mse: 0.0265 - val_accuracy: 0.8969 - val_loss: 0.2420 - val_mse: 0.0247\n",
      "Epoch 265/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8756 - loss: 0.3027 - mse: 0.0296 - val_accuracy: 0.8972 - val_loss: 0.2350 - val_mse: 0.0238\n",
      "Epoch 266/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.2673 - mse: 0.0264 - val_accuracy: 0.8797 - val_loss: 0.2762 - val_mse: 0.0279\n",
      "Epoch 267/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8889 - loss: 0.2699 - mse: 0.0267 - val_accuracy: 0.8947 - val_loss: 0.2364 - val_mse: 0.0243\n",
      "Epoch 268/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8781 - loss: 0.2869 - mse: 0.0283 - val_accuracy: 0.8892 - val_loss: 0.2654 - val_mse: 0.0265\n",
      "Epoch 269/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.2725 - mse: 0.0270 - val_accuracy: 0.8856 - val_loss: 0.2571 - val_mse: 0.0263\n",
      "Epoch 270/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8818 - loss: 0.2780 - mse: 0.0277 - val_accuracy: 0.9003 - val_loss: 0.2393 - val_mse: 0.0242\n",
      "Epoch 271/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2640 - mse: 0.0262 - val_accuracy: 0.9089 - val_loss: 0.2167 - val_mse: 0.0218\n",
      "Epoch 272/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2690 - mse: 0.0266 - val_accuracy: 0.9022 - val_loss: 0.2395 - val_mse: 0.0235\n",
      "Epoch 273/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2684 - mse: 0.0264 - val_accuracy: 0.9008 - val_loss: 0.2418 - val_mse: 0.0240\n",
      "Epoch 274/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8860 - loss: 0.2821 - mse: 0.0275 - val_accuracy: 0.9025 - val_loss: 0.2361 - val_mse: 0.0234\n",
      "Epoch 275/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.2685 - mse: 0.0265 - val_accuracy: 0.8775 - val_loss: 0.2961 - val_mse: 0.0294\n",
      "Epoch 276/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8832 - loss: 0.2745 - mse: 0.0273 - val_accuracy: 0.8661 - val_loss: 0.2941 - val_mse: 0.0299\n",
      "Epoch 277/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8811 - loss: 0.2828 - mse: 0.0279 - val_accuracy: 0.8992 - val_loss: 0.2466 - val_mse: 0.0244\n",
      "Epoch 278/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.2625 - mse: 0.0259 - val_accuracy: 0.8867 - val_loss: 0.2503 - val_mse: 0.0257\n",
      "Epoch 279/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.2644 - mse: 0.0263 - val_accuracy: 0.8950 - val_loss: 0.2590 - val_mse: 0.0256\n",
      "Epoch 280/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2652 - mse: 0.0260 - val_accuracy: 0.8994 - val_loss: 0.2284 - val_mse: 0.0233\n",
      "Epoch 281/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2625 - mse: 0.0260 - val_accuracy: 0.9067 - val_loss: 0.2235 - val_mse: 0.0222\n",
      "Epoch 282/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8923 - loss: 0.2657 - mse: 0.0262 - val_accuracy: 0.9003 - val_loss: 0.2276 - val_mse: 0.0232\n",
      "Epoch 283/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.2639 - mse: 0.0261 - val_accuracy: 0.9114 - val_loss: 0.2118 - val_mse: 0.0211\n",
      "Epoch 284/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2626 - mse: 0.0259 - val_accuracy: 0.8592 - val_loss: 0.3314 - val_mse: 0.0336\n",
      "Epoch 285/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8802 - loss: 0.2879 - mse: 0.0284 - val_accuracy: 0.8992 - val_loss: 0.2343 - val_mse: 0.0237\n",
      "Epoch 286/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8822 - loss: 0.2771 - mse: 0.0275 - val_accuracy: 0.8858 - val_loss: 0.2564 - val_mse: 0.0261\n",
      "Epoch 287/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2780 - mse: 0.0273 - val_accuracy: 0.8750 - val_loss: 0.2884 - val_mse: 0.0296\n",
      "Epoch 288/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8867 - loss: 0.2686 - mse: 0.0267 - val_accuracy: 0.8992 - val_loss: 0.2467 - val_mse: 0.0247\n",
      "Epoch 289/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8844 - loss: 0.2748 - mse: 0.0273 - val_accuracy: 0.8894 - val_loss: 0.2662 - val_mse: 0.0265\n",
      "Epoch 290/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8885 - loss: 0.2687 - mse: 0.0267 - val_accuracy: 0.8642 - val_loss: 0.3246 - val_mse: 0.0318\n",
      "Epoch 291/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8935 - loss: 0.2619 - mse: 0.0258 - val_accuracy: 0.8972 - val_loss: 0.2365 - val_mse: 0.0243\n",
      "Epoch 292/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8857 - loss: 0.2765 - mse: 0.0273 - val_accuracy: 0.8964 - val_loss: 0.2447 - val_mse: 0.0247\n",
      "Epoch 293/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8913 - loss: 0.2661 - mse: 0.0263 - val_accuracy: 0.8222 - val_loss: 0.3290 - val_mse: 0.0358\n",
      "Epoch 294/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8852 - loss: 0.2718 - mse: 0.0271 - val_accuracy: 0.9106 - val_loss: 0.2152 - val_mse: 0.0217\n",
      "Epoch 295/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.2642 - mse: 0.0260 - val_accuracy: 0.8972 - val_loss: 0.2384 - val_mse: 0.0238\n",
      "Epoch 296/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.2850 - mse: 0.0283 - val_accuracy: 0.8903 - val_loss: 0.2568 - val_mse: 0.0253\n",
      "Epoch 297/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8918 - loss: 0.2635 - mse: 0.0261 - val_accuracy: 0.8822 - val_loss: 0.2616 - val_mse: 0.0263\n",
      "Epoch 298/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.2582 - mse: 0.0256 - val_accuracy: 0.8983 - val_loss: 0.2351 - val_mse: 0.0239\n",
      "Epoch 299/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.2647 - mse: 0.0262 - val_accuracy: 0.9058 - val_loss: 0.2227 - val_mse: 0.0225\n",
      "Epoch 300/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2544 - mse: 0.0253 - val_accuracy: 0.8931 - val_loss: 0.2557 - val_mse: 0.0253\n",
      "Epoch 301/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8882 - loss: 0.2664 - mse: 0.0265 - val_accuracy: 0.8875 - val_loss: 0.2504 - val_mse: 0.0255\n",
      "Epoch 302/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8892 - loss: 0.2661 - mse: 0.0263 - val_accuracy: 0.9136 - val_loss: 0.2040 - val_mse: 0.0205\n",
      "Epoch 303/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8854 - loss: 0.2747 - mse: 0.0273 - val_accuracy: 0.8997 - val_loss: 0.2366 - val_mse: 0.0241\n",
      "Epoch 304/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8804 - loss: 0.2802 - mse: 0.0280 - val_accuracy: 0.8989 - val_loss: 0.2356 - val_mse: 0.0241\n",
      "Epoch 305/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2609 - mse: 0.0261 - val_accuracy: 0.8603 - val_loss: 0.3277 - val_mse: 0.0319\n",
      "Epoch 306/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8858 - loss: 0.2691 - mse: 0.0267 - val_accuracy: 0.8842 - val_loss: 0.2770 - val_mse: 0.0275\n",
      "Epoch 307/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8840 - loss: 0.2712 - mse: 0.0268 - val_accuracy: 0.8947 - val_loss: 0.2699 - val_mse: 0.0263\n",
      "Epoch 308/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8910 - loss: 0.2665 - mse: 0.0263 - val_accuracy: 0.9031 - val_loss: 0.2486 - val_mse: 0.0243\n",
      "Epoch 309/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8887 - loss: 0.2693 - mse: 0.0265 - val_accuracy: 0.9022 - val_loss: 0.2185 - val_mse: 0.0222\n",
      "Epoch 310/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8901 - loss: 0.2630 - mse: 0.0262 - val_accuracy: 0.8844 - val_loss: 0.2558 - val_mse: 0.0263\n",
      "Epoch 311/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2644 - mse: 0.0259 - val_accuracy: 0.8825 - val_loss: 0.2712 - val_mse: 0.0274\n",
      "Epoch 312/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8956 - loss: 0.2482 - mse: 0.0245 - val_accuracy: 0.9050 - val_loss: 0.2238 - val_mse: 0.0222\n",
      "Epoch 313/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8873 - loss: 0.2692 - mse: 0.0268 - val_accuracy: 0.8992 - val_loss: 0.2354 - val_mse: 0.0235\n",
      "Epoch 314/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2595 - mse: 0.0257 - val_accuracy: 0.9064 - val_loss: 0.2207 - val_mse: 0.0221\n",
      "Epoch 315/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.2687 - mse: 0.0266 - val_accuracy: 0.8911 - val_loss: 0.2741 - val_mse: 0.0266\n",
      "Epoch 316/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2572 - mse: 0.0253 - val_accuracy: 0.8825 - val_loss: 0.2984 - val_mse: 0.0287\n",
      "Epoch 317/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8899 - loss: 0.2633 - mse: 0.0260 - val_accuracy: 0.8931 - val_loss: 0.2416 - val_mse: 0.0247\n",
      "Epoch 318/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8922 - loss: 0.2573 - mse: 0.0255 - val_accuracy: 0.8675 - val_loss: 0.2715 - val_mse: 0.0285\n",
      "Epoch 319/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8952 - loss: 0.2542 - mse: 0.0252 - val_accuracy: 0.8708 - val_loss: 0.3055 - val_mse: 0.0301\n",
      "Epoch 320/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8938 - loss: 0.2572 - mse: 0.0254 - val_accuracy: 0.8911 - val_loss: 0.2513 - val_mse: 0.0255\n",
      "Epoch 321/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8901 - loss: 0.2637 - mse: 0.0261 - val_accuracy: 0.8978 - val_loss: 0.2272 - val_mse: 0.0231\n",
      "Epoch 322/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8902 - loss: 0.2627 - mse: 0.0262 - val_accuracy: 0.8872 - val_loss: 0.2577 - val_mse: 0.0261\n",
      "Epoch 323/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.2699 - mse: 0.0266 - val_accuracy: 0.8686 - val_loss: 0.2772 - val_mse: 0.0288\n",
      "Epoch 324/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8909 - loss: 0.2640 - mse: 0.0263 - val_accuracy: 0.9003 - val_loss: 0.2382 - val_mse: 0.0238\n",
      "Epoch 325/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8898 - loss: 0.2610 - mse: 0.0260 - val_accuracy: 0.8936 - val_loss: 0.2457 - val_mse: 0.0251\n",
      "Epoch 326/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8933 - loss: 0.2546 - mse: 0.0251 - val_accuracy: 0.8944 - val_loss: 0.2564 - val_mse: 0.0255\n",
      "Epoch 327/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2647 - mse: 0.0262 - val_accuracy: 0.9025 - val_loss: 0.2333 - val_mse: 0.0236\n",
      "Epoch 328/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8925 - loss: 0.2567 - mse: 0.0254 - val_accuracy: 0.8878 - val_loss: 0.2767 - val_mse: 0.0272\n",
      "Epoch 329/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8940 - loss: 0.2547 - mse: 0.0251 - val_accuracy: 0.9097 - val_loss: 0.2113 - val_mse: 0.0212\n",
      "Epoch 330/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8944 - loss: 0.2505 - mse: 0.0249 - val_accuracy: 0.8719 - val_loss: 0.2805 - val_mse: 0.0295\n",
      "Epoch 331/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2795 - mse: 0.0277 - val_accuracy: 0.9056 - val_loss: 0.2331 - val_mse: 0.0235\n",
      "Epoch 332/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2586 - mse: 0.0255 - val_accuracy: 0.9019 - val_loss: 0.2348 - val_mse: 0.0233\n",
      "Epoch 333/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8933 - loss: 0.2542 - mse: 0.0251 - val_accuracy: 0.8869 - val_loss: 0.2615 - val_mse: 0.0259\n",
      "Epoch 334/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8903 - loss: 0.2631 - mse: 0.0260 - val_accuracy: 0.9019 - val_loss: 0.2499 - val_mse: 0.0245\n",
      "Epoch 335/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8955 - loss: 0.2543 - mse: 0.0251 - val_accuracy: 0.9017 - val_loss: 0.2242 - val_mse: 0.0229\n",
      "Epoch 336/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8931 - loss: 0.2554 - mse: 0.0255 - val_accuracy: 0.9022 - val_loss: 0.2136 - val_mse: 0.0220\n",
      "Epoch 337/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8942 - loss: 0.2542 - mse: 0.0252 - val_accuracy: 0.8947 - val_loss: 0.2576 - val_mse: 0.0255\n",
      "Epoch 338/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8897 - loss: 0.2630 - mse: 0.0260 - val_accuracy: 0.9042 - val_loss: 0.2137 - val_mse: 0.0218\n",
      "Epoch 339/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8915 - loss: 0.2557 - mse: 0.0254 - val_accuracy: 0.9025 - val_loss: 0.2367 - val_mse: 0.0238\n",
      "Epoch 340/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2486 - mse: 0.0248 - val_accuracy: 0.8914 - val_loss: 0.2403 - val_mse: 0.0245\n",
      "Epoch 341/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2679 - mse: 0.0266 - val_accuracy: 0.8786 - val_loss: 0.2792 - val_mse: 0.0286\n",
      "Epoch 342/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8929 - loss: 0.2593 - mse: 0.0256 - val_accuracy: 0.9033 - val_loss: 0.2287 - val_mse: 0.0227\n",
      "Epoch 343/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8958 - loss: 0.2500 - mse: 0.0249 - val_accuracy: 0.9097 - val_loss: 0.2124 - val_mse: 0.0217\n",
      "Epoch 344/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8890 - loss: 0.2640 - mse: 0.0262 - val_accuracy: 0.9111 - val_loss: 0.2121 - val_mse: 0.0214\n",
      "Epoch 345/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8936 - loss: 0.2580 - mse: 0.0255 - val_accuracy: 0.8936 - val_loss: 0.2522 - val_mse: 0.0251\n",
      "Epoch 346/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8908 - loss: 0.2623 - mse: 0.0261 - val_accuracy: 0.9031 - val_loss: 0.2223 - val_mse: 0.0225\n",
      "Epoch 347/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8967 - loss: 0.2551 - mse: 0.0251 - val_accuracy: 0.8736 - val_loss: 0.2758 - val_mse: 0.0287\n",
      "Epoch 348/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8824 - loss: 0.2830 - mse: 0.0280 - val_accuracy: 0.9006 - val_loss: 0.2345 - val_mse: 0.0236\n",
      "Epoch 349/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.2496 - mse: 0.0248 - val_accuracy: 0.9047 - val_loss: 0.2271 - val_mse: 0.0225\n",
      "Epoch 350/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8917 - loss: 0.2577 - mse: 0.0256 - val_accuracy: 0.8936 - val_loss: 0.2425 - val_mse: 0.0246\n",
      "Epoch 351/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8881 - loss: 0.2605 - mse: 0.0260 - val_accuracy: 0.8719 - val_loss: 0.2729 - val_mse: 0.0288\n",
      "Epoch 352/700\n",
      "\u001b[1m131/131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8877 - loss: 0.2676 - mse: 0.0266 - val_accuracy: 0.8950 - val_loss: 0.2494 - val_mse: 0.0253\n",
      "\n",
      "Efectividad del modelo con datos de testeo para:\n",
      " - Accuracy:  91.81%\n",
      " - Pérdida :   0.19917\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "X_train = train_df.drop(columns=[\"filename\", \"num_of_fingers\"]).to_numpy()\n",
    "y_train_raw = train_df[\"num_of_fingers\"].astype(int).to_numpy()\n",
    "y_train = to_categorical(y_train_raw, num_classes=6)\n",
    "\n",
    "X_test = test_df.drop(columns=[\"filename\", \"num_of_fingers\"]).to_numpy()\n",
    "y_test_raw = test_df[\"num_of_fingers\"].astype(int).to_numpy()\n",
    "y_test = to_categorical(y_test_raw, num_classes=6)\n",
    "\n",
    "entradas = X_train.shape[1]\n",
    "print(\"ENTRADAS TRAIN:\", entradas)\n",
    "salidas = 6\n",
    "print(\"SALIDAS TRAIN:\", salidas)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Input(shape=(entradas,)))\n",
    "model.add(Dense(20, activation=\"linear\"))\n",
    "model.add(Dense(20, activation=LeakyReLU()))\n",
    "model.add(Dense(20, activation=LeakyReLU()))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(20, activation=LeakyReLU()))\n",
    "model.add(Dense(20, activation=LeakyReLU()))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(salidas, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics = ['accuracy', 'mse'])\n",
    "\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor='val_loss',\n",
    "                                    patience=50,\n",
    "                                    restore_best_weights=True\n",
    "                                )\n",
    "\n",
    "history = model.fit(\n",
    "                x = X_train,\n",
    "                y = y_train,\n",
    "                batch_size = 110,\n",
    "                epochs = 700,\n",
    "                validation_split = 0.2,\n",
    "                callbacks=[early_stop],\n",
    "            )\n",
    "\n",
    "# Evaluar el modelo con los datos de testeo\n",
    "y_pred = model.evaluate(X_test, y_test, verbose=False)\n",
    "\n",
    "print('\\nEfectividad del modelo con datos de testeo para:' )\n",
    "print(\" - Accuracy: %6.2f%%\" % (y_pred[1]*100))\n",
    "print(\" - Pérdida : %9.5f\" % (y_pred[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mi_entorno",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
